---
title: "flat_teaching.Rmd for working package"
output: html_document
editor_options: 
  chunk_output_type: console
---

<!-- 
Run this 'development' chunk

Store every call to library() that you need to run chunks line by line, as in a classical Rmd for analysis
-->

```{r development, include=FALSE}
library(testthat)
library(roxygen2)
```

<!--
# Description of your package

This will fill the description of your package.
Fill and run the content of this chunk, before anything else. 

Note: when you will use other flat templates, this part will be in a separate file. Do not be surprised!
--> 

```{r description, eval=FALSE}
# Describe your package
fusen::fill_description(
  pkg = here::here(),
  fields = list(
    Title = "Fresh and Efficient Data Processing Tools",
    Description = "`mintyr` is an R package offering fresh and efficient solutions for data processing, with a focus on animal breeding data. It provides streamlined functionality for handling multi-breed and multi-trait data in genomic selection, leveraging nested data structures for clear model iteration. Built primarily with `data.table` and base R for performance, the package delivers a comprehensive collection of utility functions that balance efficiency with user-friendly data manipulation approaches.Detailed documentation and examples are available through the package website at <https://tony2015116.github.io/mintyr>.",
    `Authors@R` = c(
      person("Guo Meng", email = "tony2015116@163.com", role = c("aut", "cre")),
      person(given = "Guo Meng", role = "cph")
    )
  ), overwrite = TRUE
)
# Define License with use_*_license()
usethis::use_mit_license("Guo Meng")
```



# split_cv
    
```{r function-split_cv}
#' Cross-Validation Split Generator
#'
#' @description
#' A robust cross-validation splitting utility for multiple datasets with advanced stratification and configuration options.
#'
#' @param split_dt `list` of input datasets
#'   - Must contain `data.frame` or `data.table` elements
#'   - Supports multiple dataset processing
#'   - Cannot be empty
#' @inheritParams rsample::vfold_cv
#' 
#' @details
#' Advanced Cross-Validation Mechanism:
#' \enumerate{
#'   \item Input dataset validation
#'   \item Stratified or unstratified sampling
#'   \item Flexible fold generation
#'   \item Train-validate set creation
#' }
#'
#' Sampling Strategies:
#' \itemize{
#'   \item Supports multiple dataset processing
#'   \item Handles stratified and unstratified sampling
#'   \item Generates reproducible cross-validation splits
#' }
#'
#' @return `list` of `data.table` objects containing:
#'   \itemize{
#'     \item `splits`: Cross-validation split objects
#'     \item `train`: Training dataset subsets
#'     \item `validate`: Validation dataset subsets
#'   }
#'
#' @note Important Constraints:
#' \itemize{
#'   \item Requires non-empty input datasets
#'   \item All datasets must be `data.frame` or `data.table`
#'   \item Strata column must exist if specified
#'   \item Computational resources impact large dataset processing
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`rsample::vfold_cv()`] Core cross-validation function
#' }
#'
#' @import data.table
#' @importFrom rsample vfold_cv
#' @export
split_cv <- function(split_dt, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...) {
  id <- splits <- NULL
  # Input validation
  if (!is.list(split_dt)) {
    stop("split_dt must be a list")
  }
  
  if (length(split_dt) == 0) {
    stop("The input split_dt cannot be empty")
  }
  
  # Check if all elements are data.frames or data.tables
  is_valid <- all(sapply(split_dt, function(x) {
    inherits(x, c("data.frame", "data.table"))
  }))
  
  if (!is_valid) {
    stop("All elements in split_dt must be data.frames or data.tables")
  }
  
  # Initialize result list
  result <- vector("list", length(split_dt))
  names(result) <- names(split_dt)
  
  # Process each element in the list
  for (i in seq_along(split_dt)) {
    current_data <- split_dt[[i]]
    
    # Convert to data.table if not already
    if (!data.table::is.data.table(current_data)) {
      current_data <- data.table::as.data.table(current_data)
    }
    
    # Create CV splits arguments
    cv_args <- list(
      data = current_data,
      v = v,
      repeats = repeats,
      breaks = breaks,
      pool = pool,
      ...
    )
    
    # Add strata to arguments if provided and exists in data
    if (!is.null(strata)) {
      if (strata %in% names(current_data)) {
        cv_args$strata <- strata
      } else {
        warning(sprintf("Strata variable '%s' not found in dataset %s, performing unstratified CV",
                        strata, names(split_dt)[i]))
      }
    }
    
    # Perform cross-validation
    cv_obj <- do.call(rsample::vfold_cv, cv_args)
    
    # Create result data.table
    result_dt <- data.table::data.table(
      splits = cv_obj$splits
    )
    
    # Set id and id2 based on repeats
    if (repeats == 1) {
      result_dt[, id := cv_obj$id]    # fold column
    } else {
      result_dt[, `:=`(
        id = cv_obj$id,    # repeat column
        id2 = cv_obj$id2   # fold column
      )]
    }
    
    # Add train and validation sets
    result_dt[, `:=`(
      train = lapply(splits, function(x) rsample::training(x)),
      validate = lapply(splits, function(x) rsample::testing(x))
    )]
    
    result[[i]] <- result_dt
  }
  
  return(result)
}
```
  
```{r example-split_cv}
# Prepare example data: Convert first 3 columns of iris dataset to long format and split
dt_split <- w2l_split(data = iris, cols2l = 1:3)
# dt_split is now a list containing 3 data tables for Sepal.Length, Sepal.Width, and Petal.Length

# Example 1: Single cross-validation (no repeats)
split_cv(
  split_dt = dt_split,  # Input list of split data
  v = 3,                # Set 3-fold cross-validation
  repeats = 1           # Perform cross-validation once (no repeats)
)
# Returns a list where each element contains:
# - splits: rsample split objects
# - id: fold numbers (Fold1, Fold2, Fold3)
# - train: training set data
# - validate: validation set data

# Example 2: Repeated cross-validation
split_cv(
  split_dt = dt_split,  # Input list of split data
  v = 3,                # Set 3-fold cross-validation
  repeats = 2           # Perform cross-validation twice
)
# Returns a list where each element contains:
# - splits: rsample split objects
# - id: repeat numbers (Repeat1, Repeat2)
# - id2: fold numbers (Fold1, Fold2, Fold3)
# - train: training set data
# - validate: validation set data
```

```{r tests-split_cv}
# Create test data
create_test_data <- function() {
  dt1 <- data.table(
    x = 1:100,
    y = rnorm(100),
    group = rep(letters[1:4], 25)
  )
  dt2 <- data.table(
    x = 1:50,
    y = rnorm(50),
    group = rep(letters[1:2], 25)
  )
  return(list(data1 = dt1, data2 = dt2))
}

# Basic functionality test
test_that("split_cv returns correct structure", {
  test_data <- create_test_data()
  result <- split_cv(test_data, v = 5, repeats = 1)
  
  # Check basic structure of return value
  expect_type(result, "list")
  expect_equal(length(result), length(test_data))
  expect_named(result, names(test_data))
  
  # Check structure of each result set
  for (res in result) {
    expect_true(is.data.table(res))
    expect_true(all(c("splits", "id", "train", "validate") %in% names(res)))
    expect_equal(nrow(res), 5)
  }
})

# Error handling test
test_that("split_cv handles invalid inputs correctly", {
  expect_error(split_cv(NULL))
  expect_error(split_cv(list()))
  expect_error(split_cv(list(a = 1, b = 2)))
  
  test_data <- create_test_data()
  expect_warning(
    split_cv(test_data, v = 5, strata = "non_existent_column"),
    "Strata variable 'non_existent_column' not found"
  )
})

# Repeated cross-validation test
test_that("split_cv handles repeats correctly", {
  test_data <- create_test_data()
  
  # Single cross-validation
  result_single <- split_cv(test_data, v = 5, repeats = 1)
  for (res in result_single) {
    expect_true("id" %in% names(res))
    expect_false("id2" %in% names(res))
    expect_equal(nrow(res), 5)
    expect_true(all(res$id %in% paste0("Fold", 1:5)))
  }
  
  # Multiple repeats
  result_multiple <- split_cv(test_data, v = 5, repeats = 3)
  for (res in result_multiple) {
    expect_true(all(c("id", "id2") %in% names(res)))
    expect_equal(nrow(res), 15)
    expect_true(all(grepl("^Repeat\\d+$", res$id)))
    expect_true(all(grepl("^Fold\\d+$", res$id2)))
    expect_equal(length(unique(res$id)), 3)
    expect_equal(length(unique(res$id2)), 5)
    
    # Check number of folds in each repeat
    for (repeat_id in unique(res$id)) {
      expect_equal(res[id == repeat_id, .N], 5)
    }
  }
})

# Train and validation sets test
test_that("split_cv generates correct train and validate sets", {
  test_data <- create_test_data()
  result <- split_cv(test_data, v = 5, repeats = 2)
  
  for (i in seq_along(result)) {
    res <- result[[i]]
    original_data <- test_data[[i]]
    
    # Randomly check one split
    sample_split_idx <- sample(1:nrow(res), 1)
    train_set <- res$train[[sample_split_idx]]
    validate_set <- res$validate[[sample_split_idx]]
    
    # Check set properties
    train_rows <- train_set$x
    validate_rows <- validate_set$x
    original_rows <- nrow(original_data)
    
    # Check mutual exclusivity
    expect_equal(length(intersect(train_rows, validate_rows)), 0)
    
    # Check sizes
    expect_equal(length(validate_rows), original_rows/5, tolerance = 1)
    expect_equal(length(train_rows), original_rows * 4/5, tolerance = 1)
    
    # Check completeness
    all_rows <- sort(unique(c(train_rows, validate_rows)))
    expect_equal(all_rows, 1:original_rows)
  }
})

# Stratification test
test_that("split_cv handles stratification correctly", {
  test_data <- create_test_data()
  result <- split_cv(test_data, v = 5, strata = "group")
  
  for (res in result) {
    first_split <- res$train[[1]]
    expect_true("group" %in% names(first_split))
    unique_groups <- unique(first_split$group)
    expect_true(length(unique_groups) > 1)
  }
})

# Data type handling test
test_that("split_cv handles different input data types", {
  # Test with data.frame
  df_data <- list(
    data1 = as.data.frame(create_test_data()[[1]]),
    data2 = as.data.frame(create_test_data()[[2]])
  )
  result_df <- split_cv(df_data, v = 5)
  expect_true(all(sapply(result_df, is.data.table)))
  
  # Test with mixed types
  mixed_data <- list(
    data1 = as.data.frame(create_test_data()[[1]]),
    data2 = create_test_data()[[2]]
  )
  result_mixed <- split_cv(mixed_data, v = 5)
  expect_true(all(sapply(result_mixed, is.data.table)))
})

```



# c2p_nest
    
```{r function-c2p_nest}
#' Column to Pair Nested Transformation
#'
#' @description
#' A sophisticated data transformation tool for generating column pair combinations 
#' and creating nested data structures with advanced configuration options.
#'
#' @param data Input `data frame` or `data table`
#'   - Must contain valid columns for transformation
#'   - Supports multiple data types
#'
#' @param cols2bind Column specification for pair generation
#'   - Can be a `character` vector of column names
#'   - Can be a `numeric` vector of column indices
#'   - Must reference existing columns in the dataset
#'
#' @param by Optional grouping specification
#'   - Can be a `character` vector of column names
#'   - Can be a `numeric` vector of column indices
#'   - Enables hierarchical nested transformations
#'   - Supports multi-level aggregation
#'   - Default is `NULL`
#'
#' @param pairs_n `numeric` indicating combination size
#'   - Minimum value: 2
#'   - Maximum value: Length of `cols2bind`
#'   - Controls column pair complexity
#'   - Default is 2
#'
#' @param sep `character` separator for pair naming
#'   - Used in generating combination identifiers
#'   - Must be a single character
#'   - Default is "-"
#'
#' @param nest_type Output nesting format
#'   - `"dt"`: Returns nested `data table` (default)
#'   - `"df"`: Returns nested `data frame`
#'
#' @details
#' Advanced Transformation Mechanism:
#' \enumerate{
#'   \item Input validation and preprocessing
#'   \item Dynamic column combination generation
#'   \item Flexible pair transformation
#'   \item Nested data structure creation
#' }
#'
#' Transformation Process:
#' \itemize{
#'   \item Validate input parameters and column specifications
#'   \item Convert numeric indices to column names if necessary
#'   \item Generate column combinations
#'   \item Create subset data tables
#'   \item Merge and nest transformed data
#' }
#'
#' Column Specification:
#' \itemize{
#'   \item Supports both column names and numeric indices
#'   \item Numeric indices must be within valid range (1 to ncol)
#'   \item Column names must exist in the dataset
#'   \item Flexible specification for both cols2bind and by parameters
#' }
#'
#' @return `data table` containing nested transformation results
#'   - Includes `pairs` column identifying column combinations
#'   - Contains `data` column storing nested data structures
#'   - Supports optional grouping variables
#'
#' @note Key Operation Constraints:
#' \itemize{
#'   \item Requires non-empty input data
#'   \item Column specifications must be valid (either names or indices)
#'   \item Supports flexible combination strategies
#'   \item Computational complexity increases with combination size
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`utils::combn()`] Combination generation
#' }
#'
#' @import data.table
#' @importFrom utils combn
#' @export

c2p_nest <- function(data, cols2bind, by = NULL, pairs_n = 2, sep = "-", nest_type = "dt") {
  . <- pairs <- NULL  # For data.table's NSE
  
  # Validate inputs
  if (!inherits(data, c("data.table", "data.frame"))) {
    stop("data must be a data.table or a data.frame")
  }
  data <- data.table::as.data.table(data)
  
  # Handle numeric indices for cols2bind
  if (is.numeric(cols2bind)) {
    if (any(cols2bind > ncol(data) | cols2bind < 1)) {
      stop("Invalid column indices in cols2bind")
    }
    cols2bind <- names(data)[cols2bind]
  }
  
  if (!is.character(cols2bind)) {
    stop("cols2bind must be either a character vector or numeric vector")
  }
  missing_cols <- cols2bind[!cols2bind %in% names(data)]
  if (length(missing_cols) > 0) {
    stop("Some columns specified in cols2bind are not present in the data: ", paste(missing_cols, collapse=", "))
  }
  
  # Handle numeric indices for by parameter
  if (!is.null(by)) {
    if (is.numeric(by)) {
      if (any(by > ncol(data) | by < 1)) {
        stop("Invalid column indices in by")
      }
      by <- names(data)[by]
    }
    if (!is.character(by)) {
      stop("'by' must be either a character vector or numeric vector of column indices")
    }
    missing_by_vars <- by[!by %in% names(data)]
    if (length(missing_by_vars) > 0) {
      stop("Grouping variables not present in data: ", paste(missing_by_vars, collapse=", "))
    }
  }
  
  # Validate pairs_n
  if (!is.numeric(pairs_n) || pairs_n < 2 || floor(pairs_n) != pairs_n) {
    stop("pairs_n must be a positive integer greater than or equal to 2")
  }
  
  # Check if pairs_n is less than or equal to the number of available columns
  if (pairs_n > length(cols2bind)) {
    stop(sprintf("pairs_n (%d) cannot be larger than the number of available columns (%d)", 
                 pairs_n, length(cols2bind)))
  }
  
  if (!is.character(sep) || length(sep) != 1) {
    stop("sep must be a single character string")
  }
  
  if (!nest_type %in% c("dt", "df")) {
    stop("Invalid nest_type provided. It must be either 'dt' or 'df'.")
  }
  
  # Prepare data for combination operations
  dt <- data.table::copy(data)
  fixed_cols <- setdiff(names(dt), cols2bind)
  comb_cols_list <- combn(cols2bind, pairs_n, simplify=FALSE)
  
  list_of_dts <- lapply(comb_cols_list, function(comb) {
    dt_subset <- dt[, c(fixed_cols, comb), with=FALSE]
    pairs_name <- paste(comb, collapse=sep)
    data.table::setnames(dt_subset, comb, paste0('value', seq_along(comb)))
    dt_subset[, pairs := pairs_name]
    dt_subset
  })
  
  dt_bind <- data.table::rbindlist(list_of_dts)
  
  # Determine grouping variables
  if (!is.null(by) && length(by) > 0) {
    groupby <- c("pairs", by)
  } else {
    groupby <- "pairs"
  }
  
  # Nest the data based on nest_type
  if (nest_type == "dt") {
    result <- dt_bind[, .(data = list(.SD)), by = groupby]
  } else if (nest_type == "df") {
    result <- dt_bind[, .(data = list(as.data.frame(.SD))), by = groupby]
  }
  
  return(result)
}
```
  
```{r example-c2p_nest}
# Example data preparation: Define column names for combination
col_names <- c("Sepal.Length", "Sepal.Width", "Petal.Length")

# Example 1: Basic column-to-pairs nesting with custom separator
c2p_nest(
  iris,                   # Input iris dataset
  cols2bind = col_names,  # Columns to be combined as pairs
  pairs_n = 2,            # Create pairs of 2 columns
  sep = "&"               # Custom separator for pair names
)
# Returns a nested data.table where:
# - pairs: combined column names (e.g., "Sepal.Length&Sepal.Width")
# - data: list column containing data.tables with value1, value2 columns

# Example 2: Column-to-pairs nesting with numeric indices and grouping
c2p_nest(
  iris,                   # Input iris dataset
  cols2bind = 1:3,        # First 3 columns to be combined
  pairs_n = 2,            # Create pairs of 2 columns
  by = 5                  # Group by 5th column (Species)
)
# Returns a nested data.table where:
# - pairs: combined column names
# - Species: grouping variable
# - data: list column containing data.tables grouped by Species
```

```{r tests-c2p_nest}
# Create test data
create_test_data <- function() {
  dt <- data.table(
    id = 1:10,
    x1 = letters[1:10],
    x2 = LETTERS[1:10],
    x3 = month.abb[1:10],
    group = rep(c("A", "B"), each = 5)
  )
  return(dt)
}

# Basic functionality test
test_that("c2p_nest returns correct structure", {
  test_data <- create_test_data()
  
  # Test with basic parameters
  result <- c2p_nest(test_data, cols2bind = c("x1", "x2", "x3"))
  
  # Check return structure
  expect_true(is.data.table(result))
  expect_true(all(c("pairs", "data") %in% names(result)))
  expect_equal(ncol(result), 2)
  
  # Check pairs combinations
  expected_pairs <- combn(c("x1", "x2", "x3"), 2, paste, collapse = "-")
  expect_equal(sort(unique(result$pairs)), sort(expected_pairs))
  
  # Check nested data structure
  expect_true(all(sapply(result$data, is.data.table)))
  first_nested_dt <- result$data[[1]]
  expect_true(all(c("id", "group", "value1", "value2") %in% names(first_nested_dt)))
})

# Test different nest_type options
test_that("c2p_nest handles different nest_type correctly", {
  test_data <- create_test_data()
  
  # Test with dt
  result_dt <- c2p_nest(test_data, cols2bind = c("x1", "x2"), nest_type = "dt")
  expect_true(all(sapply(result_dt$data, is.data.table)))
  
  # Test with df
  result_df <- c2p_nest(test_data, cols2bind = c("x1", "x2"), nest_type = "df")
  expect_true(all(sapply(result_df$data, is.data.frame)))
  expect_false(any(sapply(result_df$data, is.data.table)))
})

# Test grouping functionality
test_that("c2p_nest handles grouping correctly", {
  test_data <- create_test_data()
  
  # Test with by parameter
  result <- c2p_nest(test_data, cols2bind = c("x1", "x2"), by = "group")
  
  # Check structure
  expect_true(all(c("pairs", "group", "data") %in% names(result)))
  
  # Check grouping results
  expect_equal(nrow(result), length(unique(test_data$group)) * choose(2, 2))
  
  # Check that each group contains correct data
  first_group_data <- result[group == "A"]$data[[1]]
  expect_equal(nrow(first_group_data), 5)
})

# Test pairs_n parameter
test_that("c2p_nest handles different pairs_n correctly", {
  test_data <- create_test_data()
  
  # Test with pairs_n = 2
  result_2 <- c2p_nest(test_data, cols2bind = c("x1", "x2", "x3"), pairs_n = 2)
  expect_equal(nrow(result_2), choose(3, 2))
  
  # Test with pairs_n = 3
  result_3 <- c2p_nest(test_data, cols2bind = c("x1", "x2", "x3"), pairs_n = 3)
  expect_equal(nrow(result_3), choose(3, 3))
})

# Error handling tests
test_that("c2p_nest handles invalid inputs correctly", {
  test_data <- create_test_data()
  
  # Invalid data type
  expect_error(c2p_nest(list(), cols2bind = c("x1", "x2")))
  
  # Invalid cols2bind
  expect_error(c2p_nest(test_data, cols2bind = "non_existent_col"))
  expect_error(c2p_nest(test_data, cols2bind = 100))
  expect_error(c2p_nest(test_data, cols2bind = list()))
  
  # Invalid by parameter
  expect_error(c2p_nest(test_data, cols2bind = c("x1", "x2"), by = "non_existent_col"))
  expect_error(c2p_nest(test_data, cols2bind = c("x1", "x2"), by = 100))
  
  # Invalid pairs_n
  expect_error(c2p_nest(test_data, cols2bind = c("x1", "x2"), pairs_n = 1))
  expect_error(c2p_nest(test_data, cols2bind = c("x1", "x2"), pairs_n = 3))
  expect_error(c2p_nest(test_data, cols2bind = c("x1", "x2"), pairs_n = 1.5))
  
  # Invalid nest_type
  expect_error(c2p_nest(test_data, cols2bind = c("x1", "x2"), nest_type = "invalid"))
})

# Test different input column specifications
test_that("c2p_nest handles different column specifications correctly", {
  test_data <- create_test_data()
  
  # Test with column names
  result_names <- c2p_nest(test_data, cols2bind = c("x1", "x2"))
  
  # Test with column indices
  result_indices <- c2p_nest(test_data, cols2bind = c(2, 3))
  
  # Results should be identical
  expect_equal(result_names, result_indices)
})

# Test separator parameter
test_that("c2p_nest handles different separators correctly", {
  test_data <- create_test_data()
  
  # Test with different separators
  result_dash <- c2p_nest(test_data, cols2bind = c("x1", "x2"), sep = "-")
  result_underscore <- c2p_nest(test_data, cols2bind = c("x1", "x2"), sep = "_")
  
  # Check pair names
  expect_true(all(grepl("-", result_dash$pairs)))
  expect_true(all(grepl("_", result_underscore$pairs)))
})
```


# r2p_nest
    
```{r function-r2p_nest}
#' Row to Pair Nested Transformation
#'
#' @description
#' A sophisticated data transformation tool for performing row pair conversion 
#' and creating nested data structures with advanced configuration options.
#'
#' @param data Input `data frame` or `data table`
#'   - Must contain valid columns for transformation
#'   - Supports multiple data types
#'
#' @param rows2bind Row binding specification
#'   - Can be a `character` column name
#'   - Can be a `numeric` column index
#'   - Must be a single column identifier
#'
#' @param by Grouping specification for nested pairing
#'   - Can be a `character` vector of column names
#'   - Can be a `numeric` vector of column indices
#'   - Must specify at least one column
#'   - Supports multi-column transformation
#'
#' @param nest_type Output nesting format
#'   - `"dt"`: Returns nested `data table` (default)
#'   - `"df"`: Returns nested `data frame`
#'
#' @details
#' Advanced Transformation Mechanism:
#' \enumerate{
#'   \item Input validation and preprocessing
#'   \item Dynamic column identification
#'   \item Flexible row pairing across specified columns
#'   \item Nested data structure generation
#' }
#'
#' Transformation Process:
#' \itemize{
#'   \item Validate input parameters and column specifications
#'   \item Convert numeric indices to column names if necessary
#'   \item Reshape data from wide to long format
#'   \item Perform column-wise nested transformation
#'   \item Generate final nested structure
#' }
#'
#' Column Specification:
#' \itemize{
#'   \item Supports both column names and numeric indices
#'   \item Numeric indices must be within valid range (1 to ncol)
#'   \item Column names must exist in the dataset
#'   \item Flexible specification for both rows2bind and by parameters
#' }
#'
#' @return `data table` containing nested transformation results
#'   - Includes `name` column identifying source columns
#'   - Contains `data` column storing nested data structures
#'
#' @note Key Operation Constraints:
#' \itemize{
#'   \item Requires non-empty input data
#'   \item Column specifications must be valid (either names or indices)
#'   \item By parameter must specify at least one column
#'   \item Low computational overhead
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`data.table::melt()`] Long format conversion
#'   \item [`data.table::dcast()`] Wide format conversion
#'   \item [`base::rbind()`] Row binding utility
#'   \item [`c2p_nest()`] Column to pair nested transformation
#' }
#'
#' @import data.table
#' @importFrom stats as.formula
#' @export

r2p_nest <- function(data, rows2bind, by, nest_type = "dt") {
  # Input validation
  if (length(by) < 1) {
    stop("At least one column must be specified in 'by'")
  }
  if (length(rows2bind) != 1) {
    stop("rows2bind must be a single column")
  }

  # Convert data to data.table first
  data <- as.data.table(data)

  # Validate column existence and indices
  if (is.numeric(by)) {
    if (any(by > ncol(data) | by < 1)) {
      stop("Invalid column indices in by")
    }
  } else if (!all(by %in% names(data))) {
    stop("Specified by columns not found in data")
  }

  if (is.numeric(rows2bind)) {
    if (rows2bind > ncol(data) | rows2bind < 1) {
      stop("Invalid column index in rows2bind")
    }
  } else if (!rows2bind %in% names(data)) {
    stop("Specified rows2bind not found in data")
  }

  # Process each column in 'by'
  result_list <- lapply(by, function(x) {
    row_pair_init(
      data = data,
      rows2bind = rows2bind,
      by = x,
      nest_type = nest_type
    )
  })

  # Combine all results using rbindlist
  combined_result <- rbindlist(result_list)

  return(combined_result)
}
row_pair_init <- function (data, rows2bind, by, nest_type = "dt") {
  . <- NULL
  # Convert numeric indices to column names
  if (is.numeric(by)) {
    by <- names(data)[by]
  }
  if (is.numeric(rows2bind)) {
    rows2bind <- names(data)[rows2bind]
  }

  # Get ID columns (all columns except 'by' columns)
  id_cols <- setdiff(names(data), by)

  # Reshape data from wide to long format
  long_dt <- melt(data,
                  id.vars = id_cols,
                  measure.vars = by,
                  variable.name = "name",
                  value.name = "value")

  # Get columns for formula creation
  other_ids <- setdiff(id_cols, rows2bind)

  # Create formula string for dcast
  formula_str <- paste(paste(c("name", other_ids), collapse = " + "),
                       rows2bind, sep = " ~ ")

  # Reshape data from long to wide format
  wide_dt <- dcast(long_dt, as.formula(formula_str), value.var = "value")

  # Create nested output based on nest_type
  if (nest_type == "dt") {
    result <- wide_dt[, .(data = list(.SD)), by = "name"]
  }
  else if (nest_type == "df") {
    result <- wide_dt[, .(data = list(as.data.frame(.SD))),
                      by = "name"]
  }
  else {
    stop("Invalid nest_type provided. It must be either 'dt' or 'df'.")
  }

  return(result)
}
```

```{r example-r2p_nest}
# Example 1: Row-to-pairs nesting with column names
r2p_nest(
  mtcars,                     # Input mtcars dataset
  rows2bind = "cyl",          # Column to be used as row values
  by = c("hp", "drat", "wt")  # Columns to be transformed into pairs
)
# Returns a nested data.table where:
# - name: variable names (hp, drat, wt)
# - data: list column containing data.tables with rows grouped by cyl values

# Example 2: Row-to-pairs nesting with numeric indices
r2p_nest(
  mtcars,                     # Input mtcars dataset
  rows2bind = 2,              # Use 2nd column (cyl) as row values
  by = 4:6                    # Use columns 4-6 (hp, drat, wt) for pairs
)
# Returns a nested data.table where:
# - name: variable names from columns 4-6
# - data: list column containing data.tables with rows grouped by cyl values
```


```{r tests-r2p_nest}
# Basic functionality test
test_that("r2p_nest returns correct structure with mtcars", {
  # Test with basic parameters
  result <- r2p_nest(
    mtcars,
    rows2bind = "cyl",
    by = c("hp", "drat", "wt")
  )
  
  # Check return structure
  expect_true(is.data.table(result))
  expect_true(all(c("name", "data") %in% names(result)))
  expect_equal(ncol(result), 2)
  
  # Check number of groups matches by columns
  expect_equal(nrow(result), 3)  # Should match length of by columns
  expect_equal(sort(unique(as.character(result$name))), sort(c("hp", "drat", "wt")))
  
  # Check nested data structure
  expect_true(all(sapply(result$data, is.data.table)))
  first_nested_dt <- result$data[[1]]
  
  # Check that other columns are preserved in nested data
  expected_cols <- setdiff(names(mtcars), c("hp", "cyl"))
  expect_true(all(expected_cols %in% names(first_nested_dt)))
})

# Test different nest_type options
test_that("r2p_nest handles different nest_type correctly with mtcars", {
  # Test with dt
  result_dt <- r2p_nest(
    mtcars,
    rows2bind = "cyl",
    by = "hp",
    nest_type = "dt"
  )
  expect_true(all(sapply(result_dt$data, is.data.table)))
  
  # Test with df
  result_df <- r2p_nest(
    mtcars,
    rows2bind = "cyl",
    by = "hp",
    nest_type = "df"
  )
  expect_true(all(sapply(result_df$data, is.data.frame)))
  expect_false(any(sapply(result_df$data, is.data.table)))
})

# Test column specification methods
test_that("r2p_nest handles different column specifications correctly with mtcars", {
  # Test with column names
  result_names <- r2p_nest(
    mtcars,
    rows2bind = "cyl",
    by = c("hp", "drat")
  )
  
  # Test with column indices
  mtcars_cols <- names(mtcars)
  hp_index <- which(mtcars_cols == "hp")
  drat_index <- which(mtcars_cols == "drat")
  cyl_index <- which(mtcars_cols == "cyl")
  
  result_indices <- r2p_nest(
    mtcars,
    rows2bind = cyl_index,
    by = c(hp_index, drat_index)
  )
  
  # Results should be identical
  expect_equal(result_names, result_indices)
})

# Error handling tests
test_that("r2p_nest handles invalid inputs correctly with mtcars", {
  # Missing by parameter
  expect_error(r2p_nest(mtcars, rows2bind = "cyl", by = character(0)))
  
  # Invalid rows2bind
  expect_error(r2p_nest(mtcars, rows2bind = c("cyl", "hp"), by = "hp"))
  expect_error(r2p_nest(mtcars, rows2bind = "nonexistent", by = "hp"))
  expect_error(r2p_nest(mtcars, rows2bind = 100, by = "hp"))
  
  # Invalid by parameter
  expect_error(r2p_nest(mtcars, rows2bind = "cyl", by = "nonexistent"))
  expect_error(r2p_nest(mtcars, rows2bind = "cyl", by = 100))
  
  # Invalid nest_type
  expect_error(r2p_nest(mtcars, rows2bind = "cyl", by = "hp", nest_type = "invalid"))
})

# Test data consistency
test_that("r2p_nest maintains data consistency with mtcars", {
  result <- r2p_nest(
    mtcars,
    rows2bind = "cyl",
    by = c("hp", "drat", "wt")
  )
  
  # Check that all by variables are present in names
  expect_true(all(c("hp", "drat", "wt") %in% unique(result$name)))
  
  # Check that nested data contains expected columns
  first_nested_dt <- result$data[[1]]
  expected_cols <- setdiff(names(mtcars), c("hp", "cyl"))
  expect_true(all(expected_cols %in% names(first_nested_dt)))
  
  # Check that row counts are preserved
  expect_equal(nrow(first_nested_dt), nrow(mtcars))
})

# Test multiple by columns
test_that("r2p_nest handles multiple by columns correctly with mtcars", {
  # Test with single by column
  result_single <- r2p_nest(mtcars, rows2bind = "cyl", by = "hp")
  expect_equal(nrow(result_single), 1)
  
  # Test with multiple by columns
  result_multiple <- r2p_nest(mtcars, rows2bind = "cyl", by = c("hp", "drat", "wt"))
  expect_equal(nrow(result_multiple), 3)
  
  # Check that all by columns are represented
  expect_equal(sort(as.character(unique(result_multiple$name))), sort(c("hp", "drat", "wt")))
})
```


# export_nest
    
```{r function-export_nest}
#' Export Nested Data with Advanced Grouping and Flexible Handling
#'
#' @description
#' The `export_list` function exports nested data from a `data.frame` or `data.table` with sophisticated grouping 
#' capabilities, supporting multiple nested column types and flexible file export options.
#'
#' @param nest_dt A `data.frame` or `data.table` containing nested columns of `data.frame`s, 
#'   `data.table`s, or lists to be exported.
#' @param group_cols Optional character vector specifying grouping columns. 
#'   If `NULL`, uses all non-nested columns as grouping variables.
#' @param nest_col Optional character string indicating the nested column to export. 
#'   If `NULL`, automatically selects the first nested column.
#' @param export_path Base directory path for file export. Defaults to a temporary directory 
#'   created by `tempdir()`.
#' @param file_type File export format, either `"txt"` (tab-separated) or `"csv"`. 
#'   Defaults to `"txt"`.
#'
#' @details
#' Comprehensive Nested Data Export Features:
#' \itemize{
#'   \item Automatic detection and handling of different nested column types
#'   \item Flexible grouping strategies with intelligent column selection
#'   \item Hierarchical directory structure generation based on grouping columns
#'   \item Support for mixed nested column types (`data.frame`, `data.table`, `list`)
#'   \item Multi-threaded file writing for enhanced performance
#'   \item Informative messaging and warning system
#' }
#'
#' Nested Column Detection Hierarchy:
#' \enumerate{
#'   \item Prioritizes `data.frame`/`data.table` nested columns
#'   \item Falls back to regular `list` columns if no `data.frame` columns exist
#' }
#'
#' Grouping Column Selection Strategy:
#' \enumerate{
#'   \item When `group_cols` is `NULL`, uses all non-nested columns
#'   \item Provides warnings about unused non-nested columns
#'   \item Validates provided group columns
#' }
#'
#' File Export Characteristics:
#' \itemize{
#'   \item Supports `"txt"` (tab-separated) and `"csv"` formats
#'   \item Uses multi-threading via `parallel::detectCores()`
#'   \item Creates nested directory structure based on grouping variables
#' }
#'
#' @return 
#' An `integer` representing the total number of files exported successfully.
#'
#' @note
#' Key Capabilities:
#' \itemize{
#'   \item Handles complex nested data structures
#'   \item Performs type conversion for nested content
#'   \item Utilizes multi-threaded file export for optimal performance
#'   \item Provides comprehensive column selection feedback
#' }
#'
#' @importFrom data.table as.data.table fwrite
#' @importFrom parallel detectCores
#' @export
export_nest <- function(nest_dt, group_cols = NULL, nest_col = NULL,
                        export_path = tempdir(), file_type = "txt") {
  # Basic input validation
  if (nrow(nest_dt) == 0) {
    stop("The input nest_dt cannot be empty")
  }

  # Check and get nested columns
  # 1. Check for data.frame/data.table nested columns
  df_nested_cols <- names(nest_dt)[sapply(nest_dt, function(x) {
    is.list(x) && all(sapply(x, function(y) {
      inherits(y, c("data.frame", "data.table"))
    }))
  })]

  # 2. Check for regular list columns
  list_cols <- names(nest_dt)[vapply(nest_dt, is.list, logical(1))]

  # Combine both types of nested columns
  nested_cols <- unique(c(df_nested_cols, list_cols))

  if (length(nested_cols) == 0) {
    stop("The input nest_dt must contain at least one nested column")
  }

  # If nest_col is NULL, prioritize using data.frame/data.table nested columns
  if (is.null(nest_col)) {
    if (length(df_nested_cols) > 0) {
      nest_col <- df_nested_cols[1]
      message("Using first nested data.frame/data.table column: ", nest_col)
    } else {
      nest_col <- list_cols[1]
      message("Using first list column: ", nest_col)
    }
  } else if (!nest_col %in% nested_cols) {
    stop("Specified nest_col is not a valid nested column")
  }

  # If group_cols is NULL, use all non-nested columns
  if (is.null(group_cols)) {
    group_cols <- setdiff(names(nest_dt), nested_cols)
    message("Using all non-nested columns as groups: ", paste(group_cols, collapse = ", "))
  } else {
    # Validate user-provided group columns
    if (!is.character(group_cols)) {
      stop("group_cols must be a character vector")
    }
    missing_cols <- setdiff(group_cols, names(nest_dt))
    if (length(missing_cols) > 0) {
      stop("The following group columns are missing: ", paste(missing_cols, collapse = ", "))
    }

    # Check if all non-nested columns are used as group columns
    all_non_nested_cols <- setdiff(names(nest_dt), nested_cols)
    unused_cols <- setdiff(all_non_nested_cols, group_cols)
    if (length(unused_cols) > 0) {
      warning("Not all non-nested columns are used as group columns. ",
              "The exported data may be incomplete without the following columns: ",
              paste(unused_cols, collapse = ", "))
    }
  }

  # Parameter validation
  file_type <- tolower(file_type)
  if (!(file_type %in% c("txt", "csv"))) {
    stop("file_type must be either 'txt' or 'csv'")
  }

  if (!is.character(export_path) || length(export_path) != 1) {
    stop("export_path must be a single character string")
  }

  # Create export directory
  dir.create(export_path, showWarnings = FALSE, recursive = TRUE)

  # Export processing
  tryCatch({
    # Process and expand nested data
    expanded_dt <- nest_dt[, {
      processed_nests <- lapply(get(nest_col), function(x) {
        if (inherits(x, c("data.frame", "data.table"))) {
          x_dt <- if (!is.data.table(x)) as.data.table(x) else x
          setattr(x_dt, "row.names", .set_row_names(nrow(x_dt)))
          return(x_dt)
        } else {
          # Try to convert non-data.frame/data.table to data.table
          tryCatch({
            x_dt <- as.data.table(as.list(x))
            setattr(x_dt, "row.names", .set_row_names(nrow(x_dt)))
            return(x_dt)
          }, error = function(e) {
            stop(sprintf("Cannot convert nested content to data.table: %s", e$message))
          })
        }
      })
      data.table::rbindlist(processed_nests, fill = TRUE)
    }, by = group_cols]

    expanded_dt <- copy(expanded_dt)

    # Create required subdirectories
    unique_paths <- unique(expanded_dt[, do.call(file.path,
                                                 c(list(export_path), lapply(group_cols, function(col) get(col))))])
    lapply(unique_paths, dir.create, showWarnings = FALSE, recursive = TRUE)

    # Export files
    file_count <- 0L
    expanded_dt[, {
      dir_path <- do.call(file.path, c(list(export_path),
                                       lapply(group_cols, function(col) get(col))))
      sep <- if (file_type == "txt") "\t" else ","
      filename <- paste0(nest_col, ".", file_type)
      fwrite(.SD, file = file.path(dir_path, filename),
             sep = sep, nThread = parallel::detectCores() - 1, buffMB = 32)
      file_count <<- file_count + 1L
      NULL
    }, by = group_cols]

    return(file_count)
  }, error = function(e) {
    stop("Failed to export nested data: ", e$message)
  })
}
```
  
```{r example-export_nest}
# Example 1: Basic nested data export workflow
# Step 1: Create nested data structure
dt_nest <- w2l_nest(
  data = iris,              # Input iris dataset
  cols2l = 1:2,             # Columns to be nested
  by = "Species"            # Grouping variable
)

# Step 2: Export nested data to files
export_nest(
  nest_dt = dt_nest,        # Input nested data.table
  nest_col = "data",        # Column containing nested data
  group_cols = c("name", "Species")  # Columns to create directory structure
)
# Returns the number of files created
# Creates directory structure: tempdir()/name/Species/data.txt

# Check exported files
list.files(
  path = tempdir(),         # Default export directory
  pattern = "txt",          # File type pattern to search
  recursive = TRUE          # Search in subdirectories
)
# Returns list of created files and their paths

# Clean up exported files
files <- list.files(
  path = tempdir(),         # Default export directory
  pattern = "txt",          # File type pattern to search
  recursive = TRUE,         # Search in subdirectories
  full.names = TRUE         # Return full file paths
)
file.remove(files)          # Remove all exported files
```


```{r tests-export_nest}
# Test basic functionality
test_that("export_nest basic functionality works", {
  # Create sample nested data
  dt <- data.table(
    group = c("A", "B"),
    name = c("test1", "test2"),
    data = list(
      data.table(x = 1:3, y = letters[1:3]),
      data.table(x = 4:6, y = letters[4:6])
    )
  )
  
  # Create temporary directory for testing
  temp_dir <- file.path(tempdir(), "export_test")
  
  # Test basic export
  file_count <- export_nest(dt, 
                            group_cols = c("group", "name"), 
                            nest_col = "data",
                            export_path = temp_dir)
  
  # Check return value
  expect_equal(file_count, 2)
  
  # Check if files were created
  expect_true(dir.exists(file.path(temp_dir, "A", "test1")))
  expect_true(dir.exists(file.path(temp_dir, "B", "test2")))
  expect_true(file.exists(file.path(temp_dir, "A", "test1", "data.txt")))
  expect_true(file.exists(file.path(temp_dir, "B", "test2", "data.txt")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test file type handling
test_that("export_nest handles different file types", {
  dt <- data.table(
    group = "A",
    data = list(data.table(x = 1:3))
  )
  
  temp_dir <- file.path(tempdir(), "export_test_types")
  
  # Test txt export
  export_nest(dt, file_type = "txt", export_path = temp_dir)
  expect_true(file.exists(file.path(temp_dir, "A", "data.txt")))
  
  # Test csv export
  export_nest(dt, file_type = "csv", export_path = temp_dir)
  expect_true(file.exists(file.path(temp_dir, "A", "data.csv")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test automatic group_cols detection handling
test_that("export_nest handles automatic group_cols detection", {
  dt <- data.table(
    group = "A",
    name = "test",
    data = list(data.table(x = 1:3))
  )
  
  temp_dir <- file.path(tempdir(), "export_test_auto")
  
  # Test without specifying group_cols
  expect_message(
    export_nest(dt, nest_col = "data", export_path = temp_dir),
    "Using all non-nested columns as groups"
  )
  
  expect_true(dir.exists(file.path(temp_dir, "A", "test")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test automatic nest_col detection handling
test_that("export_nest handles automatic nest_col detection", {
  dt <- data.table(
    group = "A",
    data = list(data.table(x = 1:3))
  )
  
  temp_dir <- file.path(tempdir(), "export_test_auto_nest")
  
  # Test without specifying nest_col
  expect_message(
    export_nest(dt, export_path = temp_dir),
    "Using first nested data.frame/data.table column"
  )
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test error handling
test_that("export_nest handles errors appropriately", {
  # Test empty input
  expect_error(
    export_nest(data.table()),
    "The input nest_dt cannot be empty"
  )
  
  # Test no nested columns
  expect_error(
    export_nest(data.table(a = 1)),
    "The input nest_dt must contain at least one nested column"
  )
  
  # Test invalid nest_col
  dt <- data.table(
    group = "A",
    data = list(data.table(x = 1:3))
  )
  expect_error(
    export_nest(dt, nest_col = "invalid"),
    "Specified nest_col is not a valid nested column"
  )
  
  # Test invalid file_type
  expect_error(
    export_nest(dt, file_type = "invalid"),
    "file_type must be either 'txt' or 'csv'"
  )
  
  # Test invalid group_cols
  expect_error(
    export_nest(dt, group_cols = "invalid"),
    "The following group columns are missing: invalid"
  )
})

# Test complex nested structures handling
test_that("export_nest handles complex nested structures", {
  # Create nested data with mixed types
  dt <- data.table(
    group = c("A", "B"),
    list_col = list(
      list(x = 1, y = "a"),
      list(x = 2, y = "b")
    ),
    df_col = list(
      data.frame(x = 1:2, y = letters[1:2]),
      data.frame(x = 3:4, y = letters[3:4])
    )
  )
  
  temp_dir <- file.path(tempdir(), "export_test_complex")
  
  # Test export with list column
  expect_message(
    export_nest(dt, nest_col = "list_col", export_path = temp_dir),
    "Using all non-nested columns as groups"
  )
  
  # Test export with data.frame column
  expect_message(
    export_nest(dt, nest_col = "df_col", export_path = temp_dir),
    "Using all non-nested columns as groups"
  )
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test warn handling
test_that("export_nest warns about unused columns", {
  dt <- data.table(
    group1 = "A",
    group2 = "B",
    unused = "C",
    data = list(data.table(x = 1:3))
  )
  
  temp_dir <- file.path(tempdir(), "export_test_warning")
  
  # Test warning about unused columns
  expect_warning(
    export_nest(dt, group_cols = c("group1", "group2"), export_path = temp_dir),
    "Not all non-nested columns are used as group columns"
  )
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})
```

# export_list
    
```{r function-export_list}
#' Export List with Advanced Directory Management
#'
#' @description
#' The `export_list` function exports a list of `data.frame`, `data.table`, or compatible data structures 
#' with sophisticated directory handling, flexible naming, and multiple file format support.
#'
#' @param split_dt A `list` of `data.frame`, `data.table`, or compatible data structures 
#'   to be exported.
#' @param export_path Base directory path for file export. Defaults to a temporary directory 
#'   created by `tempdir()`.
#' @param file_type File export format, either `"txt"` (tab-separated) or `"csv"`. 
#'   Defaults to `"txt"`.
#'
#' @details
#' Comprehensive List Export Features:
#' \itemize{
#'   \item Advanced nested directory structure support based on list element names
#'   \item Intelligent handling of unnamed list elements
#'   \item Automatic conversion to `data.table` for consistent export
#'   \item Hierarchical directory creation with nested path names
#'   \item Multi-format file export with intelligent separator selection
#'   \item Robust error handling and input validation
#' }
#'
#' File Export Capabilities:
#' \itemize{
#'   \item Supports `"txt"` (tab-separated) and `"csv"` formats
#'   \item Intelligent file naming based on list element names
#'   \item Handles complex nested directory structures
#'   \item Efficient file writing using `data.table::fwrite()`
#' }
#'
#' @return 
#' An `integer` representing the total number of files exported successfully.
#'
#' @note
#' Key Capabilities:
#' \itemize{
#'   \item Flexible list naming and directory management
#'   \item Comprehensive support for `data.frame` and `data.table` inputs
#'   \item Intelligent default naming for unnamed elements
#'   \item High-performance file writing mechanism
#' }
#'
#' @importFrom data.table fwrite as.data.table
#' @importFrom utils head tail
#' @export

export_list <- function(split_dt, export_path = tempdir(), file_type = "txt") {
  # Input validation
  if (!is.list(split_dt)) {
    stop("split_dt must be a list of data.tables/data.frames")
  }

  file_type <- match.arg(file_type, c("txt", "csv"))

  # Define separator mapping for file types
  sep_map <- c(txt = "\t", csv = ",")

  # Create base export directory if it doesn't exist
  dir.create(export_path, recursive = TRUE, showWarnings = FALSE)

  # Initialize counter
  count <- 0L

  # Process each element in the list
  exported_files <- vapply(seq_along(split_dt), function(i) {
    current_data <- split_dt[[i]]
    current_name <- names(split_dt)[i]

    current_name <- if (is.null(current_name) || current_name == "") {
      paste0("split_", i)
    } else {
      current_name
    }

    # Handle path components
    if (grepl("/", current_name)) {
      path_components <- strsplit(current_name, "/")[[1]]
      file_name <- tail(path_components, 1)
      sub_dirs <- head(path_components, -1)

      full_path <- file.path(export_path, paste(sub_dirs, collapse = "/"))
      dir.create(full_path, recursive = TRUE, showWarnings = FALSE)
    } else {
      file_name <- current_name
      full_path <- export_path
    }

    file_path <- file.path(full_path, paste0(file_name, ".", file_type))

    if (!data.table::is.data.table(current_data)) {
      current_data <- data.table::as.data.table(current_data)
    }

    data.table::fwrite(current_data,
                       file = file_path,
                       sep = sep_map[file_type],
                       quote = TRUE)

    # Increment counter
    count <<- count + 1L

    file_path
  }, character(1))

  names(exported_files) <- names(split_dt)

  # Return count
  return(count)

  invisible(exported_files)
}
```
  
```{r example-export_list}
# Example: Export split data to files

# Step 1: Create split data structure
dt_split <- w2l_split(
  data = iris,              # Input iris dataset
  cols2l = 1:2,             # Columns to be split
  by = "Species"            # Grouping variable
)

# Step 2: Export split data to files
export_list(
  split_dt = dt_split       # Input list of data.tables
)
# Returns the number of files created
# Files are saved in tempdir() with .txt extension

# Check exported files
list.files(
  path = tempdir(),         # Default export directory
  pattern = "txt",          # File type pattern to search
  recursive = TRUE          # Search in subdirectories
)

# Clean up exported files
files <- list.files(
  path = tempdir(),         # Default export directory
  pattern = "txt",          # File type pattern to search
  recursive = TRUE,         # Search in subdirectories
  full.names = TRUE         # Return full file paths
)
file.remove(files)          # Remove all exported files
```


```{r tests-export_list}
# Test basic functionality
test_that("export_list basic functionality works", {
  # Create sample data
  dt1 <- data.table(x = 1:3, y = letters[1:3])
  dt2 <- data.table(a = 4:6, b = letters[4:6])
  test_list <- list(data1 = dt1, data2 = dt2)
  
  # Create temporary directory for testing
  temp_dir <- file.path(tempdir(), "export_list_test")
  
  # Test basic export
  file_count <- export_list(test_list, export_path = temp_dir)
  
  # Check return value
  expect_equal(file_count, 2)
  
  # Check if files were created
  expect_true(file.exists(file.path(temp_dir, "data1.txt")))
  expect_true(file.exists(file.path(temp_dir, "data2.txt")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test file type handling
test_that("export_list handles different file types", {
  dt <- data.table(x = 1:3, y = letters[1:3])
  test_list <- list(data = dt)
  
  temp_dir <- file.path(tempdir(), "export_list_types")
  
  # Test txt export
  export_list(test_list, export_path = temp_dir, file_type = "txt")
  expect_true(file.exists(file.path(temp_dir, "data.txt")))
  
  # Test csv export
  export_list(test_list, export_path = temp_dir, file_type = "csv")
  expect_true(file.exists(file.path(temp_dir, "data.csv")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test nested directory structure
test_that("export_list handles nested directory paths", {
  dt <- data.table(x = 1:3)
  test_list <- list("dir1/dir2/data" = dt)
  
  temp_dir <- file.path(tempdir(), "export_list_nested")
  
  file_count <- export_list(test_list, export_path = temp_dir)
  
  expect_equal(file_count, 1)
  expect_true(dir.exists(file.path(temp_dir, "dir1", "dir2")))
  expect_true(file.exists(file.path(temp_dir, "dir1", "dir2", "data.txt")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test unnamed list elements
test_that("export_list handles unnamed list elements", {
  dt1 <- data.table(x = 1:3)
  dt2 <- data.table(y = 4:6)
  test_list <- list(dt1, dt2)
  
  temp_dir <- file.path(tempdir(), "export_list_unnamed")
  
  file_count <- export_list(test_list, export_path = temp_dir)
  
  expect_equal(file_count, 2)
  expect_true(file.exists(file.path(temp_dir, "split_1.txt")))
  expect_true(file.exists(file.path(temp_dir, "split_2.txt")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test error handling
test_that("export_list handles errors appropriately", {
  # Test invalid input type
  expect_error(
    export_list("not_a_list"),
    "split_dt must be a list of data.tables/data.frames"
  )
  
  # Test invalid file type
  dt <- data.table(x = 1:3)
  test_list <- list(data = dt)
  expect_error(
    export_list(test_list, file_type = "invalid"),
    "should be one of"
  )
})

# Test data frame conversion
test_that("export_list handles data.frame conversion", {
  df <- data.frame(x = 1:3, y = letters[1:3])
  test_list <- list(data = df)
  
  temp_dir <- file.path(tempdir(), "export_list_df")
  
  file_count <- export_list(test_list, export_path = temp_dir)
  
  expect_equal(file_count, 1)
  expect_true(file.exists(file.path(temp_dir, "data.txt")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test empty list handling
test_that("export_list handles empty list", {
  test_list <- list()
  
  temp_dir <- file.path(tempdir(), "export_list_empty")
  
  file_count <- export_list(test_list, export_path = temp_dir)
  
  expect_equal(file_count, 0)
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

# Test mixed content in list
test_that("export_list handles mixed content types", {
  dt <- data.table(x = 1:3)
  df <- data.frame(y = 4:6)
  test_list <- list(dt_data = dt, df_data = df)
  
  temp_dir <- file.path(tempdir(), "export_list_mixed")
  
  file_count <- export_list(test_list, export_path = temp_dir)
  
  expect_equal(file_count, 2)
  expect_true(file.exists(file.path(temp_dir, "dt_data.txt")))
  expect_true(file.exists(file.path(temp_dir, "df_data.txt")))
  
  # Clean up
  unlink(temp_dir, recursive = TRUE)
})

```


# fires
    
```{r function-fires}
#' Update Fire Dataset with Current Date
#'
#' @description
#' The `fires` function creates a copy of the fire dataset and adjusts the dates 
#' to align with the current date while maintaining the original date patterns.
#'
#' @details
#' The function performs the following operations:
#' \itemize{
#'   \item Creates a copy of the fire dataset from the mintyr package
#'   \item Calculates the number of days between the last recorded date and the previous day
#'   \item Shifts all dates forward by the calculated number of days
#'   \item Converts the updated dates back to character format
#' }
#'
#' @return A data.table with updated dates, shifted to the current date
#'
#' @note
#' - Requires the `data.table` and `mintyr` packages
#' - Uses the current system date as a reference for date shifting
#' - Maintains the original structure of the date column
#'
#' @importFrom data.table copy
#' @export
fires <- function() {
  Date <- NULL
  data <- data.table::copy(mintyr::fire)
  days_diff <- Sys.Date() - 1 - max(unique(as.Date(data$Date)))
  data[, Date := as.Date(Date)
  ][, `:=`(Date, as.Date(Date) + days_diff)
  ][, Date := as.character(Date)][]
}

```
  
```{r example-fires}
head(fires())
```
  

# nedaps
    
```{r function-nedaps}
#' Update Nedap Dataset with Current Date
#'
#' @description
#' The `nedaps` function creates a copy of the Nedap dataset and adjusts the visit times 
#' to align with the current date while maintaining the original time patterns.
#'
#' @details
#' The function performs the following operations:
#' \itemize{
#'   \item Creates a copy of the Nedap dataset from the mintyr package
#'   \item Calculates the number of days between the last recorded visit and the previous day
#'   \item Shifts all visit times forward by the calculated number of days
#'   \item Preserves the original time patterns of the visits
#' }
#'
#' @return A `data.table` with updated visit times, shifted to the current date
#'
#' @note
#' - Requires the `data.table` and `mintyr` packages
#' - Uses the current system date as a reference for date shifting
#' - Maintains the original time of day for each visit
#'
#' @importFrom data.table copy IDateTime
#' @export
nedaps <- function() {
  visit_time <- time <- NULL
  data <- data.table::copy(mintyr::nedap)
  days_diff <- Sys.Date() - 1 - max(unique(as.Date(data$visit_time)))
  data[, `:=`(c("date", "time"), data.table::IDateTime(visit_time))
  ][, `:=`(date, as.Date(date) + days_diff)
  ][, visit_time := as.POSIXct(paste(date, time), format="%Y-%m-%d %H:%M:%S")
  ][, c("date", "time") := NULL][]
}

```
  
```{r example-nedaps}
head(nedaps())
```


# convert_nest
    
```{r function-convert_nest}
#' Convert Nested Columns Between `data.frame` and `data.table`
#'
#' @description
#' The `convert_nest` function transforms a `data.frame` or `data.table` by converting nested columns 
#' to either `data.frame` or `data.table` format while preserving the original data structure.
#'
#' @param data A `data.frame` or `data.table` containing nested columns
#' @param to A `character` string specifying the target format. 
#'   Options are `"df"` (data frame) or `"dt"` (data table). Defaults to `"df"`.
#' @param nest_cols A `character` vector of column names containing nested data. 
#'   If `NULL`, the function automatically detects list columns.
#'
#' @details
#' Advanced Nested Column Conversion Features:
#' \itemize{
#'   \item Intelligent automatic detection of nested columns
#'   \item Comprehensive conversion of entire data structure
#'   \item Selective conversion of specified nested columns
#'   \item Non-destructive transformation with data copying
#' }
#' 
#' Input Validation and Error Handling:
#' \itemize{
#'   \item Validates existence of specified nested columns
#'   \item Verifies that specified columns are actually list columns
#'   \item Provides informative error messages for invalid inputs
#'   \item Ensures data integrity through comprehensive checks
#' }
#' 
#' Conversion Strategies:
#' \enumerate{
#'   \item Nested column identification based on `is.list()` detection
#'   \item Preservation of original data integrity
#'   \item Flexible handling of mixed data structures
#'   \item Consistent type conversion across nested elements
#' }
#'
#' Nested Column Handling:
#' \itemize{
#'   \item Supports conversion of `list` columns
#'   \item Handles `data.table`, `data.frame`, and generic `list` inputs
#'   \item Maintains original column structure and order
#'   \item Prevents in-place modification of source data
#' }
#'
#' @return 
#' A transformed `data.frame` or `data.table` with nested columns converted to the specified format.
#'
#' @note
#' Conversion Characteristics:
#' \itemize{
#'   \item Non-destructive transformation of nested columns
#'   \item Supports flexible input and output formats
#'   \item Intelligent type detection and conversion
#'   \item Minimal performance overhead
#' }
#'
#' Error Conditions:
#' \itemize{
#'   \item Throws error if specified columns don't exist in the input data
#'   \item Throws error if specified columns are not list columns
#'   \item Provides clear error messages for troubleshooting
#'   \item Validates input parameters before processing
#' }
#'
#' @importFrom data.table as.data.table copy
#' @importFrom tibble as_tibble
#' 
#' @export
convert_nest <- function(data, to = c("df", "dt"), nest_cols = NULL) {
  to <- match.arg(to)
  
  # Automatically detect nested columns (list columns) if not specified
  if (is.null(nest_cols)) {
    nest_cols <- names(data)[sapply(data, is.list)]
  }
  # Validate nest_cols
  invalid_cols <- setdiff(nest_cols, names(data))
  if (length(invalid_cols) > 0) {
    stop("Column(s) not found in data: ", paste(invalid_cols, collapse = ", "))
  }
  
  # Check if specified columns are actually list columns
  non_list_cols <- nest_cols[!sapply(data[, nest_cols, with = FALSE], is.list)]
  if (length(non_list_cols) > 0) {
    stop("Column(s) are not nested (list) columns: ", paste(non_list_cols, collapse = ", "))
  }
  
  if (to == "df") {
    # If data is data.table, convert to data.frame and copy to avoid modifying original data
    if (inherits(data, "data.table")) {
      data <- as_tibble(copy(data))
    } else if (!inherits(data, "data.frame")) {
      data <- as_tibble(data)
    }
    # Convert each element of nested columns to data.frame
    for (col in nest_cols) {
      data[[col]] <- lapply(data[[col]], function(x) {
        if (inherits(x, "data.table")) {
          as_tibble(copy(x))
        } else if (!inherits(x, "data.frame")) {
          as_tibble(x)
        } else {
          x
        }
      })
    }
  } else if (to == "dt") {
    # If data is not data.table, convert to data.table and copy to avoid modifying original data
    if (!inherits(data, "data.table")) {
      data <- as.data.table(copy(data))
    }
    # Convert each element of nested columns to data.table
    for (col in nest_cols) {
      data[[col]] <- lapply(data[[col]], function(x) {
        if (!inherits(x, "data.table")) {
          as.data.table(copy(x))
        } else {
          x
        }
      })
    }
  }
  
  return(data)
}
```
  
```{r example-convert_nest}
# Example 1: Create nested data structures
# Create single nested column
df_nest1 <- iris |> 
  dplyr::group_nest(Species)     # Group and nest by Species

# Create multiple nested columns
df_nest2 <- iris |>
  dplyr::group_nest(Species) |>  # Group and nest by Species
  dplyr::mutate(
    data2 = purrr::map(          # Create second nested column
      data,
      dplyr::mutate, 
      c = 2
    )
  )

# Example 2: Convert nested structures
# Convert data frame to data table
convert_nest(
  df_nest1,                      # Input nested data frame
  to = "dt"                      # Convert to data.table
)

# Convert specific nested columns
convert_nest(
  df_nest2,                      # Input nested data frame
  to = "dt",                     # Convert to data.table
  nest_cols = "data"             # Only convert 'data' column
)

# Example 3: Convert data table to data frame
dt_nest <- mintyr::w2l_nest(
  data = iris,                   # Input dataset
  cols2l = 1:2                   # Columns to nest
)
convert_nest(
  dt_nest,                       # Input nested data table
  to = "df"                      # Convert to data frame
)
```


```{r tests-convert_nest}
# Test basic functionality for data.frame conversion
test_that("convert_nest converts basic nested structures to data.frame", {
  # Create test data
  nested_dt <- data.table(
    id = 1:2,
    nested = list(
      data.table(x = 1:3, y = letters[1:3]),
      data.table(x = 4:6, y = letters[4:6])
    )
  )
  
  # Convert to data.frame
  result <- convert_nest(nested_dt, to = "df")
  
  # Check overall structure
  expect_true(inherits(result, "tbl_df"))
  expect_false(inherits(result, "data.table"))
  
  # Check nested elements
  expect_true(all(sapply(result$nested, inherits, "tbl_df")))
  expect_false(any(sapply(result$nested, inherits, "data.table")))
})

# Test basic functionality for data.table conversion
test_that("convert_nest converts basic nested structures to data.table", {
  # Create test data
  nested_df <- tibble::tibble(
    id = 1:2,
    nested = list(
      tibble::tibble(x = 1:3, y = letters[1:3]),
      tibble::tibble(x = 4:6, y = letters[4:6])
    )
  )
  
  # Convert to data.table
  result <- convert_nest(nested_df, to = "dt")
  
  # Check overall structure
  expect_true(inherits(result, "data.table"))
  
  # Check nested elements
  expect_true(all(sapply(result$nested, inherits, "data.table")))
})

# Test automatic nested column detection
test_that("convert_nest automatically detects nested columns", {
  # Create test data with multiple nested columns
  test_data <- data.table(
    id = 1:2,
    nested1 = list(data.table(a = 1), data.table(a = 2)),
    normal = 1:2,
    nested2 = list(data.table(b = 1), data.table(b = 2))
  )
  
  result <- convert_nest(test_data, to = "df")
  
  # Check that both nested columns were converted
  expect_true(all(sapply(result$nested1, inherits, "tbl_df")))
  expect_true(all(sapply(result$nested2, inherits, "tbl_df")))
  expect_true(is.numeric(result$normal))  # Non-nested column should remain unchanged
})

# Test specified nested columns
test_that("convert_nest handles specified nested columns", {
  test_data <- data.table(
    id = 1:2,
    nested1 = list(data.table(a = 1), data.table(a = 2)),
    nested2 = list(data.table(b = 1), data.table(b = 2))
  )
  
  # Only convert nested1
  result <- convert_nest(test_data, to = "df", nest_cols = "nested1")
  
  expect_true(all(sapply(result$nested1, inherits, "tbl_df")))
  expect_true(all(sapply(result$nested2, inherits, "data.table")))
})

# Test handling of empty nested columns
test_that("convert_nest handles empty nested columns", {
  test_data <- data.table(
    id = 1:2,
    nested = list(data.table(), data.table())
  )
  
  result <- convert_nest(test_data, to = "df")
  
  expect_true(all(sapply(result$nested, inherits, "tbl_df")))
  expect_true(all(sapply(result$nested, nrow) == 0))
})

# Test data copying
test_that("convert_nest creates copies and doesn't modify original data", {
  # Create test data
  original_dt <- data.table(
    id = 1:2,
    nested = list(
      data.table(x = 1:3),
      data.table(x = 4:6)
    )
  )
  
  # Make a copy for comparison
  original_copy <- copy(original_dt)
  
  # Convert to data.frame
  result <- convert_nest(original_dt, to = "df")
  
  # Check that original data wasn't modified
  expect_equal(original_dt, original_copy)
})

# Test error handling x
test_that("convert_nest handles invalid inputs appropriately", {
  nested_dt <- data.table(
    id = 1:2,
    nested = list(
      data.table(x = 1:3, y = letters[1:3]),
      data.table(x = 4:6, y = letters[4:6])
    )
  )
  
  # Test invalid 'to' parameter
  expect_error(
    convert_nest(nested_dt, to = "invalid"),
    "should be one of"
  )
  
  # Test invalid nest_cols
  expect_error(
    convert_nest(nested_dt, to = "df", nest_cols = "nonexistent"),
    "Column\\(s\\) not found in data: nonexistent"
  )
})

```



# get_path_segment
    
```{r function-get_path_segment}
#' Extract Specific Segments from File Paths
#'
#' @description
#' The `get_path_segment` function extracts specific segments from file paths provided as character strings. Segments can be extracted from either the beginning or the end of the path, depending on the value of `n`.
#'
#' @param paths A 'character vector' containing file system paths
#'   - Must be non-empty
#'   - Path segments separated by forward slash `'/'`
#'   - Supports absolute and relative paths
#'   - Handles cross-platform path representations
#'   - Supports paths with mixed separators (`'\\'` and `'/'`)
#'
#' @param n Numeric index for segment selection
#'   - Positive values: Select from path start
#'   - Negative values: Select from path end
#'   - Supports single index or range extraction
#'   - Cannot be `0`
#'   - Default is `1` (first segment)
#'
#' @details
#' Sophisticated Path Segment Extraction Mechanism:
#' \enumerate{
#'   \item Comprehensive input validation
#'   \item Path normalization and preprocessing
#'   \item Robust cross-platform path segmentation
#'   \item Flexible indexing with forward and backward navigation
#'   \item Intelligent segment retrieval
#'   \item Graceful handling of edge cases
#' }
#'
#' Indexing Behavior:
#' \itemize{
#'   \item Positive `n`: Forward indexing from path start
#'     - `n = 1`: First segment
#'     - `n = 2`: Second segment
#'   \item Negative `n`: Reverse indexing from path end
#'     - `n = -1`: Last segment
#'     - `n = -2`: Second-to-last segment
#'   \item Range extraction: Supports `c(start, end)` index specification
#' }
#'
#' Path Parsing Characteristics:
#' \itemize{
#'   \item Standardizes path separators to `'/'`
#'   \item Removes drive letters (e.g., `'C:'`)
#'   \item Ignores consecutive `'/'` delimiters
#'   \item Removes leading and trailing separators
#'   \item Returns `NA_character_` for non-existent segments
#'   \item Supports complex path structures
#' }
#'
#' @return 'character vector' with extracted path segments
#'   - Matching segments for valid indices
#'   - `NA_character_` for segments beyond path length
#'
#' @note Critical Operational Constraints:
#' \itemize{
#'   \item Requires non-empty 'paths' input
#'   \item `n` must be non-zero numeric value
#'   \item Supports cross-platform path representations
#'   \item Minimal computational overhead
#'   \item Preserves path segment order
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`tools::file_path_sans_ext()`] File extension manipulation
#' }
#'
#' @export
get_path_segment <- function(paths, n = 1) {
  # Input validation for 'paths' parameter
  if (missing(paths)) stop("Parameter 'paths' cannot be empty")
  if (!is.character(paths)) stop("'paths' must be character")
  if (length(paths) == 0) return(character(0))
  
  # Input validation for 'n' parameter
  if (!is.numeric(n)) stop("'n' must be numeric")
  if (length(n) > 2) stop("'n' must be a single number or a vector of length 2")
  if (any(n == 0)) stop("'n' cannot contain 0")
  
  # Preprocessing: Standardize path separators
  # 1. Replace all '\' and '//' with single '/'
  paths <- gsub("\\\\|//", "/", paths)
  
  # 2. Handle multiple consecutive separators
  paths <- gsub("/+", "/", paths)
  
  # 3. Remove leading and trailing separators
  paths <- gsub("^/+|/+$", "", paths)
  
  # 4. Remove drive letters (e.g., C:)
  paths <- sub("^[A-Za-z]:/", "", paths)
  
  # Split paths into segments
  segments <- strsplit(paths, "/")
  
  # Segment extraction logic
  if (length(n) == 1) {
    result <- sapply(segments, function(x) {
      if (n > 0) {
        # Forward indexing
        if (length(x) >= n) x[n] else NA_character_
      } else {
        # Backward indexing
        pos <- length(x) + n + 1
        if (pos > 0 && pos <= length(x)) x[pos] else NA_character_
      }
    })
  } else {
    # Range extraction
    result <- sapply(segments, function(x) {
      # Convert negative indices
      pos1 <- if (n[1] > 0) n[1] else length(x) + n[1] + 1
      pos2 <- if (n[2] > 0) n[2] else length(x) + n[2] + 1
      
      # Ensure pos1 is not greater than pos2
      if (pos1 > pos2) {
        tmp <- pos1
        pos1 <- pos2
        pos2 <- tmp
      }
      
      # Check position validity and extract range
      if (pos1 > 0 && pos2 <= length(x)) {
        paste(x[pos1:pos2], collapse = "/")
      } else {
        NA_character_
      }
    })
  }
  
  return(result)
}
```
  
```{r example-get_path_segment}
# Example: Path segment extraction demonstrations

# Setup test paths
paths <- c(
  "C:/home/user/documents",   # Windows style path
  "/var/log/system",          # Unix system path
  "/usr/local/bin"            # Unix binary path
)

# Example 1: Extract first segment
get_path_segment(
  paths,                      # Input paths
  1                           # Get first segment
)
# Returns: c("home", "var", "usr")

# Example 2: Extract second-to-last segment
get_path_segment(
  paths,                      # Input paths
  -2                          # Get second-to-last segment
)
# Returns: c("user", "log", "local")

# Example 3: Extract from first to last segment
get_path_segment(
  paths,                      # Input paths
  c(1,-1)                     # Range from first to last
)
# Returns full paths without drive letters

# Example 4: Extract first three segments
get_path_segment(
  paths,                      # Input paths
  c(1,3)                      # Range from first to third
)
# Returns: c("home/user/documents", "var/log/system", "usr/local/bin")

# Example 5: Extract last two segments (reverse order)
get_path_segment(
  paths,                      # Input paths
  c(-1,-2)                    # Range from last to second-to-last
)
# Returns: c("documents/user", "system/log", "bin/local")

# Example 6: Extract first two segments
get_path_segment(
  paths,                      # Input paths
  c(1,2)                      # Range from first to second
)
# Returns: c("home/user", "var/log", "usr/local")
```

```{r tests-get_path_segment}
# Test basic path segment extraction
test_that("get_path_segment handles basic path extraction correctly", {
  # Test basic forward indexing
  paths <- c("a/b/c", "x/y/z")
  expect_equal(get_path_segment(paths, 1), c("a", "x"))
  expect_equal(get_path_segment(paths, 2), c("b", "y"))
  expect_equal(get_path_segment(paths, 3), c("c", "z"))
  
  # Test backward indexing
  expect_equal(get_path_segment(paths, -1), c("c", "z"))
  expect_equal(get_path_segment(paths, -2), c("b", "y"))
  expect_equal(get_path_segment(paths, -3), c("a", "x"))
})

# Test range extraction functionality
test_that("get_path_segment handles range extraction", {
  paths <- c("a/b/c/d", "w/x/y/z")
  expect_equal(get_path_segment(paths, c(1, 2)), c("a/b", "w/x"))
  expect_equal(get_path_segment(paths, c(2, 3)), c("b/c", "x/y"))
  expect_equal(get_path_segment(paths, c(-2, -1)), c("c/d", "y/z"))
  expect_equal(get_path_segment(paths, c(-3, -1)), c("b/c/d", "x/y/z"))
  
  # Test reversed range
  expect_equal(get_path_segment(paths, c(3, 1)), c("a/b/c", "w/x/y"))
})

# Test path normalization features
test_that("get_path_segment handles path normalization", {
  # Test Windows-style paths
  expect_equal(get_path_segment("C:\\foo\\bar\\baz", 2), "bar")
  
  # Test paths with multiple separators
  expect_equal(get_path_segment("a//b///c", 2), "b")
  
  # Test paths with leading/trailing separators
  expect_equal(get_path_segment("/a/b/c/", 2), "b")
  
  # Test mixed separators
  expect_equal(get_path_segment("a\\b/c//d", c(2, 3)), "b/c")
})

# Test edge cases and boundary conditions
test_that("get_path_segment handles edge cases", {
  # Test empty paths vector
  expect_equal(get_path_segment(character(0)), character(0))
  
  # Test single segment paths
  expect_equal(get_path_segment("foo", 1), "foo")
  expect_equal(get_path_segment("foo", 2), NA_character_)
  
  # Test out of range indices
  paths <- "a/b/c"
  expect_equal(get_path_segment(paths, 4), NA_character_)
  expect_equal(get_path_segment(paths, -4), NA_character_)
  expect_equal(get_path_segment(paths, c(1, 4)), NA_character_)
})

# Test input validation
test_that("get_path_segment validates inputs correctly", {
  # Test missing paths parameter
  expect_error(get_path_segment(), "Parameter 'paths' cannot be empty")
  
  # Test non-character paths
  expect_error(get_path_segment(1:3), "'paths' must be character")
  
  # Test invalid n parameter
  expect_error(get_path_segment("a/b/c", "1"), "'n' must be numeric")
  expect_error(get_path_segment("a/b/c", c(1,2,3)), "'n' must be a single number or a vector of length 2")
  expect_error(get_path_segment("a/b/c", 0), "'n' cannot contain 0")
})

# Test special path formats
test_that("get_path_segment handles special cases", {
  # Test paths with spaces
  expect_equal(get_path_segment("path with/spaces in/file name", 2), "spaces in")
  
  # Test paths with special characters
  expect_equal(get_path_segment("path.with/special-chars/file_name", 2), "special-chars")
  
  # Test empty segments
  expect_equal(get_path_segment("a//b", 2), "b")
})
```


# format_digits
    
```{r function-format_digits}
#' Format Numeric Columns with Specified Digits
#' 
#' @description
#' The `format_digits` function formats numeric columns in a data frame or data table by rounding numbers to a specified number of decimal places and converting them to character strings. It can optionally format the numbers as percentages.
#'
#' @param data A `data.frame` or `data.table`. The input data containing numeric columns to format.
#' @param cols An optional numeric or character vector specifying the columns to format. If `NULL` (default), all numeric columns are formatted.
#' @param digits A non-negative integer specifying the number of decimal places to use. Defaults to `2`.
#' @param percentage A logical value indicating whether to format the numbers as percentages. If `TRUE`, the numbers are multiplied by 100 and a percent sign (`%`) is appended. Defaults to `FALSE`.
#'
#' @return A `data.table` with the specified numeric columns formatted as character strings with the specified number of decimal places. If `percentage = TRUE`, the numbers are shown as percentages.
#'
#' @details
#' The function performs the following steps:
#' \enumerate{
#'   \item Validates the input parameters, ensuring that `data` is a `data.frame` or `data.table`, `cols` (if provided) are valid column names or indices, and `digits` is a non-negative integer.
#'   \item Converts `data` to a `data.table` if it is not already one.
#'   \item Creates a formatting function based on the `digits` and `percentage` parameters:
#'   \itemize{
#'     \item If `percentage = FALSE`, numbers are rounded to `digits` decimal places.
#'     \item If `percentage = TRUE`, numbers are multiplied by 100, rounded to `digits` decimal places, and a percent sign (`%`) is appended.
#'   }
#'   \item Applies the formatting function to the specified columns:
#'   \itemize{
#'     \item If `cols` is `NULL`, the function formats all numeric columns in `data`.
#'     \item If `cols` is specified, only those columns are formatted.
#'   }
#'   \item Returns a new `data.table` with the formatted columns.
#' }
#'
#' @import data.table
#' @export
#'
#' @note
#' \itemize{
#'   \item The input `data` must be a `data.frame` or `data.table`.
#'   \item If `cols` is specified, it must be a vector of valid column names or indices present in `data`.
#'   \item The `digits` parameter must be a single non-negative integer.
#'   \item The original `data` is not modified; a modified copy is returned.
#' }
format_digits <- function(data, cols = NULL, digits = 2, percentage = FALSE) {
  # Parameter checks
  if (!is.data.frame(data)) {
    stop("Input data must be a data.frame or data.table object")
  }

  # Convert to data.table if it's a data.frame
  if (!is.data.table(data)) {
    data <- as.data.table(data)
  }

  # Check cols parameter
  if (!is.null(cols)) {
    if (!is.numeric(cols) && !is.character(cols)) {
      stop("'cols' must be numeric or character vector")
    }

    if (length(cols) == 0) {
      stop("When specified, 'cols' cannot be empty")
    }

    if (is.numeric(cols)) {
      if (any(cols < 1) || any(cols > ncol(data))) {
        stop("Numeric column indices must be between 1 and ", ncol(data))
      }
      cols <- names(data)[cols]
    }

    if (!all(cols %in% names(data))) {
      invalid_cols <- cols[!cols %in% names(data)]
      stop("Following columns do not exist in the data: ",
           paste(invalid_cols, collapse = ", "))
    }
  }

  # Check digits parameter
  if (!is.numeric(digits) ||
      length(digits) != 1 ||
      digits < 0 ||
      digits != round(digits)) {
    stop("'digits' must be a single non-negative integer")
  }

  # Create format string based on percentage parameter
  fmt <- if(percentage) {
    function(x) sprintf(paste0("%.", digits, "f%%"), round(as.numeric(x) * 100, digits))
  } else {
    function(x) sprintf(paste0("%.", digits, "f"), as.numeric(x))
  }

  # Create a copy of the data to modify
  result <- copy(data)

  # Process all numeric columns if cols is NULL
  if (is.null(cols)) {
    result[, names(.SD) := lapply(.SD, fmt), .SDcols = is.numeric][]
  } else {
    # Process specified columns
    result[, (cols) := lapply(.SD, fmt), .SDcols = cols][]
  }

  return(result)
}
```
  
```{r example-format_digits}
# Example: Number formatting demonstrations

# Setup test data
dt <- data.table::data.table(
  a = c(0.1234, 0.5678),      # Numeric column 1
  b = c(0.2345, 0.6789),      # Numeric column 2
  c = c("text1", "text2")     # Text column
)

# Example 1: Format all numeric columns
format_digits(
  dt,                         # Input data table
  digits = 2                  # Round to 2 decimal places
)

# Example 2: Format specific column as percentage
format_digits(
  dt,                         # Input data table
  cols = c("a"),              # Only format column 'a'
  digits = 2,                 # Round to 2 decimal places
  percentage = TRUE           # Convert to percentage
)
```


```{r tests-format_digits}
# Test basic formatting functionality
test_that("format_digits performs basic number formatting correctly", {
  df <- data.table(
    a = c(1.234, 2.345),
    b = c(3.456, 4.567),
    c = c("text1", "text2")
  )
  
  # Test default formatting
  result <- format_digits(df, cols = c("a", "b"))
  expect_equal(result$a, c("1.23", "2.35"))
  expect_equal(result$b, c("3.46", "4.57"))
  expect_equal(result$c, c("text1", "text2"))
  
  # Test different digits
  result <- format_digits(df, cols = "a", digits = 1)
  expect_equal(result$a, c("1.2", "2.3"))
  
  # Test percentage formatting
  result <- format_digits(df, cols = "a", percentage = TRUE)
  expect_equal(result$a, c("123.40%", "234.50%"))
})

# Test automatic column detection
test_that("format_digits handles automatic numeric column detection", {
  df <- data.table(
    num1 = c(1.234, 2.345),
    num2 = c(3.456, 4.567),
    text = c("a", "b")
  )
  
  result <- format_digits(df)
  expect_equal(result$num1, c("1.23", "2.35"))
  expect_equal(result$num2, c("3.46", "4.57"))
  expect_equal(result$text, c("a", "b"))
})

# Test input validation
test_that("format_digits validates input parameters correctly", {
  df <- data.table(x = 1.234)
  
  # Test invalid data input
  expect_error(format_digits(1:3), "Input data must be a data.frame or data.table object")
  
  # Test invalid cols parameter
  expect_error(format_digits(df, cols = list()), "'cols' must be numeric or character vector")
  expect_error(format_digits(df, cols = character(0)), "When specified, 'cols' cannot be empty")
  expect_error(format_digits(df, cols = "nonexistent"), "Following columns do not exist")
  expect_error(format_digits(df, cols = 0), "Numeric column indices must be between")
  
  # Test invalid digits parameter
  expect_error(format_digits(df, digits = -1), "'digits' must be a single non-negative integer")
  expect_error(format_digits(df, digits = c(1,2)), "'digits' must be a single non-negative integer")
  expect_error(format_digits(df, digits = 1.5), "'digits' must be a single non-negative integer")
})

# Test data type handling
test_that("format_digits handles different data types correctly", {
  df <- data.table(
    int = c(1L, 2L),
    dbl = c(1.23, 4.56),
    chr = c("7.89", "0.12")
  )
  
  result <- format_digits(df)
  expect_equal(result$int, c("1.00", "2.00"))
  expect_equal(result$dbl, c("1.23", "4.56"))
  expect_equal(result$chr, c("7.89", "0.12"))
})

# Test special cases
test_that("format_digits handles special cases correctly", {
  df <- data.table(
    x = c(0, 999999.999),
    y = c(NA, 1.23),
    z = c(Inf, -Inf)
  )
  
  result <- format_digits(df)
  expect_equal(result$x, c("0.00", "1000000.00"))
  expect_equal(result$y[1], "NA")
  expect_equal(result$y[2], "1.23")
  expect_equal(result$z, c("Inf", "-Inf"))
})

# Test data.frame conversion
test_that("format_digits handles data.frame to data.table conversion", {
  df <- data.frame(
    x = c(1.234, 2.345),
    y = c("a", "b")
  )
  
  result <- format_digits(df)
  expect_true(is.data.table(result))
  expect_equal(result$x, c("1.23", "2.35"))
  expect_equal(result$y, c("a", "b"))
})

```


# mintyr_example
    
```{r function-mintyr_example}
#' Get path to mintyr examples
#' 
#' `mintyr` comes bundled with a number of sample files in
#' its `inst/extdata` directory. Use `mintyr_example()` to retrieve the full file path to a 
#' specific example file.
#' 
#' @param path Name of the example file to locate. If NULL or missing,
#'   returns the directory path containing the examples.
#' @return Character string containing the full path to the requested example file.
#' @seealso [mintyr::mintyr_examples()] to list all available example files
#' @export
mintyr_example <- function(path = NULL) {
  # Handle case when path is NULL or missing
  if (is.null(path)) {
    return(system.file("extdata", package = "mintyr", mustWork = TRUE))
  }
  
  
  # Get the file path
  file_path <- system.file("extdata", path, package = "mintyr", mustWork = TRUE)
  
  return(file_path)
}
```
  
```{r example-mintyr_example}
# Get path to an example file
mintyr_example("csv_test1.csv")
```


```{r tests-mintyr_example}
# Test basic functionality and file existence
test_that("mintyr_example returns correct path for existing files", {
  # Test with existing file in the package
  expect_true(file.exists(mintyr_example("csv_test1.csv")))
  
  # Check if return value is a string
  expect_type(mintyr_example("csv_test1.csv"), "character")
  
  # Verify the returned path contains correct directory structure
  expect_match(mintyr_example("csv_test1.csv"), "extdata")
})
# Test file path resolution
test_that("mintyr_example returns correct path for existing files", {
  # Assuming example.csv exists in extdata directory
  result <- mintyr_example("csv_test1.csv")
  
  expect_true(file.exists(result))
  expect_type(result, "character")
  expect_match(result, "extdata")
})
```

# mintyr_examples
    
```{r function-mintyr_examples}
#' List all available example files in mintyr package
#' 
#' `mintyr` comes bundled with a number of sample files in its `inst/extdata` 
#' directory. This function lists all available example files, optionally filtered
#' by a pattern.
#' 
#' @param pattern A regular expression to filter filenames. If `NULL` (default),
#'   all available files are returned.
#' @return A character vector containing the names of example files. If no files
#'   match the pattern or if the example directory is empty, returns a zero-length
#'   character vector.
#' @seealso [mintyr::mintyr_example()] to get the full path of a specific example file
#' @export
mintyr_examples <- function(pattern = NULL) {
  # Validate pattern if provided
  if (!is.null(pattern)) {
    if (!is.character(pattern)) {
      stop("'pattern' must be a character string or NULL", call. = FALSE)
    }
  }
  
  # Get the example directory path
  example_dir <- system.file("extdata", package = "mintyr")
  
  # Check if directory exists
  if (example_dir == "") {
    return(character(0))
  }
  
  # Get and return matching files
  list.files(example_dir, pattern = pattern)
}
```
  
```{r example-mintyr_examples}
# List all example files
mintyr_examples()
```


```{r tests-mintyr_examples}
# Test basic functionality
test_that("mintyr_examples lists files correctly without pattern", {
  # Get all files
  files <- mintyr_examples()
  
  expect_type(files, "character")
  expect_true(length(files) > 0)
})

# Test pattern matching
test_that("mintyr_examples filters files with pattern", {
  # Test with .csv pattern
  csv_files <- mintyr_examples(pattern = "\\.csv$")
  expect_true(all(grepl("\\.csv$", csv_files)))
  
  # Test with non-existing pattern
  no_files <- mintyr_examples(pattern = "nonexistent")
  expect_length(no_files, 0)
})

# Test input validation
test_that("mintyr_examples validates pattern parameter", {
  # Test NULL pattern (default)
  expect_type(mintyr_examples(NULL), "character")
  
  # Test invalid pattern types
  expect_error(mintyr_examples(pattern = 123))
  expect_error(mintyr_examples(pattern = list()))
})

# Test edge cases
test_that("mintyr_examples handles edge cases", {
  # Test empty pattern
  empty_pattern <- mintyr_examples(pattern = "")
  expect_type(empty_pattern, "character")
  
  # Test pattern with special characters
  special_pattern <- mintyr_examples(pattern = "^.*\\.csv$")
  expect_type(special_pattern, "character")
})
```


# import_xlsx
    
```{r function-import_xlsx}
#' Import Data from `XLSX` Files with Advanced Handling
#'
#' @description
#' A robust and flexible function for importing data from one or multiple 
#' `XLSX` files, offering comprehensive options for sheet selection, 
#' data combination, and source tracking.
#'
#' @param file A `character` vector of file paths to `Excel` files. 
#'   Must point to existing `.xlsx` or `.xls` files.
#' @param rbind A `logical` value controlling data combination strategy:
#'   - `TRUE`: Combines all data into a single `data.table`
#'   - `FALSE`: Returns a list of `data.table`s
#'   Default is `TRUE`.
#' @param sheet A `numeric` vector or `NULL` specifying sheet import strategy:
#'   - `NULL` (default): Imports all sheets
#'   - `numeric`: Imports only specified sheet indices
#' @param ... Additional arguments passed to [`readxl::read_excel()`], 
#'   such as `col_types`, `skip`, or `na`.
#'
#' @details
#' The function provides a comprehensive solution for importing Excel data with the
#' following features:
#' \itemize{
#'   \item Supports multiple files and sheets
#'   \item Automatic source tracking for files and sheets
#'   \item Flexible combining options
#'   \item Handles missing columns across sheets when combining
#'   \item Preserves original data types through readxl
#' }
#'
#' @return 
#' Depends on the `rbind` parameter:
#' \itemize{
#'   \item If `rbind = TRUE`: A single `data.table` with additional tracking columns:
#'     - `excel_name`: Source file name (without extension)
#'     - `sheet_name`: Source sheet name
#'   \item If `rbind = FALSE`: A named list of `data.table`s with format 
#'     `"filename_sheetname"`
#' }
#'
#' @note
#' Critical Import Considerations:
#' \itemize{
#'   \item Requires all specified files to be accessible `Excel` files
#'   \item Sheet indices must be valid across input files
#'   \item `rbind = TRUE` assumes compatible data structures
#'   \item Missing columns are automatically filled with `NA`
#'   \item File extensions are automatically removed in tracking columns
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`readxl::read_excel()`] for underlying Excel reading
#'   \item [`data.table::rbindlist()`] for data combination
#' }
#'
#' @importFrom data.table ":="
#' @importFrom readxl read_excel excel_sheets
#'
#' @export
import_xlsx <- function(file, rbind = TRUE, sheet = NULL, ...) {
  excel_name <- NULL
  # Parameter checks
  if (!is.character(file) || !all(file.exists(file))) {
    stop("file must be a vector of existing file paths.")
  }

  if (!is.logical(rbind)) {
    stop("Parameter 'rbind' should be logical (TRUE or FALSE).")
  }

  # Function to remove file extension
  remove_extension <- function(filename) {
    sub("\\.[^.]*$", "", basename(filename))
  }

  # Reads selected sheets from a single Excel file and converts them into a data.table
  read_selected_sheets <- function(file_path, merge, sheet_indices, ...) {
    all_sheets <- readxl::excel_sheets(file_path)
    # Validate sheet indices
    if (!is.null(sheet_indices)) {
      if (is.numeric(sheet_indices)) {
        if (any(sheet_indices > length(all_sheets)) || any(sheet_indices < 1)) {
          stop("sheet index out of range for file: ", file_path)
        }
      } else {
        stop("sheet parameter must be a numeric vector or NULL.")
      }
    }

    selected_sheets <- if (is.null(sheet_indices)) all_sheets else all_sheets[sheet_indices]

    sheet_data <- lapply(selected_sheets, function(s) {
      dt <- data.table::as.data.table(readxl::read_excel(file_path, sheet = s, ...))
      if (!merge) {
        return(list(data = dt))  # Return each sheet as an independent list item if not merging
      } else {
        return(dt)
      }
    })

    if (merge) {
      names(sheet_data) <- selected_sheets
      data.table::rbindlist(sheet_data, use.names = TRUE, fill = TRUE, idcol = "sheet_name")
    } else {
      names(sheet_data) <- selected_sheets
      return(sheet_data)
    }
  }

  # Finding minimum sheet count across all Excel files
  min_sheet_count <- min(sapply(file, function(f) length(readxl::excel_sheets(f))))

  # Sheet parameter validation
  if (!is.null(sheet)) {
    if (is.numeric(sheet) && (max(sheet) > min_sheet_count || min(sheet) < 1)) {
      stop("sheet parameter contains indices out of range across files.")
    }
  }

  # Applies the modified function across all files
  all_data <- lapply(file, read_selected_sheets, merge = rbind, sheet_indices = sheet, ...)

  if (rbind) {
    # If merging, use rbindlist to combine all files' data into one data.table
    combined_data <- data.table::rbindlist(all_data, use.names = TRUE, fill = TRUE, idcol = "excel_name")
    xlsx_sheets_names <- sapply(file, remove_extension)  # 使用remove_extension替代tools::file_path_sans_ext
    # Set 'excel_name' column's value to the corresponding file names
    combined_data[, excel_name := rep(xlsx_sheets_names, sapply(all_data, nrow))][]
    return(combined_data)
  } else {
    # If not merging, create a new list to store all sheets' data
    result_list <- list()
    xlsx_sheets_names <- sapply(file, remove_extension)  # 使用remove_extension替代tools::file_path_sans_ext
    for (i in seq_along(file)) {
      file_name <- xlsx_sheets_names[i]
      file_data <- all_data[[i]]
      # For each file's sheets, set list item names as "file_name_sheet_name"
      for (sheet_name in names(file_data)) {
        list_name <- paste(file_name, sheet_name, sep = "_")
        result_list[[list_name]] <- file_data[[sheet_name]][["data"]]
      }
    }
    return(result_list)
  }
}
```
  
```{r example-import_xlsx}
# Example: Excel file import demonstrations

# Setup test files
xlsx_files <- mintyr_example(
  mintyr_examples("xlsx_test")    # Get example Excel files
)

# Example 1: Import and combine all sheets from all files
import_xlsx(
  xlsx_files,                     # Input Excel file paths
  rbind = TRUE                    # Combine all sheets into one data.table
)

# Example 2: Import specific sheets separately
import_xlsx(
  xlsx_files,                     # Input Excel file paths
  rbind = FALSE,                  # Keep sheets as separate data.tables
  sheet = 2                       # Only import first sheet
)
```


```{r tests-import_xlsx}
# Test import_xlsx functionality
test_that("import_xlsx reads Excel files correctly", {
  # Setup test files
  xlsx_files <- mintyr_example(
    mintyr_examples(pattern = "xlsx_test")  # Get example Excel files
  )
  
  # Test basic functionality with rbind = TRUE
  test_that("import_xlsx combines all sheets with rbind = TRUE", {
    result <- import_xlsx(xlsx_files, rbind = TRUE)
    
    # Check return type
    expect_s3_class(result, "data.table")
    
    # Check required columns exist
    expect_true(all(c("excel_name", "sheet_name") %in% names(result)))
    
    # Check data is not empty
    expect_true(nrow(result) > 0)
  })
  
  # Test with rbind = FALSE
  test_that("import_xlsx returns list of sheets with rbind = FALSE", {
    result <- import_xlsx(xlsx_files, rbind = FALSE)
    
    # Check return type
    expect_type(result, "list")
    
    # Check each element is a data.table
    expect_true(all(sapply(result, data.table::is.data.table)))
  })
  
  # Test sheet selection
  test_that("import_xlsx handles sheet parameter correctly", {
    # Test specific sheet selection
    result_sheet1 <- import_xlsx(xlsx_files, sheet = 1)
    expect_true(all(result_sheet1$sheet_name == "Sheet1"))
    
    # Test multiple sheet selection
    result_sheets <- import_xlsx(xlsx_files, sheet = c(1, 2))
    expect_true(all(result_sheets$sheet_name %in% c("Sheet1", "Sheet2", "a")))
  })
})

# Test error handling
test_that("import_xlsx handles errors appropriately", {
  # Setup test files
  xlsx_files <- mintyr_example(
    mintyr_examples(pattern = "\\.xlsx$")
  )
  
  # Test invalid file path
  expect_error(
    import_xlsx("nonexistent.xlsx"),
    "file must be a vector of existing file paths"
  )
  
  # Test invalid rbind parameter
  expect_error(
    import_xlsx(xlsx_files, rbind = "TRUE"),
    "Parameter 'rbind' should be logical"
  )
  
  # Test invalid sheet parameter
  expect_error(
    import_xlsx(xlsx_files, sheet = "1"),
    "sheet parameter must be a numeric vector or NULL"
  )
  
  # Test out of range sheet index
  expect_error(
    import_xlsx(xlsx_files, sheet = 999),
    "sheet parameter contains indices out of range"
  )
})

# Test edge cases
test_that("import_xlsx handles edge cases", {
  # Setup test files
  xlsx_files <- mintyr_example(
    mintyr_examples(pattern = "\\.xlsx$")
  )
  
  # Test single file
  single_result <- import_xlsx(xlsx_files[1])
  expect_s3_class(single_result, "data.table")
  
  # Test multiple files
  multi_result <- import_xlsx(xlsx_files)
  expect_s3_class(multi_result, "data.table")
  
  # Test with empty sheets (if applicable)
  # Note: This test depends on your test file structure
  
  # Test with different column names across sheets
  # Note: This test depends on your test file structure
})
```



# import_csv

```{r function-import_csv}
#' Flexible `CSV`/`TXT` File Import with Multiple Backend Support
#'
#' @description
#' A comprehensive `CSV` or `TXT` file import function offering advanced reading capabilities 
#' through `data.table` and `arrow` packages with intelligent data combination strategies.
#'
#' @param file A `character` vector of file paths to `CSV` files.
#'   Must point to existing and accessible files.
#'
#' @param package A `character` string specifying the backend package:
#'   - `"data.table"`: Uses [`data.table::fread()`] (default)
#'   - `"arrow"`: Uses [`arrow::read_csv_arrow()`]
#'   Determines the underlying reading mechanism.
#'
#' @param rbind A `logical` value controlling data combination strategy:
#'   - `TRUE`: Combines all files into a single data object
#'   - `FALSE`: Returns a list of individual data objects
#'   Default is `TRUE`.
#'
#' @param rbind_label A `character` string or `NULL` for source file tracking:
#'   - `character`: Specifies the column name for file source labeling
#'   - `NULL`: Disables source file tracking
#'   Default is `"_file"`.
#'
#' @param ... Additional arguments passed to backend-specific reading functions 
#'   (e.g., `col_types`, `na.strings`, `skip`).
#'
#' @details
#' The function provides a unified interface for reading CSV files using either data.table
#' or arrow package. When reading multiple files, it can either combine them into a single
#' data object or return them as a list. File source tracking is supported through the
#' rbind_label parameter.
#'
#' @return 
#' Depends on the `rbind` parameter:
#' \itemize{
#'   \item If `rbind = TRUE`: A single data object (from chosen package) 
#'     containing all imported data
#'   \item If `rbind = FALSE`: A named list of data objects with names 
#'     derived from input file names (without extensions)
#' }
#'
#' @note
#' Critical Import Considerations:
#' \itemize{
#'   \item Requires all specified files to be accessible `CSV/TXT` files
#'   \item Supports flexible backend selection
#'   \item `rbind = TRUE` assumes compatible data structures
#'   \item Missing columns are automatically aligned
#'   \item File extensions are automatically removed in tracking columns
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`data.table::fread()`] for `data.table` backend
#'   \item [`arrow::read_csv_arrow()`] for `arrow` backend
#'   \item [`data.table::rbindlist()`] for data combination
#' }
#'
#' @import data.table
#' @import arrow
#'
#' @export
import_csv <- function (file, package = "data.table", rbind = TRUE, rbind_label = "_file", ...) {
  # Validations
  if (!is.character(file) || !all(file.exists(file))) {
    stop("file must be a vector of existing file paths.")
  }

  if (!package %in% c("data.table", "arrow")) {
    stop("package must be one of 'data.table', 'arrow'.")
  }

  # Function to remove file extension
  remove_extension <- function(filename) {
    sub("\\.[^.]*$", "", basename(filename))
  }

  # Read Functionality with naming
  read_files <- function(read_function) {
    file_data <- lapply(file, function(file_path) {
      df <- read_function(file_path, ...)
      if (!is.null(rbind_label) && rbind && length(file) > 1) {
        # Add a column with the label indicating the file origin, without extension
        df <- cbind(stats::setNames(data.frame(remove_extension(file_path)), rbind_label), df)
      }
      return(df)
    })

    if (rbind && length(file) > 1) {
      # Combine all data into a single data table/data frame
      return(data.table::rbindlist(file_data, use.names = TRUE, fill = TRUE))
    } else {
      # When rbind is FALSE, name the list elements with file names
      names(file_data) <- remove_extension(file)
      return(file_data)
    }
  }

  # Package specific operations
  if (package == "data.table") {
    return(read_files(data.table::fread))
  } else if (package == "arrow") {
    return(read_files(arrow::read_csv_arrow))
  }
}
```

```{r examples-import_csv}
# Example: CSV file import demonstrations

# Setup test files
csv_files <- mintyr_example(
  mintyr_examples("csv_test")     # Get example CSV files
)

# Example 1: Import and combine CSV files using data.table
import_csv(
  csv_files,                      # Input CSV file paths
  package = "data.table",         # Use data.table for reading
  rbind = TRUE,                   # Combine all files into one data.table
  rbind_label = "_file"           # Column name for file source
)

# Example 2: Import files separately using arrow
import_csv(
  csv_files,                      # Input CSV file paths
  package = "arrow",              # Use arrow for reading
  rbind = FALSE                   # Keep files as separate data.tables
)
```


```{r tests-import_csv}
# Test import_csv functionality
test_that("import_csv reads CSV files correctly", {
  # Setup test files
  csv_files <- mintyr_example(
    mintyr_examples(pattern = "\\.csv$")  # Get example CSV files
  )
  
  # Test basic functionality with data.table
  test_that("import_csv works with data.table package", {
    result <- import_csv(csv_files, package = "data.table")
    
    # Check return type
    expect_s3_class(result, "data.table")
    
    # Check rbind_label column exists when multiple files
    if (length(csv_files) > 1) {
      expect_true("_file" %in% names(result))
    }
    
    # Check data is not empty
    expect_true(nrow(result) > 0)
  })
  
  # Test with arrow package
  test_that("import_csv works with arrow package", {
    skip_if_not_installed("arrow")
    
    result <- import_csv(csv_files, package = "arrow")
    
    # Check return type (arrow converts to data.frame/data.table)
    expect_true(is.data.frame(result))
    
    # Check rbind_label column exists when multiple files
    if (length(csv_files) > 1) {
      expect_true("_file" %in% names(result))
    }
  })
  
  # Test rbind = FALSE
  test_that("import_csv returns list when rbind = FALSE", {
    result <- import_csv(csv_files, rbind = FALSE)
    
    # Check return type
    expect_type(result, "list")
    
    # Check list names
    expect_equal(names(result), tools::file_path_sans_ext(basename(csv_files)))
    
    # Check each element is a data.table
    expect_true(all(sapply(result, data.table::is.data.table)))
  })
  
  # Test custom rbind_label
  test_that("import_csv handles custom rbind_label", {
    custom_label <- "source_file"
    result <- import_csv(csv_files, rbind_label = custom_label)
    
    if (length(csv_files) > 1) {
      expect_true(custom_label %in% names(result))
    }
  })
})

# Test error handling
test_that("import_csv handles errors appropriately", {
  # Setup test files
  csv_files <- mintyr_example(
    mintyr_examples(pattern = "\\.csv$")
  )
  
  # Test invalid file path
  expect_error(
    import_csv("nonexistent.csv"),
    "file must be a vector of existing file paths"
  )
  
  # Test invalid package parameter
  expect_error(
    import_csv(csv_files, package = "invalid"),
    "package must be one of 'data.table', 'arrow'"
  )
})

# Test edge cases
test_that("import_csv handles edge cases", {
  # Setup test files
  csv_files <- mintyr_example(
    mintyr_examples(pattern = "\\.csv$")
  )
  
  # Test single file
  test_that("import_csv handles single file correctly", {
    single_result <- import_csv(csv_files[1])
    # No rbind_label column should be added for single file
    expect_false("_file" %in% names(single_result))
  })
  
  # Test with NULL rbind_label
  test_that("import_csv handles NULL rbind_label", {
    result <- import_csv(csv_files, rbind_label = NULL)
    expect_s3_class(result, "data.table")
    expect_false("_file" %in% names(result))
  })
  
  # Test with empty CSV files (if applicable)
  # Note: This test depends on your test file structure
  
  # Test with different column structures (if applicable)
  # Note: This test depends on your test file structure
})

# Test additional parameters
test_that("import_csv handles additional parameters correctly", {
  # Setup test files
  csv_files <- mintyr_example(
    mintyr_examples(pattern = "\\.csv$")
  )
  
  # Test with additional fread/read_csv_arrow parameters
  test_that("import_csv passes additional parameters correctly", {
    # Test with data.table
    result_dt <- import_csv(csv_files, package = "data.table", header = TRUE, sep = ",")
    expect_s3_class(result_dt, "data.table")
    
    # Test with arrow
    skip_if_not_installed("arrow")
    result_arrow <- import_csv(csv_files, package = "arrow", col_names = TRUE)
    expect_true(is.data.frame(result_arrow))
  })
})
```


# get_filename
    
```{r function-get_filename}
#' Extract Filenames from File Paths
#'
#' @description
#' The `get_filename` function extracts filenames from file paths with options to remove file extensions 
#' and/or directory paths.
#'
#' @param paths A `character` vector containing file system paths.
#'   Must be valid and accessible path strings.
#'
#' @param rm_extension A `logical` flag controlling file extension removal:
#'   - `TRUE`: Strips file extensions from filenames
#'   - `FALSE`: Preserves complete filename with extension
#'   Default is `TRUE`.
#'
#' @param rm_path A `logical` flag managing directory path handling:
#'   - `TRUE`: Extracts only the filename, discarding directory information
#'   - `FALSE`: Retains complete path information
#'   Default is `TRUE`.
#'
#' @details
#' The function performs the following operations:
#' \itemize{
#'   \item Validates input paths
#'   \item Handles empty input vectors
#'   \item Optionally removes directory paths using \code{\link[base]{basename}}
#'   \item Optionally removes file extensions using regex substitution
#' }
#'
#' @return A `character` vector of processed filenames with applied transformations.
#'
#' @note
#' - If both \code{rm_extension} and \code{rm_path} are FALSE, 
#'   a warning is issued and the original paths are returned
#' - Supports multiple file paths in the input vector
#'
#' @seealso
#' \itemize{
#'   \item [`base::basename()`] for basic filename extraction
#' }
#'
#' @export
get_filename <- function(paths, rm_extension = TRUE, rm_path = TRUE) {

  # Input validation
  if (missing(paths)) {
    stop("Parameter 'paths' cannot be empty")
  }

  if (!is.character(paths)) {
    stop("'paths' must be a character vector")
  }

  # Handle empty vector
  if (length(paths) == 0) {
    return(character(0))
  }

  # Warn if both parameters are FALSE
  if (!rm_extension && !rm_path) {
    warning("Setting both rm_extension=FALSE and rm_path=FALSE returns the original paths")
  }

  # Process paths
  result <- if (rm_path) basename(paths) else paths

  # Process extensions
  if (rm_extension) {
    result <- sub("\\.[^.]*$", "", result)
  }

  return(result)
}
```
  
```{r example-get_filename}
# Example: File path processing demonstrations

# Setup test files
xlsx_files <- mintyr_example(
  mintyr_examples("xlsx_test")    # Get example Excel files
)

# Example 1: Extract filenames without extensions
get_filename(
  xlsx_files,                     # Input file paths
  rm_extension = TRUE,            # Remove file extensions
  rm_path = TRUE                  # Remove directory paths
)

# Example 2: Keep file extensions
get_filename(
  xlsx_files,                     # Input file paths
  rm_extension = FALSE,           # Keep file extensions
  rm_path = TRUE                  # Remove directory paths
)

# Example 3: Keep full paths without extensions
get_filename(
  xlsx_files,                     # Input file paths
  rm_extension = TRUE,            # Remove file extensions
  rm_path = FALSE                 # Keep directory paths
)
```


```{r tests-get_filename}
test_that("get_filename functions correctly", {
  # Setup test files
  csv_files <- mintyr_example(
    mintyr_examples(pattern = "\\.csv$")
  )
  
  # Test basic functionality
  test_that("basic functionality works", {
    # Test with default parameters (rm_extension = TRUE, rm_path = TRUE)
    result <- get_filename(csv_files)
    expect_type(result, "character")
    expect_false(any(grepl("/", result)))  # No path components
    expect_false(any(grepl("\\.", result)))  # No extensions
    
    # Verify results match expected pattern
    for (i in seq_along(result)) {
      expect_equal(
        result[i],
        sub("\\.[^.]*$", "", basename(csv_files[i]))
      )
    }
  })
  
  # Test different parameter combinations
  test_that("parameter combinations work correctly", {
    # Keep extension, remove path
    result1 <- get_filename(csv_files, rm_extension = FALSE, rm_path = TRUE)
    expect_true(all(grepl("\\.csv$", result1)))
    expect_false(any(grepl("/", result1)))
    
    # Keep path, remove extension
    result2 <- get_filename(csv_files, rm_extension = TRUE, rm_path = FALSE)
    expect_false(any(grepl("\\.csv$", result2)))
    expect_true(any(grepl("/", result2)))
    
    # Keep both path and extension
    expect_warning(
      result3 <- get_filename(csv_files, rm_extension = FALSE, rm_path = FALSE),
      "Setting both rm_extension=FALSE and rm_path=FALSE returns the original paths"
    )
    expect_equal(result3, csv_files)
  })
  
  # Test error handling
  test_that("error handling works correctly", {
    # Test missing parameter
    expect_error(
      get_filename(),
      "Parameter 'paths' cannot be empty"
    )
    
    # Test invalid input type
    expect_error(
      get_filename(123),
      "'paths' must be a character vector"
    )
    
    expect_error(
      get_filename(list("path")),
      "'paths' must be a character vector"
    )
  })
  
  # Test edge cases
  test_that("edge cases are handled correctly", {
    # Empty vector
    expect_equal(
      get_filename(character(0)),
      character(0)
    )
    
    # Single file
    single_file <- csv_files[1]
    result <- get_filename(single_file)
    expect_length(result, 1)
    expect_equal(
      result,
      sub("\\.[^.]*$", "", basename(single_file))
    )
    
    # Files without extensions
    no_ext_files <- sub("\\.csv$", "", csv_files)
    result <- get_filename(no_ext_files)
    expect_equal(
      result,
      basename(no_ext_files)
    )
    
    # Files with multiple extensions (e.g., "file.tar.gz")
    multi_ext_file <- c(
      "path/to/file.csv",
      "path/to/data.backup.csv"
    )
    result <- get_filename(multi_ext_file)
    expect_equal(
      result,
      c("file", "data.backup")
    )
  })
})
```


# w2l_nest
    
```{r function-w2l_nest}
#' Reshape Wide Data to Long Format and Nest by Specified Columns
#'
#' @description
#' The `w2l_nest` function reshapes wide-format data into long-format and nests it by specified columns.
#' It handles both `data.frame` and `data.table` objects and provides options for grouping and nesting the data.
#'
#' @param data `data.frame` or `data.table`
#'   - Input dataset in wide format
#'   - Automatically converted to `data.table` if necessary
#'
#' @param cols2l `numeric` or `character` columns to transform
#'   - Specifies columns for wide-to-long conversion
#'   - Can be column indices or column names
#'   - Default is `NULL`
#'
#' @param by `numeric` or `character` grouping variables
#'   - Optional columns for additional data stratification
#'   - Can be column indices or column names
#'   - Used to create hierarchical nested structures
#'   - Default is `NULL`
#'
#' @param nest_type `character` output data type
#'   - Defines nested data object type
#'   - Possible values:
#'     - `"dt"`: nested `data.table`
#'     - `"df"`: nested `data.frame`
#'   - Default is `"dt"`
#'
#' @details
#' The function melts the specified wide columns into long format and nests the resulting data by the `name`
#' column and any additional grouping variables specified in `by`. The nested data can be in the form of
#' `data.table` or `data.frame` objects, controlled by the `nest_type` parameter.
#'
#' Both `cols2l` and `by` parameters accept either column indices or column names, providing flexible ways
#' to specify the columns for transformation and grouping.
#'
#' @return `data.table` with nested data in long format, grouped by specified columns if provided. Each row contains a nested `data.table` or `data.frame` under the column data, depending on nest_type.
#' \itemize{
#'   \item If `by` is `NULL`, returns a `data.table` nested by `name`.
#'   \item If `by` is specified, returns a `data.table` nested by `name` and the grouping variables.
#' }
#'
#' @note
#' \itemize{
#'   \item Both `cols2l` and `by` parameters can be specified using either numeric indices or character column names.
#'   \item When using numeric indices, they must be valid column positions in the data (1 to ncol(data)).
#'   \item When using character names, all specified columns must exist in the data.
#'   \item The function converts `data.frame` to `data.table` if necessary.
#'   \item The `nest_type` parameter controls whether nested data are `data.table` (`"dt"`) or `data.frame` (`"df"`) objects.
#'   \item If `nest_type` is not `"dt"` or `"df"`, the function will stop with an error.
#' }
#'
#' @seealso
#' Related functions and packages:
#' \itemize{
#'   \item [`tidytable::nest_by()`] Nest data.tables by group
#' }
#'
#' @import data.table
#' @export
w2l_nest <- function(data, cols2l = NULL, by = NULL, nest_type = "dt") {
  . <- name <- NULL

  # Ensure the data is a data.table object
  if (!data.table::is.data.table(data)) {
    if (is.data.frame(data)) {
      data <- data.table::as.data.table(data)  # Convert data.frame to data.table if necessary
    } else {
      stop("Data must be either a data.frame or a data.table.")  # Stop if data is not a data.table or data.frame
    }
  }

  # Process grouping variables
  if (!is.null(by)) {
    # Convert numeric indices to column names if necessary
    if (is.numeric(by)) {
      if (any(by < 1 | by > ncol(data))) {
        stop("Numeric indices in by are out of bounds.")
      }
      by <- names(data)[by]
    } else if (is.character(by)) {
      missing_by_vars <- by[!by %in% names(data)]
      if (length(missing_by_vars) > 0) {
        stop("Grouping variables not present in data: ", paste(missing_by_vars, collapse=", "))
      }
    } else {
      stop("by should be either numeric indices or character vector of column names.")
    }
  }

  # Handle case when cols2l is NULL
  if (is.null(cols2l)) {
    if (is.null(by)) {
      stop("When cols2l is NULL, by parameter must be provided.")
    }
    # Directly nest the data by grouping variables
    if (nest_type == "dt") {
      result <- data[, .(data = list(.SD)), by = by]
    } else if (nest_type == "df") {
      result <- data[, .(data = list(as.data.frame(.SD))), by = by]
    } else {
      stop("Invalid nest_type provided. It must be either 'dt' or 'df'.")
    }
  } else {
    # Check the validity of cols2l based on its type
    if (is.numeric(cols2l)) {
      if (any(cols2l < 1 | cols2l > ncol(data))) {
        stop("Numeric indices in cols2l are out of bounds.")
      }
      cols2l <- names(data)[cols2l]
    } else if (is.character(cols2l)) {
      if (!all(cols2l %in% names(data))) {
        missing_cols <- cols2l[!cols2l %in% names(data)]
        stop("Some columns specified in cols2l are not present in the data: ", paste(missing_cols, collapse=", "))
      }
    } else {
      stop("cols2l should be either numeric indices or character vector of column names.")
    }

    # Melt the data
    melted_data <- data.table::melt(
      data,
      measure.vars = cols2l,
      variable.name = "name",
      value.name = "value"
    )

    # Determine grouping variables for nesting
    if (!is.null(by) && length(by) > 0) {
      groupby <- c("name", by)
    } else {
      groupby <- "name"
    }

    # Nest the data based on nest_type
    if (nest_type == "dt") {
      result <- melted_data[, .(data = list(.SD)), by = groupby]
    } else if (nest_type == "df") {
      result <- melted_data[, .(data = list(as.data.frame(.SD))), by = groupby]
    } else {
      stop("Invalid nest_type provided. It must be either 'dt' or 'df'.")
    }
  }

  # Return the result
  return(result)
}
```
  
```{r example-w2l_nest}
# Example: Wide to long format nesting demonstrations

# Example 1: Basic nesting by group
w2l_nest(
  data = iris,                    # Input dataset
  by = "Species"                  # Group by Species column
)

# Example 2: Nest specific columns with numeric indices
w2l_nest(
  data = iris,                    # Input dataset
  cols2l = 1:4,                   # Select first 4 columns to nest
  by = "Species"                  # Group by Species column
)

# Example 3: Nest specific columns with column names
w2l_nest(
  data = iris,                    # Input dataset
  cols2l = c("Sepal.Length",      # Select columns by name
             "Sepal.Width", 
             "Petal.Length"),
  by = 5                          # Group by column index 5 (Species)
)
# Returns similar structure to Example 2
```


```{r tests-w2l_nest}
test_that("w2l_nest functions correctly", {
  # Setup test data
  test_dt <- data.table::data.table(
    id = 1:4,
    group = c("A", "A", "B", "B"),
    val1 = c(10, 20, 30, 40),
    val2 = c(100, 200, 300, 400)
  )
  
  test_df <- as.data.frame(test_dt)
  
  # Test basic functionality
  test_that("basic functionality works", {
    # Test with data.table input
    result1 <- w2l_nest(test_dt, cols2l = c("val1", "val2"))
    expect_true(data.table::is.data.table(result1))
    expect_equal(nrow(result1), 2)  # One row for each value column
    expect_equal(names(result1), c("name", "data"))
    
    # Test with data.frame input
    result2 <- w2l_nest(test_df, cols2l = c("val1", "val2"))
    expect_true(data.table::is.data.table(result2))
    expect_equal(result1, result2)
  })
  
  # Test different parameter combinations
  test_that("parameter combinations work correctly", {
    # Test with by parameter
    result <- w2l_nest(test_dt, cols2l = c("val1", "val2"), by = "group")
    expect_equal(nrow(result), 4)  # 2 value columns × 2 groups
    expect_equal(names(result), c("name", "group", "data"))
    
    # Test with numeric indices
    result_num <- w2l_nest(test_dt, cols2l = c(3, 4), by = 2)
    expect_equal(result, result_num)
    
    # Test with nest_type = "df"
    result_df <- w2l_nest(test_dt, cols2l = c("val1", "val2"), nest_type = "df")
    expect_true(is.data.frame(result_df$data[[1]]))
    
    # Test with NULL cols2l
    result_null <- w2l_nest(test_dt, cols2l = NULL, by = "group")
    expect_equal(nrow(result_null), 2)  # One row for each group
    expect_equal(names(result_null), c("group", "data"))
  })
  
  # Test error handling
  test_that("error handling works correctly", {
    # Test invalid input type
    expect_error(
      w2l_nest(list(a = 1)),
      "Data must be either a data.frame or a data.table."
    )
    
    # Test invalid cols2l
    expect_error(
      w2l_nest(test_dt, cols2l = "nonexistent"),
      "Some columns specified in cols2l are not present in the data"
    )
    
    expect_error(
      w2l_nest(test_dt, cols2l = 10),
      "Numeric indices in cols2l are out of bounds"
    )
    
    # Test invalid by
    expect_error(
      w2l_nest(test_dt, cols2l = c("val1", "val2"), by = "nonexistent"),
      "Grouping variables not present in data"
    )
    
    expect_error(
      w2l_nest(test_dt, cols2l = c("val1", "val2"), by = 10),
      "Numeric indices in by are out of bounds"
    )
    
    # Test invalid nest_type
    expect_error(
      w2l_nest(test_dt, cols2l = c("val1", "val2"), nest_type = "invalid"),
      "Invalid nest_type provided"
    )
    
    # Test missing by when cols2l is NULL
    expect_error(
      w2l_nest(test_dt, cols2l = NULL),
      "When cols2l is NULL, by parameter must be provided"
    )
  })
  
  # Test edge cases
  test_that("edge cases are handled correctly", {
    # Single column to nest
    result <- w2l_nest(test_dt, cols2l = "val1")
    expect_equal(nrow(result), 1)
    
    # Single group
    result <- w2l_nest(test_dt, cols2l = c("val1", "val2"), by = "id")
    expect_equal(nrow(result), 8)  # 2 value columns × 4 ids
    
    # Empty groups
    empty_dt <- test_dt[0,]
    result <- w2l_nest(empty_dt, cols2l = c("val1", "val2"))
    expect_equal(nrow(result), 0)
  })
  
  # Test nested data content
  test_that("nested data content is correct", {
    result <- w2l_nest(test_dt, cols2l = c("val1", "val2"), by = "group")
    
    # Check first nested dataset
    first_nest <- result$data[[1]]
    expect_true(data.table::is.data.table(first_nest))
    expect_equal(names(first_nest), c("id", "value"))
    
    # Verify values are correctly nested
    group_a_val1 <- result[name == "val1" & group == "A"]$data[[1]]
    expect_equal(group_a_val1$value, c(10, 20))
    
    group_b_val2 <- result[name == "val2" & group == "B"]$data[[1]]
    expect_equal(group_b_val2$value, c(300, 400))
  })
})
```



# w2l_split
    
```{r function-w2l_split}
#' Reshape Wide Data to Long Format and Split into List
#'
#' @description
#' The `w2l_split` function reshapes wide-format data into long-format and splits it into a list
#' by variable names and optional grouping columns. It handles both `data.frame` and `data.table` objects.
#'
#' @param data `data.frame` or `data.table`
#'   - Input dataset in wide format
#'   - Automatically converted to `data.table` if necessary
#'
#' @param cols2l `numeric` or `character` columns to transform
#'   - Specifies columns for wide-to-long conversion
#'   - Can be column indices or column names
#'   - Default is `NULL`
#'
#' @param by `numeric` or `character` grouping variables
#'   - Optional columns for data splitting
#'   - Can be column indices or column names
#'   - Used to create hierarchical split structure
#'   - Default is `NULL`
#'
#' @param split_type `character` output data type
#'   - Defines split data object type
#'   - Possible values:
#'     - `"dt"`: split `data.table` objects
#'     - `"df"`: split `data.frame` objects
#'   - Default is `"dt"`
#'
#' @param sep `character` separator
#'   - Used for combining split names
#'   - Default is `"_"`
#'
#' @details
#' The function melts the specified wide columns into long format and splits the resulting data
#' into a list based on the variable names and any additional grouping variables specified in `by`.
#' The split data can be in the form of `data.table` or `data.frame` objects, controlled by the
#' `split_type` parameter.
#'
#' Both `cols2l` and `by` parameters accept either column indices or column names, providing flexible ways
#' to specify the columns for transformation and splitting.
#'
#' @return A list of `data.table` or `data.frame` objects (depending on `split_type`), split by variable
#' names and optional grouping columns.
#' \itemize{
#'   \item If `by` is `NULL`, returns a list split by variable names only.
#'   \item If `by` is specified, returns a list split by both variable names and grouping variables.
#' }
#'
#' @note
#' \itemize{
#'   \item Both `cols2l` and `by` parameters can be specified using either numeric indices or character column names.
#'   \item When using numeric indices, they must be valid column positions in the data (1 to ncol(data)).
#'   \item When using character names, all specified columns must exist in the data.
#'   \item The function converts `data.frame` to `data.table` if necessary.
#'   \item The `split_type` parameter controls whether split data are `data.table` (`"dt"`) or `data.frame` (`"df"`) objects.
#'   \item If `split_type` is not `"dt"` or `"df"`, the function will stop with an error.
#' }
#'
#' @seealso
#' Related functions and packages:
#' \itemize{
#'   \item [`tidytable::group_split()`] Split data frame by groups
#' }
#'
#' @import data.table
#' @export

w2l_split <- function(data, cols2l = NULL, by = NULL, split_type = "dt", sep = "_") {
  # Check if input data is data.table, if not convert it
  if (!data.table::is.data.table(data)) {
    if (is.data.frame(data)) {
      data <- data.table::as.data.table(data)
    } else {
      stop("data must be a data.frame or data.table.")
    }
  }
  
  # Process by parameter - handle both numeric and character input
  if (!is.null(by)) {
    if (is.numeric(by)) {
      if (any(by < 1 | by > ncol(data))) {
        stop("Numeric indices in by are out of bounds.")
      }
      by <- names(data)[by]
    } else if (is.character(by)) {
      if (!all(by %in% names(data))) {
        missing_by <- by[!by %in% names(data)]
        stop("Some 'by' columns are not present in the data: ",
             paste(missing_by, collapse = ", "))
      }
    } else {
      stop("by should be either numeric indices or character vector of column names.")
    }
  }
  
  # Handle case when cols2l is NULL
  if (is.null(cols2l)) {
    if (is.null(by)) {
      stop("When cols2l is NULL, by parameter must be provided.")
    }
    # Directly split the data by grouping variables
    dt_list <- split(data, by = by, keep.by = F, drop = TRUE)
    
    # Create list names using by variables
    split_values <- do.call(paste, c(lapply(by, function(x) data[[x]]), list(sep = sep)))
    split_values <- unique(split_values)
    names(dt_list) <- split_values
  } else {
    # Process cols2l parameter - handle both numeric and character input
    if (is.numeric(cols2l)) {
      if (any(cols2l < 1 | cols2l > ncol(data))) {
        stop("Numeric indices in cols2l are out of bounds.")
      }
      cols2l_names <- names(data)[cols2l]
    } else if (is.character(cols2l)) {
      if (!all(cols2l %in% names(data))) {
        missing_cols <- cols2l[!cols2l %in% names(data)]
        stop("Some columns specified in cols2l are not present in the data: ",
             paste(missing_cols, collapse = ", "))
      }
      cols2l_names <- cols2l
    } else {
      stop("cols2l should be either numeric indices or character vector of column names.")
    }
    
    # Identify ID variables (all columns except those to be transformed)
    id_vars <- setdiff(names(data), cols2l_names)
    if (!is.null(by)) {
      id_vars <- unique(c(id_vars, by))
    }
    
    # Melt data from wide to long format
    dt_long <- data.table::melt(data, id.vars = id_vars, measure.vars = cols2l_names,
                                variable.name = "variable", value.name = "value")
    
    # Define splitting variables and split the data
    split_vars <- c("variable", by)
    dt_list <- split(dt_long, by = split_vars, keep.by = F, drop = TRUE)
    
    # Create list names using by variables if provided
    if (!is.null(by)) {
      # Combine split variables values using specified separator
      split_values <- do.call(paste, c(lapply(split_vars, function(x) dt_long[[x]]), list(sep = sep)))
      split_values <- unique(split_values)
      names(dt_list) <- split_values
    }
  }
  
  # Convert to specified output format
  if (split_type == "dt") {
    # Keep as data.table
  } else if (split_type == "df") {
    # Convert to data.frame
    dt_list <- lapply(dt_list, as.data.frame)
  } else {
    stop("Invalid split_type provided. It must be either 'dt' or 'df'.")
  }
  
  return(dt_list)
}
```
  
```{r example-w2l_split}
# Example: Wide to long format splitting demonstrations

# Example 1: Basic splitting by Species
w2l_split(
  data = iris,                    # Input dataset
  by = "Species"                  # Split by Species column
) |> 
  lapply(head)                    # Show first 6 rows of each split

# Example 2: Split specific columns using numeric indices
w2l_split(
  data = iris,                    # Input dataset
  cols2l = 1:3,                   # Select first 3 columns to split
  by = 5                          # Split by column index 5 (Species)
) |> 
  lapply(head)                    # Show first 6 rows of each split

# Example 3: Split specific columns using column names
list_res <- w2l_split(
  data = iris,                    # Input dataset
  cols2l = c("Sepal.Length",      # Select columns by name
             "Sepal.Width"),
  by = "Species"                  # Split by Species column
)
lapply(list_res, head)            # Show first 6 rows of each split
# Returns similar structure to Example 2
```


```{r tests-w2l_split}
test_that("w2l_split functions correctly", {
  # Setup test data
  test_dt <- data.table::data.table(
    id = 1:4,
    group = c("A", "A", "B", "B"),
    val1 = c(10, 20, 30, 40),
    val2 = c(100, 200, 300, 400)
  )
  
  test_df <- as.data.frame(test_dt)
  
  # Test basic functionality
  test_that("basic functionality works", {
    # Test with data.table input
    result1 <- w2l_split(test_dt, cols2l = c("val1", "val2"))
    expect_type(result1, "list")
    expect_length(result1, 2)  # One for each value column
    expect_true(all(sapply(result1, data.table::is.data.table)))
    
    # Test with data.frame input
    result2 <- w2l_split(test_df, cols2l = c("val1", "val2"))
    expect_equal(result1, result2)
    
    # Verify content structure
    expect_equal(names(result1[[1]]), c("id", "group", "value"))
    expect_equal(nrow(result1[[1]]), 4)
  })
  
  # Test different parameter combinations
  test_that("parameter combinations work correctly", {
    # Test with by parameter
    result <- w2l_split(test_dt, cols2l = c("val1", "val2"), by = "group")
    expect_length(result, 4)  # 2 value columns × 2 groups
    expect_true(all(grepl("^(val1|val2)_[AB]$", names(result))))
    
    # Test with numeric indices
    result_num <- w2l_split(test_dt, cols2l = c(3, 4), by = 2)
    expect_equal(result, result_num)
    
    # Test with split_type = "df"
    result_df <- w2l_split(test_dt, cols2l = c("val1", "val2"), split_type = "df")
    expect_true(all(sapply(result_df, is.data.frame)))
    
    # Test with NULL cols2l
    result_null <- w2l_split(test_dt, cols2l = NULL, by = "group")
    expect_length(result_null, 2)  # One for each group
    expect_equal(sort(names(result_null)), c("A", "B"))
  })
  
  # Test custom separator
  test_that("custom separator works", {
    result <- w2l_split(test_dt, cols2l = c("val1", "val2"), by = "group", sep = ":")
    expect_true(all(grepl(":", names(result))))
  })
  
  # Test error handling
  test_that("error handling works correctly", {
    # Test invalid input type
    expect_error(
      w2l_split(list(a = 1)),
      "data must be a data.frame or data.table"
    )
    
    # Test invalid cols2l
    expect_error(
      w2l_split(test_dt, cols2l = "nonexistent"),
      "Some columns specified in cols2l are not present in the data"
    )
    
    expect_error(
      w2l_split(test_dt, cols2l = 10),
      "Numeric indices in cols2l are out of bounds"
    )
    
    # Test invalid by
    expect_error(
      w2l_split(test_dt, cols2l = c("val1", "val2"), by = "nonexistent"),
      "Some 'by' columns are not present in the data"
    )
    
    expect_error(
      w2l_split(test_dt, cols2l = c("val1", "val2"), by = 10),
      "Numeric indices in by are out of bounds"
    )
    
    # Test invalid split_type
    expect_error(
      w2l_split(test_dt, cols2l = c("val1", "val2"), split_type = "invalid"),
      "Invalid split_type provided"
    )
    
    # Test missing by when cols2l is NULL
    expect_error(
      w2l_split(test_dt, cols2l = NULL),
      "When cols2l is NULL, by parameter must be provided"
    )
  })
  
  # Test edge cases
  test_that("edge cases are handled correctly", {
    # Single column to split
    result <- w2l_split(test_dt, cols2l = "val1")
    expect_length(result, 1)
    
    # Single group
    result <- w2l_split(test_dt, cols2l = c("val1", "val2"), by = "id")
    expect_length(result, 8)  # 2 value columns × 4 ids
    
    # Empty data
    empty_dt <- test_dt[0,]
    result <- w2l_split(empty_dt, cols2l = c("val1", "val2"))
    expect_length(result, 0)
    expect_true(all(sapply(result, nrow) == 0))
  })
  
  # Test data content
  test_that("split data content is correct", {
    result <- w2l_split(test_dt, cols2l = c("val1", "val2"), by = "group")
    
    # Check values in split datasets
    val1_a <- result[["val1_A"]]
    expect_equal(val1_a$value, c(10, 20))
    
    val2_b <- result[["val2_B"]]
    expect_equal(val2_b$value, c(300, 400))
    
    # Check structure preservation
    expect_true(all(sapply(result, function(x) "value" %in% names(x))))
    expect_true(all(sapply(result, function(x) "id" %in% names(x))))
  })
  
  # Test with multiple grouping variables
  test_that("multiple grouping variables work correctly", {
    # Create test data with multiple grouping variables
    test_dt_multi <- data.table::data.table(
      id = 1:4,
      group1 = c("A", "A", "B", "B"),
      group2 = c("X", "Y", "X", "Y"),
      val1 = c(10, 20, 30, 40),
      val2 = c(100, 200, 300, 400)
    )
    
    result <- w2l_split(test_dt_multi, 
                        cols2l = c("val1", "val2"), 
                        by = c("group1", "group2"))
    
    expect_length(result, 8)  # 2 value columns × 2 group1 × 2 group2
    expect_true(all(grepl("^val[12]_[AB]_[XY]$", names(result))))
  })
})
```



# nest_cv
    
```{r function-nest_cv}
#' Apply Cross-Validation to Nested Data
#'
#' @description
#' The `nest_cv` function applies cross-validation splits to nested data frames or data tables within a data table. It uses the `rsample` package's `vfold_cv` function to create cross-validation splits for predictive modeling and analysis on nested datasets.
#'
#' @param nest_dt A `data.frame` or `data.table` containing at least one nested 
#' `data.frame` or `data.table` column.
#'   - Supports multi-level nested structures
#'   - Requires at least one nested data column
#' @inheritParams rsample::vfold_cv
#'
#' @details
#' The function performs the following steps:
#' \enumerate{
#'   \item Checks if the input `nest_dt` is non-empty and contains at least one nested column of `data.frame`s or `data.table`s.
#'   \item Identifies the nested columns and non-nested columns within `nest_dt`.
#'   \item Applies `rsample::vfold_cv` to each nested data frame in the specified nested column(s), creating the cross-validation splits.
#'   \item Expands the cross-validation splits and associates them with the non-nested columns.
#'   \item Extracts the training and validation data for each split and adds them to the output data table.
#' }
#'
#' If the `strata` parameter is provided, stratified sampling is performed during the cross-validation. Additional arguments can be passed to `rsample::vfold_cv` via `...`.
#' 
#' @return A `data.table` containing the cross-validation splits for each nested dataset. It includes:
#' \itemize{
#'   \item Original non-nested columns from `nest_dt`.
#'   \item `splits`: The cross-validation split objects returned by `rsample::vfold_cv`.
#'   \item `train`: The training data for each split.
#'   \item `validate`: The validation data for each split.
#' }
#'
#' @note
#' \itemize{
#'   \item The `nest_dt` must contain at least one nested column of `data.frame`s or `data.table`s.
#'   \item The function converts `nest_dt` to a `data.table` internally to ensure efficient data manipulation.
#'   \item The `strata` parameter should be a column name present in the nested data frames.
#'   \item If `strata` is specified, ensure that the specified column exists in all nested data frames.
#'   \item The `breaks` and `pool` parameters are used when `strata` is a numeric variable and control how stratification is handled.
#'   \item Additional arguments passed through `...` are forwarded to `rsample::vfold_cv`.
#' }
#'
#'
#' @seealso
#' \itemize{
#'   \item [`rsample::vfold_cv()`] Underlying cross-validation function
#'   \item [`rsample::training()`] Extract training set
#'   \item [`rsample::testing()`] Extract test set
#' }
#'
#' @import data.table
#' @importFrom rsample vfold_cv training testing
#' @export
#'
nest_cv <- function(nest_dt, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...) {
  # Initialize local variables to avoid global binding warnings
  cv_split <- data <- splits <- NULL
  
  # Validate input data is not empty
  if (nrow(nest_dt) == 0) {
    stop("Input 'nest_dt' cannot be empty")
  }
  
  # Identify nested data.frame or data.table columns
  nested_cols <- names(nest_dt)[sapply(nest_dt, function(x) {
    is.list(x) && all(sapply(x, function(y) {
      inherits(y, c("data.frame", "data.table"))
    }))
  })]
  
  # Ensure at least one nested column exists
  if (length(nested_cols) == 0) {
    stop("Input 'nest_dt' must contain at least one nested column of data.frames or data.tables")
  }
  
  # Check if "data" column exists in nested columns
  if (!"data" %in% nested_cols) {
    message("Available nested columns: ", paste(nested_cols, collapse = ", "))
    message("Using first nested column '", nested_cols[1], "' for cross-validation")
  }
  
  # Create a copy of input data to prevent modification of original dataset
  dt <- data.table::copy(nest_dt)
  
  # Identify nested list columns
  is_nested_list <- sapply(dt, function(x) all(vapply(x, is.list, logical(1))))
  
  # Extract non-nested column names
  non_nested_cols <- names(dt)[!is_nested_list]
  
  # Apply cross-validation with flexible stratification
  dt[, cv_split := lapply(get(nested_cols[1]), function(x) {
    if (!is.null(strata)) {
      rsample::vfold_cv(
        data = x, 
        v = v, 
        repeats = repeats,
        strata = strata,
        breaks = breaks, 
        pool = pool, 
        ...
      )
    } else {
      rsample::vfold_cv(
        data = x, 
        v = v, 
        repeats = repeats,
        breaks = breaks, 
        pool = pool, 
        ...
      )
    }
  })
  ][, cv_split[[1]], by = non_nested_cols
  ][, ':='(
    train = lapply(splits, \(x) rsample::training(x)),
    validate = lapply(splits, \(x) rsample::testing(x))
  )][]
}
```
  
```{r example-nest_cv}
# Example: Cross-validation for nested data.table demonstrations

# Setup test data
dt_nest <- w2l_nest(
  data = iris,                   # Input dataset
  cols2l = 1:2                   # Nest first 2 columns
)

# Example 1: Basic 2-fold cross-validation
nest_cv(
  nest_dt = dt_nest,             # Input nested data.table
  v = 2                          # Number of folds (2-fold CV)
)

# Example 2: Repeated 2-fold cross-validation
nest_cv(
  nest_dt = dt_nest,             # Input nested data.table
  v = 2,                         # Number of folds (2-fold CV)
  repeats = 2                    # Number of repetitions
)
```


```{r tests-nest_cv}
test_that("nest_cv functions correctly", {
  # Setup test data
  base_dt <- data.table::data.table(
    id = 1:100,
    group = rep(c("A", "B"), each = 50),
    value = rnorm(100),
    category = factor(rep(c("X", "Y"), times = 50))
  )
  
  # Create nested test data
  test_dt <- data.table::data.table(
    name = c("group1", "group2"),
    data = list(
      base_dt[group == "A"],
      base_dt[group == "B"]
    )
  )
  
  # Test basic functionality
  test_that("basic functionality works", {
    result <- nest_cv(test_dt, v = 5, repeats = 2)
    
    # Check structure
    expect_true(data.table::is.data.table(result))
    expect_true(all(c("name", "id", "splits", "train", "validate") %in% names(result)))
    expect_equal(nrow(result), 5 * 2 * 2)  # v * repeats * groups
    
    # Check content types
    expect_true(all(sapply(result$train, data.table::is.data.table)))
    expect_true(all(sapply(result$validate, data.table::is.data.table)))
    
    # Check split sizes
    first_fold <- result$train[[1]]
    expect_equal(nrow(first_fold), 40)  # 80% of 50 for training
    expect_equal(nrow(result$validate[[1]]), 10)  # 20% of 50 for validation
  })
  
  # Test with stratification
  test_that("stratification works correctly", {
    result <- nest_cv(test_dt, v = 5, repeats = 1, strata = "category")
    
    # Check if strata is maintained in splits
    first_train <- result$train[[1]]
    first_validate <- result$validate[[1]]
    
    # Check proportions in training and validation sets
    train_prop <- table(first_train$category) / nrow(first_train)
    validate_prop <- table(first_validate$category) / nrow(first_validate)
    expect_equal(train_prop, train_prop, tolerance = 0.1)
  })
  
  # Test with different parameters
  test_that("parameter variations work", {
    # Test with different v
    result_v3 <- nest_cv(test_dt, v = 3, repeats = 1)
    expect_equal(nrow(result_v3), 3 * 2)  # 3 folds * 2 groups
    
    # Test with different repeats
    result_r3 <- nest_cv(test_dt, v = 5, repeats = 3)
    expect_equal(nrow(result_r3), 5 * 3 * 2)  # 5 folds * 3 repeats * 2 groups
    
    # Test with different breaks
    result_breaks <- nest_cv(test_dt, v = 5, breaks = 3)
    expect_true(!is.null(result_breaks))
    
    # Test with different pool
    result_pool <- nest_cv(test_dt, v = 5, pool = 0.2)
    expect_true(!is.null(result_pool))
  })
  
  # Test error handling
  test_that("error handling works correctly", {
    # Test empty input
    empty_dt <- test_dt[0]
    expect_error(
      nest_cv(empty_dt),
      "Input 'nest_dt' cannot be empty"
    )
    
    # Test input without nested columns
    bad_dt <- data.table::data.table(a = 1:3, b = 4:6)
    expect_error(
      nest_cv(bad_dt),
      "Input 'nest_dt' must contain at least one nested column"
    )
  })
  
  # Test with multiple nested columns
  test_that("multiple nested columns work", {
    # Create test data with multiple nested columns
    multi_nest_dt <- data.table::data.table(
      name = c("group1", "group2"),
      data1 = list(
        base_dt[group == "A"],
        base_dt[group == "B"]
      ),
      data = list(
        base_dt[group == "A"],
        base_dt[group == "B"]
      )
    )
    
    result <- nest_cv(multi_nest_dt, v = 2)
    expect_true(!is.null(result))
    expect_true(all(c("name", "splits", "train", "validate") %in% names(result)))
  })
  
  # Test data consistency
  test_that("data consistency is maintained", {
    result <- nest_cv(test_dt, v = 5, repeats = 1)
    
    # Check that all original columns are preserved in splits
    first_train <- result$train[[1]]
    expect_true(all(names(base_dt) %in% names(first_train)))
    
    # Check that no observations are lost or duplicated
    for (i in seq_len(nrow(result))) {
      train_set <- result$train[[i]]
      validate_set <- result$validate[[i]]
      
      # Total number of observations should equal original group size
      expect_equal(nrow(train_set) + nrow(validate_set), 50)
      
      # No duplicates between train and validate
      train_ids <- train_set$id
      validate_ids <- validate_set$id
      expect_equal(length(intersect(train_ids, validate_ids)), 0)
    }
  })
  
  # Test reproducibility
  test_that("results are reproducible with seed", {
    set.seed(123)
    result1 <- nest_cv(test_dt, v = 5)
    
    set.seed(123)
    result2 <- nest_cv(test_dt, v = 5)
    
    expect_equal(result1, result2)
  })
  
  # Test with different data types
  test_that("handles different data types correctly", {
    # Create test data with various data types
    complex_dt <- data.table::data.table(
      id = 1:50,
      num = rnorm(50),
      int = 1:50,
      fct = factor(rep(letters[1:5], 10)),
      date = seq(as.Date("2024-01-01"), by = "day", length.out = 50),
      char = letters[1:50]
    )
    
    nested_complex <- data.table::data.table(
      name = "group1",
      data = list(complex_dt)
    )
    
    result <- nest_cv(nested_complex, v = 5)
    
    # Check that data types are preserved
    first_train <- result$train[[1]]
    expect_type(first_train$num, "double")
    expect_type(first_train$int, "integer")
    expect_s3_class(first_train$fct, "factor")
    expect_s3_class(first_train$date, "Date")
    expect_type(first_train$char, "character")
  })
})
```


# top_perc
    
```{r function-top_perc}
#' Select Top Percentage of Data and Statistical Summarization
#'
#' @description
#' The `top_perc` function selects the top percentage of data based on a specified trait and computes summary statistics.
#' It allows for grouping by additional columns and offers flexibility in the type of statistics calculated.
#' The function can also retain the selected data if needed.
#'
#' @param data A `data.frame` containing the source dataset for analysis
#'   - Supports various data frame-like structures
#'   - Automatically converts non-data frame inputs
#'
#' @param perc Numeric vector of percentages for data selection
#'   - Range: `-1` to `1`
#'   - Positive values: Select top percentiles
#'   - Negative values: Select bottom percentiles
#'   - Multiple percentiles supported
#'
#' @param trait Character string specifying the 'selection column'
#'   - Must be a valid column name in the input `data`
#'   - Used as the basis for top/bottom percentage selection
#'
#' @param by Optional character vector for 'grouping columns'
#'   - Default is `NULL`
#'   - Enables stratified analysis
#'   - Allows granular percentage selection within groups
#'
#' @param type Statistical summary type
#'   - Default: `"mean_sd"`
#'   - Controls the type of summary statistics computed
#'   - Supports various summary methods from `rstatix`
#'
#' @param keep_data Logical flag for data retention
#'   - Default: `FALSE`
#'   - `TRUE`: Return both summary statistics and selected data
#'   - `FALSE`: Return only summary statistics
#'
#' @return A list or data frame:
#' \itemize{
#'   \item If `keep_data` is FALSE, a data frame with summary statistics.
#'   \item If `keep_data` is TRUE, a list where each element is a list containing summary statistics (`stat`) and the selected top data (`data`).
#' }
#'
#' @note
#' \itemize{
#'   \item The `perc` parameter accepts values between -1 and 1. Positive values select the top percentage, while negative values select the bottom percentage.
#'   \item The function performs initial checks to ensure required arguments are provided and valid.
#'   \item Grouping by additional columns (`by`) is optional and allows for more granular analysis.
#'   \item The `type` parameter specifies the type of summary statistics to compute, with "mean_sd" as the default.
#'   \item If `keep_data` is set to TRUE, the function will return both the summary statistics and the selected top data for each percentage.
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`rstatix::get_summary_stats()`] Statistical summary computation
#'   \item [`dplyr::top_frac()`] Percentage-based data selection
#' }
#'
#' @importFrom purrr map set_names list_rbind
#' @importFrom dplyr group_by top_frac across all_of mutate
#' @importFrom rstatix get_summary_stats
#' @importFrom rlang sym
#' @export
top_perc <- function(data, perc, trait, by = NULL, type = "mean_sd", keep_data = FALSE) {
  # Initial checks and data preparation
  missing_args <- c()
  if (missing(data)) missing_args <- c(missing_args, "data")
  if (missing(perc)) missing_args <- c(missing_args, "perc")
  if (missing(trait)) missing_args <- c(missing_args, "trait")
  
  if (length(missing_args) > 0) {
    stop("Error: Missing argument(s): ", paste(missing_args, collapse=", "))
  }
  
  if (!inherits(data, "data.frame")) {
    message("Converting 'data' to data.frame")
    data <- as.data.frame(data)
  }
  
  # Ensure 'perc' is treated as a numeric vector
  perc <- as.numeric(perc)
  if (length(perc) == 0) {
    stop("Error: 'perc' must not be empty.")
  }
  if (any(perc < -1 | perc > 1)) {
    stop("Error: Each element of 'perc' must be a numeric value between -1 and 1.")
  }
  
  # Validate 'trait' parameter
  if (!is.character(trait) || length(trait) != 1) {
    stop("Error: 'trait' must be a single character string.")
  }
  if (!trait %in% names(data)) {
    stop("Error: 'trait' must be a valid column name in 'data'.")
  }
  
  # Validate 'by' parameter if not NULL
  if (!is.null(by)) {
    if (!is.character(by) || length(by) == 0) {
      stop("Error: 'by' must be a character vector of column names in 'data'.")
    }
    if (!all(by %in% names(data))) {
      stop("Error: All elements of 'by' must be valid column names in 'data'.")
    }
  }
  
  # Processing each percentage
  results <- purrr::map(perc, function(p) {
    grouped_data <- if (!is.null(by) && length(by) > 0) {
      data |> dplyr::group_by(dplyr::across(dplyr::all_of(by)))
    } else {
      data
    }
    
    top_data <- grouped_data |>
      dplyr::top_frac(p, !!rlang::sym(trait))
    
    # Always compute stats
    stats <- top_data |>
      rstatix::get_summary_stats(!!rlang::sym(trait), type = type) |>
      dplyr::mutate(top_perc = paste0(p * 100, "%"))
    
    # Return both stats and data if keep_data is TRUE
    if (keep_data) {
      list(stat = stats, data = top_data)
    } else {
      list(stat = stats)
    }
  }) |>
    purrr::set_names(paste(trait, perc, sep = "_"))
  
  # Simplify the output structure based on what is available in each result
  if (keep_data) {
    results
  } else {
    results <- purrr::map(results, "stat") |> purrr::list_rbind()
  }
  
  return(results)
}
```
  
```{r example-top_perc}
# Example 1: Basic usage with single trait
# This example selects the top 10% of observations based on Petal.Width
# keep_data=TRUE returns both summary statistics and the filtered data
top_perc(iris, 
         perc = 0.1,                # Select top 10%
         trait = c("Petal.Width"),  # Column to analyze
         keep_data = TRUE)          # Return both stats and filtered data

# Example 2: Using grouping with 'by' parameter
# This example performs the same analysis but separately for each Species
# Returns nested list with stats and filtered data for each group
top_perc(iris, 
         perc = 0.1,                # Select top 10%
         trait = c("Petal.Width"),  # Column to analyze
         by = "Species")            # Group by Species

# Example 3: Complex example with multiple percentages and grouping variables
# Reshape data from wide to long format for Sepal.Length and Sepal.Width
iris |> 
  tidyr::pivot_longer(1:2,
                      names_to = "names", 
                      values_to = "values") |> 
  mintyr::top_perc(
    perc = c(0.1, -0.2),
    trait = "values",
    by = c("Species", "names"),
    type = "mean_sd")
```


```{r tests-top_perc}
test_that("top_perc functions correctly", {
  # Setup test data
  set.seed(123)
  test_data <- data.frame(
    id = 1:100,
    group = rep(c("A", "B"), each = 50),
    value = rnorm(100, mean = 10, sd = 2),
    score = runif(100, 0, 100)
  )
  
  # Test basic functionality
  test_that("basic functionality works", {
    # Test with single percentage
    result1 <- top_perc(test_data, perc = 0.1, trait = "value")
    expect_true(is.data.frame(result1))
    expect_equal(nrow(result1), 1)
    expect_true(all(c("variable", "n", "mean", "sd", "top_perc") %in% names(result1)))
    
    # Test with multiple percentages
    result2 <- top_perc(test_data, perc = c(0.1, 0.2), trait = "value")
    expect_equal(nrow(result2), 2)
    expect_equal(result2$top_perc, c("10%", "20%"))
  })
  
  # Test grouping functionality
  test_that("grouping works correctly", {
    result <- top_perc(test_data, perc = 0.1, trait = "value", by = "group")
    expect_equal(nrow(result), 2)  # One row per group
    expect_true("group" %in% names(result))
    
    # Test multiple grouping variables
    test_data$subgroup <- rep(c("X", "Y"), 50)
    result_multi <- top_perc(test_data, perc = 0.1, trait = "value", by = c("group", "subgroup"))
    expect_equal(nrow(result_multi), 4)  # 2 groups × 2 subgroups
  })
  
  # Test keep_data parameter
  test_that("keep_data parameter works", {
    result <- top_perc(test_data, perc = 0.1, trait = "value", keep_data = TRUE)
    expect_true(is.list(result))
    expect_true(all(c("stat", "data") %in% names(result[[1]])))
    expect_true(is.data.frame(result[[1]]$data))
    expect_true(is.data.frame(result[[1]]$stat))
    
    # Check data size
    expect_equal(nrow(result[[1]]$data), ceiling(nrow(test_data) * 0.1))
  })
  
  # Test different summary types
  test_that("summary types work correctly", {
      result_mean_sd <- top_perc(test_data, perc = 0.1, trait = "value", type = "mean_sd")
      result_median_iqr <- top_perc(test_data, perc = 0.1, trait = "value", type = "median_iqr")
      
      expect_true(all(c("mean", "sd") %in% names(result_mean_sd)))
      expect_true(all(c("median", "iqr") %in% names(result_median_iqr)))
    })
    
  # Test error handling
  test_that("error handling works correctly", {
      # Missing arguments
      expect_error(top_perc(perc = 0.1, trait = "value"), "Missing argument.*data")
      expect_error(top_perc(data = test_data, trait = "value"), "Missing argument.*perc")
      expect_error(top_perc(data = test_data, perc = 0.1), "Missing argument.*trait")
      
      # Invalid perc values
      expect_error(top_perc(test_data, perc = 1.5, trait = "value"),
                   "must be.*between -1 and 1")
      expect_error(top_perc(test_data, perc = -1.5, trait = "value"),
                   "must be.*between -1 and 1")
      
      # Invalid trait
      expect_error(top_perc(test_data, perc = 0.1, trait = "nonexistent"),
                   "must be a valid column name")
      expect_error(top_perc(test_data, perc = 0.1, trait = c("value", "score")),
                   "must be a single character string")
      
      # Invalid by
      expect_error(top_perc(test_data, perc = 0.1, trait = "value", by = "nonexistent"),
                   "must be valid column names")
      expect_error(top_perc(test_data, perc = 0.1, trait = "value", by = 1),
                   "must be a character vector")
    })
    
  # Test data type handling
  test_that("handles different data types correctly", {
      # Test with data.table
      dt_data <- data.table::as.data.table(test_data)
      result_dt <- top_perc(dt_data, perc = 0.1, trait = "value")
      expect_true(is.data.frame(result_dt))
      
      # Test with tibble
      tbl_data <- tibble::as_tibble(test_data)
      result_tbl <- top_perc(tbl_data, perc = 0.1, trait = "value")
      expect_true(is.data.frame(result_tbl))
    })
    
  # Test edge cases
  test_that("edge cases are handled correctly", {
      # Test with 100% selection
      result_all <- top_perc(test_data, perc = 1, trait = "value")
      expect_equal(nrow(result_all), 1)
      
      # Test with very small percentage
      result_min <- top_perc(test_data, perc = 0.01, trait = "value")
      expect_equal(nrow(result_min), 1)
      
      # Test with NA values
      test_data_na <- test_data
      test_data_na$value[1:10] <- NA
      result_na <- top_perc(test_data_na, perc = 0.1, trait = "value")
      expect_true(!is.na(result_na$n))
    })
    
  # Test result consistency
  test_that("results are consistent", {
      # Test that top percentage actually contains top values
      result <- top_perc(test_data, perc = 0.1, trait = "value", keep_data = TRUE)
      top_values <- result[[1]]$data$value
      all_values <- test_data$value
      
      expect_true(min(top_values) >= quantile(all_values, 0.9, na.rm = TRUE))
      
      # Test that grouping preserves correct proportions
      result_grouped <- top_perc(test_data, perc = 0.1, trait = "value", 
                                 by = "group", keep_data = TRUE)
      for (group in unique(test_data$group)) {
        group_data <- result_grouped[[paste0("value_0.1")]]$data
        group_count <- sum(group_data$group == group)
        expect_equal(group_count, ceiling(sum(test_data$group == group) * 0.1))
      }
    })
    })
```

<!-- 
# Inflate your package

You're one inflate from paper to box.
Build your package from this very Rmd using `fusen::inflate()` 
-->


```{r development-inflate, eval=FALSE}
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_teaching.Rmd")
```

<!-- 
- Verify your `"DESCRIPTION"` file has been updated
- Verify your function is in `"R/"` directory
- Verify your test is in `"tests/testthat/"` directory
- Verify this Rmd appears in `"vignettes/"` directory 
-->
