---
title: "flat_teaching.Rmd for working package"
output: html_document
editor_options: 
  chunk_output_type: console
---

<!-- 
Run this 'development' chunk

Store every call to library() that you need to run chunks line by line, as in a classical Rmd for analysis
-->

```{r development, include=FALSE}
library(testthat)
library(roxygen2)
```

<!--
# Description of your package

This will fill the description of your package.
Fill and run the content of this chunk, before anything else. 

Note: when you will use other flat templates, this part will be in a separate file. Do not be surprised!
--> 

```{r description, eval=FALSE}
# Describe your package
fusen::fill_description(
  pkg = here::here(),
  fields = list(
    Title = "Tools commonly used in personal data processing work",
    Description = "A Set of tools to understand packages structure. Use Rmarkdown First method to build a package from a defined template. Start your package with documentation. Everything can be set from a Rmarkdown file in your project.",
    `Authors@R` = c(
      person("Guo Meng", email = "tony2015116@163.com", role = c("aut", "cre")),
      person(given = "Guo Meng", role = "cph")
    )
  ), overwrite = T
)
# Define License with use_*_license()
usethis::use_mit_license("Guo Meng")
```


# split_cv
    
```{r function-split_cv}
#' Cross-Validation Split Generator
#'
#' @description
#' A robust cross-validation splitting utility for multiple datasets with advanced stratification and configuration options.
#'
#' @param split_dt 'list' of input datasets
#'   - Must contain 'data.frame' or 'data.table' elements
#'   - Supports multiple dataset processing
#'   - Cannot be empty
#' @inheritParams rsample::vfold_cv
#' 
#' @details
#' Advanced Cross-Validation Mechanism:
#' \enumerate{
#'   \item Input dataset validation
#'   \item Stratified or unstratified sampling
#'   \item Flexible fold generation
#'   \item Train-validate set creation
#' }
#'
#' Sampling Strategies:
#' \itemize{
#'   \item Supports multiple dataset processing
#'   \item Handles stratified and unstratified sampling
#'   \item Generates reproducible cross-validation splits
#' }
#'
#' Computational Considerations:
#' \itemize{
#'   \item Computational complexity increases with 'v' and 'repeats'
#'   \item Memory efficiency for large datasets
#'   \item Preserves original data structure
#' }
#'
#' @return 'list' of 'data.table' objects containing:
#'   \itemize{
#'     \item 'splits': Cross-validation split objects
#'     \item 'id': Fold identifiers
#'     \item 'id2': Repeat identifiers
#'     \item 'train': Training dataset subsets
#'     \item 'validate': Validation dataset subsets
#'   }
#'
#' @note Important Constraints:
#' \itemize{
#'   \item Requires non-empty input datasets
#'   \item All datasets must be 'data.frame' or 'data.table'
#'   \item Strata column must exist if specified
#'   \item Computational resources impact large dataset processing
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`rsample::vfold_cv()`] Core cross-validation function
#' }
#'
#' @import data.table
#' @importFrom rsample vfold_cv
#' @export
split_cv <- function(split_dt, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...) {
  splits <- NULL
  # Input validation
  if (!is.list(split_dt)) {
    stop("split_dt must be a list")
  }

  if (length(split_dt) == 0) {
    stop("The input split_dt cannot be empty")
  }

  # Check if all elements are data.frames or data.tables
  is_valid <- all(sapply(split_dt, function(x) {
    inherits(x, c("data.frame", "data.table"))
  }))

  if (!is_valid) {
    stop("All elements in split_dt must be data.frames or data.tables")
  }

  # Initialize result list
  result <- vector("list", length(split_dt))
  names(result) <- names(split_dt)

  # Process each element in the list
  for (i in seq_along(split_dt)) {
    current_data <- split_dt[[i]]

    # Convert to data.table if not already
    if (!data.table::is.data.table(current_data)) {
      current_data <- data.table::as.data.table(current_data)
    }

    # Create CV splits
    if (!is.null(strata)) {
      if (!strata %in% names(current_data)) {
        warning(sprintf("Strata variable '%s' not found in dataset %s, performing unstratified CV",
                        strata, names(split_dt)[i]))
        cv_obj <- rsample::vfold_cv(
          data = current_data,
          v = v,
          repeats = repeats,
          breaks = breaks,
          pool = pool,
          ...
        )
      } else {
        cv_obj <- rsample::vfold_cv(
          data = current_data,
          v = v,
          repeats = repeats,
          strata = strata,
          breaks = breaks,
          pool = pool,
          ...
        )
      }
    } else {
      cv_obj <- rsample::vfold_cv(
        data = current_data,
        v = v,
        repeats = repeats,
        breaks = breaks,
        pool = pool,
        ...
      )
    }

    # Create result data.table
    result_dt <- data.table::data.table(
      splits = cv_obj$splits,
      id = cv_obj$id,
      id2 = cv_obj$id2
    )

    # Add train and validate sets
    result_dt[, `:=`(
      train = lapply(splits, function(x) rsample::training(x)),
      validate = lapply(splits, function(x) rsample::testing(x))
    )]

    result[[i]] <- result_dt
  }

  return(result)
}
```
  
```{r example-split_cv}
dt_split <- w2l_split(data = iris, cols2l = 1:2, by = "Species")
split_cv(split_dt = dt_split, v = 3, repeats = 2)
```


# c2p_nest
    
```{r function-c2p_nest}
#' Column to Pair Nested Transformation
#'
#' @description
#' A sophisticated data transformation tool for generating column pair combinations 
#' and creating nested data structures with advanced configuration options.
#'
#' @param data Input 'data frame' or 'data table'
#'   - Must contain valid columns for transformation
#'   - Supports multiple data types
#'
#' @param cols2bind 'character' vector of column names for pair generation
#'   - Specifies target columns for combination
#'   - Must be existing columns in the dataset
#'
#' @param by Optional 'character' vector for grouping
#'   - Enables hierarchical nested transformations
#'   - Supports multi-level aggregation
#'   - Default is `NULL`
#'
#' @param pairs_n 'numeric' indicating combination size
#'   - Minimum value: 2
#'   - Maximum value: Length of `cols2bind`
#'   - Controls column pair complexity
#'   - Default is 2
#'
#' @param sep 'character' separator for pair naming
#'   - Used in generating combination identifiers
#'   - Must be a single character
#'   - Default is "-"
#'
#' @param nest_type Output nesting format
#'   - `'dt'`: Returns nested 'data table' (default)
#'   - `'df'`: Returns nested 'data frame'
#'
#' @details
#' Advanced Transformation Mechanism:
#' \enumerate{
#'   \item Input validation and preprocessing
#'   \item Dynamic column combination generation
#'   \item Flexible pair transformation
#'   \item Nested data structure creation
#' }
#'
#' Transformation Process:
#' \itemize{
#'   \item Validate input parameters
#'   \item Generate column combinations
#'   \item Create subset data tables
#'   \item Merge and nest transformed data
#' }
#'
#' Combination Strategy:
#' \itemize{
#'   \item Supports variable-length column combinations
#'   \item Generates all possible column pair permutations
#'   \item Maintains original data context
#' }
#'
#' @return 'data table' containing nested transformation results
#'   - Includes 'pairs' column identifying column combinations
#'   - Contains 'data' column storing nested data structures
#'   - Supports optional grouping variables
#'
#' @note Key Operation Constraints:
#' \itemize{
#'   \item Requires non-empty input data
#'   \item `cols2bind` must specify existing columns
#'   \item Supports flexible combination strategies
#'   \item Computational complexity increases with combination size
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`utils::combn()`] Combination generation
#'   \item [`data.table::rbindlist()`] List binding utility
#'   \item [`data.table::copy()`] Data copying mechanism
#' }
#'
#' @import data.table
#' @importFrom utils combn
#' @export
c2p_nest <- function(data, cols2bind, by = NULL, pairs_n = 2, sep = "-", nest_type = "dt") {
  . <- pairs <- NULL  # For data.table's NSE
  
  # Validate inputs
  if (!inherits(data, c("data.table", "data.frame"))) {
    stop("data must be a data.table or a data.frame")
  }
  data <- data.table::as.data.table(data)
  
  if (!is.character(cols2bind)) {
    stop("cols2bind must be a character vector")
  }
  missing_cols <- cols2bind[!cols2bind %in% names(data)]
  if (length(missing_cols) > 0) {
    stop("Some columns specified in cols2bind are not present in the data: ", paste(missing_cols, collapse=", "))
  }
  
  # Validate pairs_n
  if (!is.numeric(pairs_n) || pairs_n < 2 || floor(pairs_n) != pairs_n) {
    stop("pairs_n must be a positive integer greater than or equal to 2")
  }
  
  # Check if pairs_n is less than or equal to the number of available columns
  if (pairs_n > length(cols2bind)) {
    stop(sprintf("pairs_n (%d) cannot be larger than the number of available columns (%d)", 
                 pairs_n, length(cols2bind)))
  }
  
  if (!is.character(sep) || length(sep) != 1) {
    stop("sep must be a single character string")
  }
  
  if (!is.null(by)) {
    if (!is.character(by)) {
      stop("'by' must be a character vector of column names.")
    }
    missing_by_vars <- by[!by %in% names(data)]
    if (length(missing_by_vars) > 0) {
      stop("Grouping variables not present in data: ", paste(missing_by_vars, collapse=", "))
    }
  }
  
  if (!nest_type %in% c("dt", "df")) {
    stop("Invalid nest_type provided. It must be either 'dt' or 'df'.")
  }
  
  # Prepare data for combination operations
  dt <- data.table::copy(data)  # Copy the data to avoid modifying the original
  
  fixed_cols <- setdiff(names(dt), cols2bind)
  comb_cols_list <- combn(cols2bind, pairs_n, simplify=FALSE)
  
  list_of_dts <- lapply(comb_cols_list, function(comb) {
    dt_subset <- dt[, c(fixed_cols, comb), with=FALSE]
    # Create pairs identifier
    pairs_name <- paste(comb, collapse=sep)
    # Rename the combination columns to 'value1', 'value2', etc.
    data.table::setnames(dt_subset, comb, paste0('value', seq_along(comb)))
    # Add 'pairs' column
    dt_subset[, pairs := pairs_name]
    dt_subset
  })
  
  dt_bind <- data.table::rbindlist(list_of_dts)
  
  # Determine grouping variables
  if (!is.null(by) && length(by) > 0) {
    groupby <- c("pairs", by)
  } else {
    groupby <- "pairs"
  }
  
  # Nest the data based on nest_type
  if (nest_type == "dt") {
    result <- dt_bind[, .(data = list(.SD)), by = groupby]
  } else if (nest_type == "df") {
    result <- dt_bind[, .(data = list(as.data.frame(.SD))), by = groupby]
  } else {
    stop("Invalid nest_type provided. It must be either 'dt' or 'df'.")
  }
  
  return(result)
}
```
  
```{r example-c2p_nest}
col_names <- c("Sepal.Length", "Sepal.Width", "Petal.Length")
c2p_nest(iris, cols2bind = col_names, pairs_n = 2, sep = "&")
c2p_nest(iris, cols2bind = col_names, pairs_n = 2, by = "Species")
```


# r2p_nest
    
```{r function-r2p_nest}
#' Row to Pair Nested Transformation
#'
#' @description
#' A flexible data transformation tool for performing row pair conversion 
#' and nesting operations across multiple columns.
#'
#' @param data Input 'data frame' or 'data table'
#'   - Must contain valid columns for transformation
#'   - Supports multiple data types
#'
#' @param rows2bind 'character' or 'numeric' column name/index for row binding
#'   - Specifies target row binding column
#'   - Must be a single column identifier
#'
#' @param by 'character' or 'numeric' column name/index vector
#'   - Columns used for nested pairing
#'   - Must specify at least one column
#'   - Supports multi-column transformation
#'
#' @param nest_type Output nesting format
#'   - `'dt'`: Returns nested 'data table' (default)
#'   - `'df'`: Returns nested 'data frame'
#'
#' @details
#' Advanced Transformation Mechanism:
#' \enumerate{
#'   \item Input validation and preprocessing
#'   \item Dynamic column identification
#'   \item Flexible row pairing across specified columns
#'   \item Nested data structure generation
#' }
#'
#' Transformation Process:
#' \itemize{
#'   \item Convert input to 'data table'
#'   \item Reshape data from wide to long format
#'   \item Perform column-wise nested transformation
#'   \item Support multi-column processing
#' }
#'
#' Index and Column Selection:
#' \itemize{
#'   \item Accepts column names and numeric indices
#'   \item Validates column existence
#'   \item Handles single and multiple column scenarios
#' }
#'
#' @return 'data table' containing nested transformation results
#'   - Includes 'name' column identifying source columns
#'   - Contains 'data' column storing nested data structures
#'
#' @note Key Operation Constraints:
#' \itemize{
#'   \item Requires non-empty input data
#'   \item `by` parameter must specify at least one column
#'   \item Supports flexible column identification
#'   \item Low computational overhead
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`data.table::melt()`] Long format conversion
#'   \item [`data.table::dcast()`] Wide format conversion
#'   \item [`base::rbind()`] Row binding utility
#' }
#'
#' @import data.table
#' @importFrom stats as.formula
#' @export
r2p_nest <- function(data, rows2bind, by, nest_type = "dt") {
  # Input validation
  if (length(by) < 1) {
    stop("At least one column must be specified in 'by'")
  }
  if (length(rows2bind) != 1) {
    stop("rows2bind must be a single column")
  }

  # Convert data to data.table first
  data <- as.data.table(data)

  # Validate column existence and indices
  if (is.numeric(by)) {
    if (any(by > ncol(data) | by < 1)) {
      stop("Invalid column indices in by")
    }
  } else if (!all(by %in% names(data))) {
    stop("Specified by columns not found in data")
  }

  if (is.numeric(rows2bind)) {
    if (rows2bind > ncol(data) | rows2bind < 1) {
      stop("Invalid column index in rows2bind")
    }
  } else if (!rows2bind %in% names(data)) {
    stop("Specified rows2bind not found in data")
  }

  # Process each column in 'by'
  result_list <- lapply(by, function(x) {
    row_pair_init(
      data = data,
      rows2bind = rows2bind,
      by = x,
      nest_type = nest_type
    )
  })

  # Combine all results using rbindlist
  combined_result <- rbindlist(result_list)

  return(combined_result)
}
row_pair_init <- function (data, rows2bind, by, nest_type = "dt") {
  . <- NULL
  # Convert numeric indices to column names
  if (is.numeric(by)) {
    by <- names(data)[by]
  }
  if (is.numeric(rows2bind)) {
    rows2bind <- names(data)[rows2bind]
  }

  # Get ID columns (all columns except 'by' columns)
  id_cols <- setdiff(names(data), by)

  # Reshape data from wide to long format
  long_dt <- melt(data,
                  id.vars = id_cols,
                  measure.vars = by,
                  variable.name = "name",
                  value.name = "value")

  # Get columns for formula creation
  other_ids <- setdiff(id_cols, rows2bind)

  # Create formula string for dcast
  formula_str <- paste(paste(c("name", other_ids), collapse = " + "),
                       rows2bind, sep = " ~ ")

  # Reshape data from long to wide format
  wide_dt <- dcast(long_dt, as.formula(formula_str), value.var = "value")

  # Create nested output based on nest_type
  if (nest_type == "dt") {
    result <- wide_dt[, .(data = list(.SD)), by = "name"]
  }
  else if (nest_type == "df") {
    result <- wide_dt[, .(data = list(as.data.frame(.SD))),
                      by = "name"]
  }
  else {
    stop("Invalid nest_type provided. It must be either 'dt' or 'df'.")
  }

  return(result)
}
```

```{r example-r2p_nest}
# Sample data
data <- data.frame(
  breed = c("A", "B", "A", "B"), 
  sex = c("F", "F", "M", "M"), 
  trait1 = c(1.1, 2.1, 3.5, 4.6),
  trait2 = c(5.2, 6.6, 7.3, 8.6))
data
# Method 1: Using r2p_nest() with data.table
# Combine by breed, grouping traits
r2p_nest(data, rows2bind = "breed", by = "trait1")
# Return as data frame nested structure
r2p_nest(data, rows2bind = "breed", by = c("trait1", "trait2"), nest_type = "df")
# Method 2: Using tidyr and dplyr for similar transformation
data |>
  tidyr::pivot_longer(cols = c("trait1"), names_to = "name", values_to = "value") |>
  tidyr::pivot_wider(names_from = "breed", values_from = "value") |>
  dplyr::group_nest(name)
```


# export_nest
    
```{r function-export_nest}
#' Export Nested Data with Advanced Grouping and Flexible Handling
#'
#' @description
#' Exports nested data from a `data.frame` or `data.table` with sophisticated grouping 
#' capabilities, supporting multiple nested column types and flexible file export options.
#'
#' @param nest_dt A `data.frame` or `data.table` containing nested columns of `data.frame`s, 
#'   `data.table`s, or lists to be exported.
#' @param group_cols Optional character vector specifying grouping columns. 
#'   If `NULL`, uses all non-nested columns as grouping variables.
#' @param nest_col Optional character string indicating the nested column to export. 
#'   If `NULL`, automatically selects the first nested column.
#' @param export_path Base directory path for file export. Defaults to a temporary directory 
#'   created by `tempdir()`.
#' @param file_type File export format, either `"txt"` (tab-separated) or `"csv"`. 
#'   Defaults to `"txt"`.
#'
#' @details
#' Comprehensive Nested Data Export Features:
#' \itemize{
#'   \item Automatic detection and handling of different nested column types
#'   \item Flexible grouping strategies with intelligent column selection
#'   \item Hierarchical directory structure generation based on grouping columns
#'   \item Support for mixed nested column types (`data.frame`, `data.table`, `list`)
#'   \item Multi-threaded file writing for enhanced performance
#'   \item Informative messaging and warning system
#' }
#'
#' Nested Column Detection Hierarchy:
#' \enumerate{
#'   \item Prioritizes `data.frame`/`data.table` nested columns
#'   \item Falls back to regular `list` columns if no `data.frame` columns exist
#' }
#'
#' Grouping Column Selection Strategy:
#' \enumerate{
#'   \item When `group_cols` is `NULL`, uses all non-nested columns
#'   \item Provides warnings about unused non-nested columns
#'   \item Validates provided group columns
#' }
#'
#' File Export Characteristics:
#' \itemize{
#'   \item Supports `"txt"` (tab-separated) and `"csv"` formats
#'   \item Uses multi-threading via `parallel::detectCores()`
#'   \item Creates nested directory structure based on grouping variables
#' }
#'
#' @return 
#' An `integer` representing the total number of files exported successfully.
#'
#' @note
#' Key Capabilities:
#' \itemize{
#'   \item Handles complex nested data structures
#'   \item Performs type conversion for nested content
#'   \item Utilizes multi-threaded file export for optimal performance
#'   \item Provides comprehensive column selection feedback
#' }
#'
#' @examples
#' \dontrun{
#' library(data.table)
#' 
#' # Create sample nested data
#' nested_data <- `data.table`(
#'   group = c("A", "B", "A"),
#'   subgroup = c(1, 2, 3),
#'   data = list(
#'     `data.frame`(x = 1:3, y = 4:6),
#'     `data.frame`(x = 7:9, y = 10:12),
#'     `data.frame`(x = 13:15, y = 16:18)
#'   )
#' )
#' 
#' # Export nested data with default settings
#' export_nest(nested_data)
#' 
#' # Export with specific grouping and file type
#' export_nest(
#'   nested_data, 
#'   group_cols = c("group"),
#'   nest_col = "data", 
#'   file_type = `"csv"`
#' )
#' }
#'
#' @importFrom data.table as.data.table fwrite
#' @importFrom parallel detectCores
#' @export
export_nest <- function(nest_dt, group_cols = NULL, nest_col = NULL,
                        export_path = tempdir(), file_type = "txt") {
  # Basic input validation
  if (nrow(nest_dt) == 0) {
    stop("The input nest_dt cannot be empty")
  }

  # Check and get nested columns
  # 1. Check for data.frame/data.table nested columns
  df_nested_cols <- names(nest_dt)[sapply(nest_dt, function(x) {
    is.list(x) && all(sapply(x, function(y) {
      inherits(y, c("data.frame", "data.table"))
    }))
  })]

  # 2. Check for regular list columns
  list_cols <- names(nest_dt)[vapply(nest_dt, is.list, logical(1))]

  # Combine both types of nested columns
  nested_cols <- unique(c(df_nested_cols, list_cols))

  if (length(nested_cols) == 0) {
    stop("The input nest_dt must contain at least one nested column")
  }

  # If nest_col is NULL, prioritize using data.frame/data.table nested columns
  if (is.null(nest_col)) {
    if (length(df_nested_cols) > 0) {
      nest_col <- df_nested_cols[1]
      message("Using first nested data.frame/data.table column: ", nest_col)
    } else {
      nest_col <- list_cols[1]
      message("Using first list column: ", nest_col)
    }
  } else if (!nest_col %in% nested_cols) {
    stop("Specified nest_col is not a valid nested column")
  }

  # If group_cols is NULL, use all non-nested columns
  if (is.null(group_cols)) {
    group_cols <- setdiff(names(nest_dt), nested_cols)
    message("Using all non-nested columns as groups: ", paste(group_cols, collapse = ", "))
  } else {
    # Validate user-provided group columns
    if (!is.character(group_cols)) {
      stop("group_cols must be a character vector")
    }
    missing_cols <- setdiff(group_cols, names(nest_dt))
    if (length(missing_cols) > 0) {
      stop("The following group columns are missing: ", paste(missing_cols, collapse = ", "))
    }

    # Check if all non-nested columns are used as group columns
    all_non_nested_cols <- setdiff(names(nest_dt), nested_cols)
    unused_cols <- setdiff(all_non_nested_cols, group_cols)
    if (length(unused_cols) > 0) {
      warning("Not all non-nested columns are used as group columns. ",
              "The exported data may be incomplete without the following columns: ",
              paste(unused_cols, collapse = ", "))
    }
  }

  # Parameter validation
  file_type <- tolower(file_type)
  if (!(file_type %in% c("txt", "csv"))) {
    stop("file_type must be either 'txt' or 'csv'")
  }

  if (!is.character(export_path) || length(export_path) != 1) {
    stop("export_path must be a single character string")
  }

  # Create export directory
  dir.create(export_path, showWarnings = FALSE, recursive = TRUE)

  # Export processing
  tryCatch({
    # Process and expand nested data
    expanded_dt <- nest_dt[, {
      processed_nests <- lapply(get(nest_col), function(x) {
        if (inherits(x, c("data.frame", "data.table"))) {
          x_dt <- if (!is.data.table(x)) as.data.table(x) else x
          setattr(x_dt, "row.names", .set_row_names(nrow(x_dt)))
          return(x_dt)
        } else {
          # Try to convert non-data.frame/data.table to data.table
          tryCatch({
            x_dt <- as.data.table(as.list(x))
            setattr(x_dt, "row.names", .set_row_names(nrow(x_dt)))
            return(x_dt)
          }, error = function(e) {
            stop(sprintf("Cannot convert nested content to data.table: %s", e$message))
          })
        }
      })
      data.table::rbindlist(processed_nests, fill = TRUE)
    }, by = group_cols]

    expanded_dt <- copy(expanded_dt)

    # Create required subdirectories
    unique_paths <- unique(expanded_dt[, do.call(file.path,
                                                 c(list(export_path), lapply(group_cols, function(col) get(col))))])
    lapply(unique_paths, dir.create, showWarnings = FALSE, recursive = TRUE)

    # Export files
    file_count <- 0L
    expanded_dt[, {
      dir_path <- do.call(file.path, c(list(export_path),
                                       lapply(group_cols, function(col) get(col))))
      sep <- if (file_type == "txt") "\t" else ","
      filename <- paste0(nest_col, ".", file_type)
      fwrite(.SD, file = file.path(dir_path, filename),
             sep = sep, nThread = parallel::detectCores() - 1, buffMB = 32)
      file_count <<- file_count + 1L
      NULL
    }, by = group_cols]

    return(file_count)
  }, error = function(e) {
    stop("Failed to export nested data: ", e$message)
  })
}
```
  
```{r example-export_nest}
# Data Nesting Operation
dt_nest <- w2l_nest(data = iris, cols2l = 1:2, by = "Species")
# Export Nested Data
export_nest(nest_dt = dt_nest, nest_col = "data",
            group_cols = c("name", "Species"))
# Check Export Results
files <- list.files(path = tempdir(), pattern = "txt", recursive = TRUE, full.names = TRUE)
files
file.remove(files)
```


# export_list
    
```{r function-export_list}
#' Export List of `data.frame`s/`data.table`s with Advanced Directory Management
#'
#' @description
#' Exports a list of `data.frame`s, `data.table`s, or compatible data structures 
#' with sophisticated directory handling, flexible naming, and multiple file format support.
#'
#' @param split_dt A `list` of `data.frame`s, `data.table`s, or compatible data structures 
#'   to be exported.
#' @param export_path Base directory path for file export. Defaults to a temporary directory 
#'   created by `tempdir()`.
#' @param file_type File export format, either `"txt"` (tab-separated) or `"csv"`. 
#'   Defaults to `"txt"`.
#'
#' @details
#' Comprehensive List Export Features:
#' \itemize{
#'   \item Advanced nested directory structure support based on list element names
#'   \item Intelligent handling of unnamed list elements
#'   \item Automatic conversion to `data.table` for consistent export
#'   \item Hierarchical directory creation with nested path names
#'   \item Multi-format file export with intelligent separator selection
#'   \item Robust error handling and input validation
#' }
#'
#' Naming and Directory Creation Strategy:
#' \enumerate{
#'   \item Unnamed list elements automatically assigned default names (e.g., `"split_1"`)
#'   \item Nested path names (containing `"/"`) dynamically create corresponding subdirectories
#'   \item Automatic generation of required export directories
#' }
#'
#' Data Conversion and Processing Characteristics:
#' \enumerate{
#'   \item Automatic conversion to `data.table` for consistent processing
#'   \item Preservation of original data structure during export
#'   \item Flexible support for various input data types
#' }
#'
#' File Export Capabilities:
#' \itemize{
#'   \item Supports `"txt"` (tab-separated) and `"csv"` formats
#'   \item Intelligent file naming based on list element names
#'   \item Handles complex nested directory structures
#'   \item Efficient file writing using `data.table::fwrite()`
#' }
#'
#' @return 
#' An `integer` representing the total number of files exported successfully.
#'
#' @note
#' Key Capabilities:
#' \itemize{
#'   \item Flexible list naming and directory management
#'   \item Comprehensive support for `data.frame` and `data.table` inputs
#'   \item Intelligent default naming for unnamed elements
#'   \item High-performance file writing mechanism
#' }
#'
#' @importFrom data.table fwrite as.data.table
#' @importFrom utils head tail
#' @export

export_list <- function(split_dt, export_path = tempdir(), file_type = "txt") {
  # Input validation
  if (!is.list(split_dt)) {
    stop("split_dt must be a list of data.tables/data.frames")
  }

  file_type <- match.arg(file_type, c("txt", "csv"))

  # Define separator mapping for file types
  sep_map <- c(txt = "\t", csv = ",")

  # Create base export directory if it doesn't exist
  dir.create(export_path, recursive = TRUE, showWarnings = FALSE)

  # Initialize counter
  count <- 0L

  # Process each element in the list
  exported_files <- vapply(seq_along(split_dt), function(i) {
    current_data <- split_dt[[i]]
    current_name <- names(split_dt)[i]

    current_name <- if (is.null(current_name) || current_name == "") {
      paste0("split_", i)
    } else {
      current_name
    }

    # Handle path components
    if (grepl("/", current_name)) {
      path_components <- strsplit(current_name, "/")[[1]]
      file_name <- tail(path_components, 1)
      sub_dirs <- head(path_components, -1)

      full_path <- file.path(export_path, paste(sub_dirs, collapse = "/"))
      dir.create(full_path, recursive = TRUE, showWarnings = FALSE)
    } else {
      file_name <- current_name
      full_path <- export_path
    }

    file_path <- file.path(full_path, paste0(file_name, ".", file_type))

    if (!data.table::is.data.table(current_data)) {
      current_data <- data.table::as.data.table(current_data)
    }

    data.table::fwrite(current_data,
                       file = file_path,
                       sep = sep_map[file_type],
                       quote = TRUE)

    # Increment counter
    count <<- count + 1L

    file_path
  }, character(1))

  names(exported_files) <- names(split_dt)

  # Return count
  return(count)

  invisible(exported_files)
}
```
  
```{r example-export_list}
# Data Nesting Operation
dt_split <- w2l_split(data = iris, cols2l = 1:2, by = "Species")
# Export Nested Data
export_list(split_dt = dt_split)
# Check Export Results
files <- list.files(path = tempdir(), pattern = "txt", recursive = TRUE, full.names = TRUE)
files
file.remove(files)
```


# fires
    
```{r function-fires}
#' Update Fire Dataset with Current Date
#'
#' @description
#' This function creates a copy of the fire dataset and adjusts the dates 
#' to align with the current date while maintaining the original date patterns.
#'
#' @details
#' The function performs the following operations:
#' \itemize{
#'   \item Creates a copy of the fire dataset from the mintyr package
#'   \item Calculates the number of days between the last recorded date and the previous day
#'   \item Shifts all dates forward by the calculated number of days
#'   \item Converts the updated dates back to character format
#' }
#'
#' @return A data.table with updated dates, shifted to the current date
#'
#' @note
#' - Requires the `data.table` and `mintyr` packages
#' - Uses the current system date as a reference for date shifting
#' - Maintains the original structure of the date column
#'
#' @importFrom data.table copy
#' @export
fires <- function() {
  Date <- NULL
  data <- data.table::copy(mintyr::fire)
  days_diff <- Sys.Date() - 1 - max(unique(as.Date(data$Date)))
  data[, Date := as.Date(Date)
  ][, `:=`(Date, as.Date(Date) + days_diff)
  ][, Date := as.character(Date)][]
}

```
  
```{r example-fires}
head(fires())
```
  

# nedaps
    
```{r function-nedaps}
#' Update NEDAPS Dataset with Current Date
#'
#' @description
#' This function creates a copy of the NEDAPS dataset and adjusts the visit times 
#' to align with the current date while maintaining the original time patterns.
#'
#' @details
#' The function performs the following operations:
#' \itemize{
#'   \item Creates a copy of the NEDAPS dataset from the mintyr package
#'   \item Calculates the number of days between the last recorded visit and the previous day
#'   \item Shifts all visit times forward by the calculated number of days
#'   \item Preserves the original time patterns of the visits
#' }
#'
#' @return A data.table with updated visit times, shifted to the current date
#'
#' @note
#' - Requires the `data.table` and `mintyr` packages
#' - Uses the current system date as a reference for date shifting
#' - Maintains the original time of day for each visit
#'
#' @importFrom data.table copy IDateTime
#' @export
nedaps <- function() {
  visit_time <- time <- NULL
  data <- data.table::copy(mintyr::nedap)
  days_diff <- Sys.Date() - 1 - max(unique(as.Date(data$visit_time)))
  data[, `:=`(c("date", "time"), data.table::IDateTime(visit_time))
  ][, `:=`(date, as.Date(date) + days_diff)
  ][, visit_time := as.POSIXct(paste(date, time), format="%Y-%m-%d %H:%M:%S")
  ][, c("date", "time") := NULL][]
}

```
  
```{r example-nedaps}
head(nedaps())
```


# convert_nest
    
```{r function-convert_nest}
#' Convert Nested Columns Between `data.frame` and `data.table`
#'
#' @description
#' Transforms a `data.frame` or `data.table` by converting nested columns 
#' to either `data.frame` or `data.table` format while preserving the original data structure.
#'
#' @param data A `data.frame` or `data.table` containing nested columns
#' @param to A `character` string specifying the target format. 
#'   Options are `"df"` (data frame) or `"dt"` (data table). Defaults to `"df"`.
#' @param nest_cols A `character` vector of column names containing nested data. 
#'   If `NULL`, the function automatically detects list columns.
#'
#' @details
#' Advanced Nested Column Conversion Features:
#' \itemize{
#'   \item Intelligent automatic detection of nested columns
#'   \item Comprehensive conversion of entire data structure
#'   \item Selective conversion of specified nested columns
#'   \item Non-destructive transformation with data copying
#' }
#'
#' Conversion Strategies:
#' \enumerate{
#'   \item Nested column identification based on `is.list()` detection
#'   \item Preservation of original data integrity
#'   \item Flexible handling of mixed data structures
#'   \item Consistent type conversion across nested elements
#' }
#'
#' Nested Column Handling:
#' \itemize{
#'   \item Supports conversion of `list` columns
#'   \item Handles `data.table`, `data.frame`, and generic `list` inputs
#'   \item Maintains original column structure and order
#'   \item Prevents in-place modification of source data
#' }
#'
#' @return 
#' A transformed `data.frame` or `data.table` with nested columns converted to the specified format.
#'
#' @note
#' Conversion Characteristics:
#' \itemize{
#'   \item Non-destructive transformation of nested columns
#'   \item Supports flexible input and output formats
#'   \item Intelligent type detection and conversion
#'   \item Minimal performance overhead
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`data.table::as.data.table()`]
#'   \item [`tibble::as_tibble()`]
#' }
#'
#' @importFrom data.table as.data.table copy
#' @importFrom tibble as_tibble
#' 
#' @export
convert_nest <- function(data, to = c("df", "dt"), nest_cols = NULL) {
  to <- match.arg(to)

  # Automatically detect nested columns (list columns) if not specified
  if (is.null(nest_cols)) {
    nest_cols <- names(data)[sapply(data, is.list)]
  }

  if (to == "df") {
    # If data is data.table, convert to data.frame and copy to avoid modifying original data
    if (inherits(data, "data.table")) {
      data <- as_tibble(copy(data))
    } else if (!inherits(data, "data.frame")) {
      data <- as_tibble(data)
    }
    # Convert each element of nested columns to data.frame
    for (col in nest_cols) {
      data[[col]] <- lapply(data[[col]], function(x) {
        if (inherits(x, "data.table")) {
          as_tibble(copy(x))
        } else if (!inherits(x, "data.frame")) {
          as_tibble(x)
        } else {
          x
        }
      })
    }
  } else if (to == "dt") {
    # If data is not data.table, convert to data.table and copy to avoid modifying original data
    if (!inherits(data, "data.table")) {
      data <- as.data.table(copy(data))
    }
    # Convert each element of nested columns to data.table
    for (col in nest_cols) {
      data[[col]] <- lapply(data[[col]], function(x) {
        if (!inherits(x, "data.table")) {
          as.data.table(copy(x))
        } else {
          x
        }
      })
    }
  }

  return(data)
}
```
  
```{r example-convert_nest}
# Convert a data frame with nested columns to data table
df_nest1 <- iris |> 
  dplyr::group_nest(Species)
df_nest1
df_nest2 <- iris |>
  dplyr::group_nest(Species) |>
  dplyr::mutate(data2 = purrr::map(data, dplyr::mutate, c=2))
df_nest2
# Convert a data table with specific nested columns to data frame
convert_nest(df_nest1, to = "dt", nest_cols = c("data"))
convert_nest(df_nest2, to = "dt", nest_cols = c("data", "data2"))
# Convert a data table with nested columns to data frame
dt_nest <- mintyr::w2l_nest(data = iris, cols2l = 1:2, by = "Species")
convert_nest(dt_nest, to = "df", nest_cols = c("data"))
```
  
  
# get_path_segment
    
```{r function-get_path_segment}
#' Advanced File Path Segment Extraction
#'
#' @description
#' A robust utility for precise segment extraction from file system paths
#' with flexible indexing and comprehensive error handling.
#'
#' @param paths A 'character vector' containing file system paths
#'   - Must be non-empty
#'   - Path segments separated by forward slash `'/'`
#'   - Supports absolute and relative paths
#'   - Handles complex path structures
#'
#' @param n Numeric index for segment selection
#'   - Positive values: Select from path start
#'   - Negative values: Select from path end
#'   - Cannot be `0`
#'   - Default is `1` (first segment)
#'
#' @details
#' Sophisticated Path Segment Extraction Mechanism:
#' \enumerate{
#'   \item Input validation and preprocessing
#'   \item Robust path segmentation
#'   \item Flexible indexing strategy
#'   \item Intelligent segment retrieval
#'   \item Graceful handling of edge cases
#' }
#'
#' Indexing Behavior:
#' \itemize{
#'   \item Positive `n`: Forward indexing from path start
#'     - `n = 1`: First segment
#'     - `n = 2`: Second segment
#'   \item Negative `n`: Reverse indexing from path end
#'     - `n = -1`: Last segment
#'     - `n = -2`: Second-to-last segment
#' }
#'
#' Path Parsing Characteristics:
#' \itemize{
#'   \item Ignores consecutive `'/'` delimiters
#'   \item Removes empty path segments
#'   \item Returns `NA_character_` for non-existent segments
#'   \item Supports complex path structures
#' }
#'
#' @return 'character vector' with extracted path segments
#'   - Matching segments for valid indices
#'   - `NA_character_` for segments beyond path length
#'
#' @note Critical Operational Constraints:
#' \itemize{
#'   \item Requires non-empty 'paths' input
#'   \item `n` must be non-zero integer
#'   \item Supports cross-platform path representations
#'   \item Minimal computational overhead
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`base::strsplit()`] String splitting utility
#'   \item [`tools::file_path_sans_ext()`] File extension manipulation
#' }
#'
#' @export
get_path_segment <- function(paths, n = 1) {
  # Check if paths parameter is provided
  if (missing(paths)) stop("Parameter 'paths' cannot be empty")
  
  # Validate paths is a character vector
  if (!is.character(paths)) stop("'paths' must be character")
  
  # Return empty character vector if paths is empty
  if (length(paths) == 0) return(character(0))
  
  # Validate n is numeric
  if (!is.numeric(n)) stop("'n' must be numeric")
  
  # Prevent zero index
  if (n == 0) stop("'n' cannot be 0")
  
  # Split paths into segments and remove empty strings
  segments <- strsplit(paths, "/")
  segments <- lapply(segments, function(x) x[x != ""])
  
  # Extract specific path segments
  result <- sapply(segments, function(x) {
    if (n > 0) {
      # Positive index: count from the beginning
      # Return segment if index exists, otherwise return NA
      if (length(x) >= n) x[n] else NA_character_
    } else {
      # Negative index: count from the end
      # Convert negative index to positive position
      pos <- length(x) + n + 1
      
      # Return segment if position is valid, otherwise return NA
      if (pos > 0 && pos <= length(x)) x[pos] else NA_character_
    }
  })
  
  return(result)
}
```
  
```{r example-get_path_segment}
# Example usage demonstrations
paths <- c("/home/user/documents", "/var/log/system", "/usr/local/bin")
# Positive index example
get_path_segment(paths, 2)
# Negative index example
get_path_segment(paths, -2)
```


# format_digits
    
```{r function-format_digits}
#' Format Numeric Columns with Specified Digits
#'
#' The `format_digits` function formats numeric columns in a data frame or data table by rounding numbers to a specified number of decimal places and converting them to character strings. It can optionally format the numbers as percentages.
#'
#' @param data A `data.frame` or `data.table`. The input data containing numeric columns to format.
#' @param cols An optional numeric or character vector specifying the columns to format. If `NULL` (default), all numeric columns are formatted.
#' @param digits A non-negative integer specifying the number of decimal places to use. Defaults to `2`.
#' @param percentage A logical value indicating whether to format the numbers as percentages. If `TRUE`, the numbers are multiplied by 100 and a percent sign (`%`) is appended. Defaults to `FALSE`.
#'
#' @return A `data.table` with the specified numeric columns formatted as character strings with the specified number of decimal places. If `percentage = TRUE`, the numbers are shown as percentages.
#'
#' @details
#' The function performs the following steps:
#' \enumerate{
#'   \item Validates the input parameters, ensuring that `data` is a `data.frame` or `data.table`, `cols` (if provided) are valid column names or indices, and `digits` is a non-negative integer.
#'   \item Converts `data` to a `data.table` if it is not already one.
#'   \item Creates a formatting function based on the `digits` and `percentage` parameters:
#'   \itemize{
#'     \item If `percentage = FALSE`, numbers are rounded to `digits` decimal places.
#'     \item If `percentage = TRUE`, numbers are multiplied by 100, rounded to `digits` decimal places, and a percent sign (`%`) is appended.
#'   }
#'   \item Applies the formatting function to the specified columns:
#'   \itemize{
#'     \item If `cols` is `NULL`, the function formats all numeric columns in `data`.
#'     \item If `cols` is specified, only those columns are formatted.
#'   }
#'   \item Returns a new `data.table` with the formatted columns.
#' }
#'
#' @import data.table
#' @export
#'
#' @note
#' \itemize{
#'   \item The input `data` must be a `data.frame` or `data.table`.
#'   \item If `cols` is specified, it must be a vector of valid column names or indices present in `data`.
#'   \item The `digits` parameter must be a single non-negative integer.
#'   \item The original `data` is not modified; a modified copy is returned.
#' }
format_digits <- function(data, cols = NULL, digits = 2, percentage = FALSE) {
  # Parameter checks
  if (!is.data.frame(data)) {
    stop("Input data must be a data.frame or data.table object")
  }

  # Convert to data.table if it's a data.frame
  if (!is.data.table(data)) {
    data <- as.data.table(data)
  }

  # Check cols parameter
  if (!is.null(cols)) {
    if (!is.numeric(cols) && !is.character(cols)) {
      stop("'cols' must be numeric or character vector")
    }

    if (length(cols) == 0) {
      stop("When specified, 'cols' cannot be empty")
    }

    if (is.numeric(cols)) {
      if (any(cols < 1) || any(cols > ncol(data))) {
        stop("Numeric column indices must be between 1 and ", ncol(data))
      }
      cols <- names(data)[cols]
    }

    if (!all(cols %in% names(data))) {
      invalid_cols <- cols[!cols %in% names(data)]
      stop("Following columns do not exist in the data: ",
           paste(invalid_cols, collapse = ", "))
    }
  }

  # Check digits parameter
  if (!is.numeric(digits) ||
      length(digits) != 1 ||
      digits < 0 ||
      digits != round(digits)) {
    stop("'digits' must be a single non-negative integer")
  }

  # Create format string based on percentage parameter
  fmt <- if(percentage) {
    function(x) sprintf(paste0("%.", digits, "f%%"), round(as.numeric(x) * 100, digits))
  } else {
    function(x) sprintf(paste0("%.", digits, "f"), as.numeric(x))
  }

  # Create a copy of the data to modify
  result <- copy(data)

  # Process all numeric columns if cols is NULL
  if (is.null(cols)) {
    result[, names(.SD) := lapply(.SD, fmt), .SDcols = is.numeric][]
  } else {
    # Process specified columns
    result[, (cols) := lapply(.SD, fmt), .SDcols = cols][]
  }

  return(result)
}
```
  
```{r example-format_digits}
# Create example data
dt <- data.table::data.table(
  a = c(0.1234, 0.5678),
  b = c(0.2345, 0.6789),
  c = c("text1", "text2")
)
dt
# Format without percentage
format_digits(dt, cols = c("a", "b"))
# Format with percentage
format_digits(dt, cols = c("a"), percentage = TRUE)
```
  


# mintyr_example
    
```{r function-mintyr_example}
#' Get path to mintyr examples
#' 
#' mintyr comes bundled with a number of sample files in
#' its 'inst/extdata' directory. Use `vroom_example()` to retrieve the path to one
#' example.
#' 
#' @param path Name of file.
#' @seealso [mintyr::mintyr_examples()]
#' @export
mintyr_example <- function (path) {
  system.file("extdata", path, package = "mintyr", mustWork = TRUE)
}
```
  
```{r example-mintyr_example}
mintyr_example("csv_test1.csv")
```
  
# mintyr_examples
    
```{r function-mintyr_examples}
#' Get path to one example
#' 
#' vroom comes bundled with a number of sample files in
#' its 'inst/extdata' directory. Use `vroom_examples()` to list all the
#' available examples.
#' 
#' @param pattern A regular expression of filenames to match. If `NULL`, all available files are returned.
#' @seealso [mintyr::mintyr_example()]
#' @export
mintyr_examples <- function (pattern = NULL) {
  list.files(system.file("extdata", package = "mintyr"), pattern = pattern)
}
```
  
```{r example-mintyr_examples}
mintyr_examples()
```
  
  
# import_xlsx
    
```{r function-import_xlsx}
#' Import Data from `Excel` Files with Advanced Handling
#'
#' @description
#' A robust and flexible function for importing data from one or multiple 
#' `Excel` files, offering comprehensive options for sheet selection, 
#' data combination, and source tracking.
#'
#' @param file A `character` vector of file paths to `Excel` files. 
#'   Must point to existing `.xlsx` or `.xls` files.
#' @param rbind A `logical` value controlling data combination strategy:
#'   - `TRUE`: Combines all data into a single `data.table`
#'   - `FALSE`: Returns a list of `data.table`s
#'   Default is `TRUE`.
#' @param sheet A `numeric` vector or `NULL` specifying sheet import strategy:
#'   - `NULL` (default): Imports all sheets
#'   - `numeric`: Imports only specified sheet indices
#' @param ... Additional arguments passed to [`readxl::read_excel()`], 
#'   such as `col_types`, `skip`, or `na`.
#'
#' @details
#' Advanced `Excel` Data Import Features:
#' \itemize{
#'   \item Multi-file and multi-sheet data extraction
#'   \item Intelligent source tracking for files and sheets
#'   \item Flexible data combination strategies
#'   \item Automatic handling of inconsistent column structures
#'   \item Preservation of original data types
#' }
#'
#' Comprehensive Import Strategies:
#' \enumerate{
#'   \item Dynamic sheet selection
#'   \item Automatic file and sheet metadata tracking
#'   \item Seamless handling of disparate data structures
#'   \item Configurable import and combination methods
#' }
#'
#' Data Transformation Capabilities:
#' \itemize{
#'   \item Supports single and multiple `Excel` file imports
#'   \item Handles partial or complete sheet imports
#'   \item Manages missing columns through intelligent filling
#'   \item Provides granular control over import process
#' }
#'
#' @return 
#' Depends on the `rbind` parameter:
#' \itemize{
#'   \item If `rbind = TRUE`: A single `data.table` with additional tracking columns:
#'     - `excel_name`: Source file name (without extension)
#'     - `sheet_name`: Source sheet name
#'   \item If `rbind = FALSE`: A named list of `data.table`s with format 
#'     `"filename_sheetname"`
#' }
#'
#' @note
#' Critical Import Considerations:
#' \itemize{
#'   \item Requires all specified files to be accessible `Excel` files
#'   \item Sheet indices must be valid across input files
#'   \item `rbind = TRUE` assumes compatible data structures
#'   \item Missing columns are automatically filled with `NA`
#'   \item File extensions are automatically removed in tracking columns
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`readxl::read_excel()`] for underlying Excel reading
#'   \item [`data.table::rbindlist()`] for data combination
#' }
#'
#' @importFrom data.table ":="
#' @importFrom readxl read_excel excel_sheets
#'
#' @export
import_xlsx <- function(file, rbind = TRUE, sheet = NULL, ...) {
  excel_name <- NULL
  # Parameter checks
  if (!is.character(file) || !all(file.exists(file))) {
    stop("file must be a vector of existing file paths.")
  }

  if (!is.logical(rbind)) {
    stop("Parameter 'rbind' should be logical (TRUE or FALSE).")
  }

  # Function to remove file extension
  remove_extension <- function(filename) {
    sub("\\.[^.]*$", "", basename(filename))
  }

  # Reads selected sheets from a single Excel file and converts them into a data.table
  read_selected_sheets <- function(file_path, merge, sheet_indices, ...) {
    all_sheets <- readxl::excel_sheets(file_path)
    # Validate sheet indices
    if (!is.null(sheet_indices)) {
      if (is.numeric(sheet_indices)) {
        if (any(sheet_indices > length(all_sheets)) || any(sheet_indices < 1)) {
          stop("sheet index out of range for file: ", file_path)
        }
      } else {
        stop("sheet parameter must be a numeric vector or NULL.")
      }
    }

    selected_sheets <- if (is.null(sheet_indices)) all_sheets else all_sheets[sheet_indices]

    sheet_data <- lapply(selected_sheets, function(s) {
      dt <- data.table::as.data.table(readxl::read_excel(file_path, sheet = s, ...))
      if (!merge) {
        return(list(data = dt))  # Return each sheet as an independent list item if not merging
      } else {
        return(dt)
      }
    })

    if (merge) {
      names(sheet_data) <- selected_sheets
      data.table::rbindlist(sheet_data, use.names = TRUE, fill = TRUE, idcol = "sheet_name")
    } else {
      names(sheet_data) <- selected_sheets
      return(sheet_data)
    }
  }

  # Finding minimum sheet count across all Excel files
  min_sheet_count <- min(sapply(file, function(f) length(readxl::excel_sheets(f))))

  # Sheet parameter validation
  if (!is.null(sheet)) {
    if (is.numeric(sheet) && (max(sheet) > min_sheet_count || min(sheet) < 1)) {
      stop("sheet parameter contains indices out of range across files.")
    }
  }

  # Applies the modified function across all files
  all_data <- lapply(file, read_selected_sheets, merge = rbind, sheet_indices = sheet, ...)

  if (rbind) {
    # If merging, use rbindlist to combine all files' data into one data.table
    combined_data <- data.table::rbindlist(all_data, use.names = TRUE, fill = TRUE, idcol = "excel_name")
    xlsx_sheets_names <- sapply(file, remove_extension)  # 使用remove_extension替代tools::file_path_sans_ext
    # Set 'excel_name' column's value to the corresponding file names
    combined_data[, excel_name := rep(xlsx_sheets_names, sapply(all_data, nrow))][]
    return(combined_data)
  } else {
    # If not merging, create a new list to store all sheets' data
    result_list <- list()
    xlsx_sheets_names <- sapply(file, remove_extension)  # 使用remove_extension替代tools::file_path_sans_ext
    for (i in seq_along(file)) {
      file_name <- xlsx_sheets_names[i]
      file_data <- all_data[[i]]
      # For each file's sheets, set list item names as "file_name_sheet_name"
      for (sheet_name in names(file_data)) {
        list_name <- paste(file_name, sheet_name, sep = "_")
        result_list[[list_name]] <- file_data[[sheet_name]][["data"]]
      }
    }
    return(result_list)
  }
}
```
  
```{r example-import_xlsx}
xlsx_files <- mintyr_example(mintyr_examples("xlsx_test"))
xlsx_files
import_xlsx(xlsx_files)
```
  

  
# import_csv
<!-- 
This first section shows:
- the three parts necessary for a package: 'function', 'examples' and 'tests'.  
  + Note that the three following chunks have names accordingly.
-->

```{r function-import_csv}
#' Flexible CSV File Import with Multiple Backend Support
#'
#' @description
#' A comprehensive `CSV` file import function offering advanced reading capabilities 
#' through `data.table` and `arrow` packages with intelligent data combination strategies.
#'
#' @param file A `character` vector of file paths to `CSV` files.
#'   Must point to existing and accessible files.
#'
#' @param package A `character` string specifying the backend package:
#'   - `"data.table"`: Uses [`data.table::fread()`] (default)
#'   - `"arrow"`: Uses [`arrow::read_csv_arrow()`]
#'   Determines the underlying reading mechanism.
#'
#' @param rbind A `logical` value controlling data combination strategy:
#'   - `TRUE`: Combines all files into a single data object
#'   - `FALSE`: Returns a list of individual data objects
#'   Default is `TRUE`.
#'
#' @param rbind_label A `character` string or `NULL` for source file tracking:
#'   - `character`: Specifies the column name for file source labeling
#'   - `NULL`: Disables source file tracking
#'   Default is `"_file"`.
#'
#' @param ... Additional arguments passed to backend-specific reading functions 
#'   (e.g., `col_types`, `na.strings`, `skip`).
#'
#' @details
#' Comprehensive `CSV` Import Features:
#' \itemize{
#'   \item Dual-backend support (`data.table` and `arrow`)
#'   \item Intelligent multi-file import strategies
#'   \item Flexible data combination and source tracking
#'   \item Automatic handling of inconsistent file structures
#'   \item Preservation of original data types
#' }
#'
#' Import Strategies:
#' \enumerate{
#'   \item Dynamic package selection
#'   \item Configurable file combination methods
#'   \item Automatic source file metadata tracking
#'   \item Seamless handling of disparate data structures
#' }
#'
#' Performance Considerations:
#' \itemize{
#'   \item `data.table`: Optimized for speed and memory efficiency
#'   \item `arrow`: Enhanced performance for large datasets
#'   \item Automatic column alignment during import
#'   \item Minimal memory overhead
#' }
#'
#' @return 
#' Depends on the `rbind` parameter:
#' \itemize{
#'   \item If `rbind = TRUE`: A single data object (from chosen package) 
#'     containing all imported data
#'   \item If `rbind = FALSE`: A named list of data objects with names 
#'     derived from input file names (without extensions)
#' }
#'
#' @note
#' Critical Import Considerations:
#' \itemize{
#'   \item Requires all specified files to be accessible `CSV` files
#'   \item Supports flexible backend selection
#'   \item `rbind = TRUE` assumes compatible data structures
#'   \item Missing columns are automatically aligned
#'   \item File extensions are automatically removed in tracking columns
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`data.table::fread()`] for `data.table` backend
#'   \item [`arrow::read_csv_arrow()`] for `arrow` backend
#'   \item [`data.table::rbindlist()`] for data combination
#' }
#'
#' @import data.table
#' @import arrow
#'
#' @export
import_csv <- function (file, package = "data.table", rbind = TRUE, rbind_label = "_file", ...) {
  # Validations
  if (!is.character(file) || !all(file.exists(file))) {
    stop("file must be a vector of existing file paths.")
  }

  if (!package %in% c("data.table", "arrow")) {
    stop("package must be one of 'data.table', 'arrow'.")
  }

  # Function to remove file extension
  remove_extension <- function(filename) {
    sub("\\.[^.]*$", "", basename(filename))
  }

  # Read Functionality with naming
  read_files <- function(read_function) {
    file_data <- lapply(file, function(file_path) {
      df <- read_function(file_path, ...)
      if (!is.null(rbind_label) && rbind && length(file) > 1) {
        # Add a column with the label indicating the file origin, without extension
        df <- cbind(stats::setNames(data.frame(remove_extension(file_path)), rbind_label), df)
      }
      return(df)
    })

    if (rbind && length(file) > 1) {
      # Combine all data into a single data table/data frame
      return(data.table::rbindlist(file_data, use.names = TRUE, fill = TRUE))
    } else {
      # When rbind is FALSE, name the list elements with file names
      names(file_data) <- remove_extension(file)
      return(file_data)
    }
  }

  # Package specific operations
  if (package == "data.table") {
    return(read_files(data.table::fread))
  } else if (package == "arrow") {
    return(read_files(arrow::read_csv_arrow))
  }
}
```

```{r examples-import_csv}
csv_files <- mintyr_example(mintyr_examples("csv_test"))
csv_files
import_csv(csv_files)
```


# get_filename
    
```{r function-get_filename}
#' Advanced Filename Extraction from File Paths
#'
#' @description
#' A robust `filename` extraction utility providing comprehensive path processing 
#' with granular control over filename transformation.
#'
#' @param paths A `character` vector containing file system paths.
#'   Must be valid and accessible path strings.
#'
#' @param rm_extension A `logical` flag controlling file extension removal:
#'   - `TRUE`: Strips file extensions from filenames
#'   - `FALSE`: Preserves complete filename with extension
#'   Default is `TRUE`.
#'
#' @param rm_path A `logical` flag managing directory path handling:
#'   - `TRUE`: Extracts only the filename, discarding directory information
#'   - `FALSE`: Retains complete path information
#'   Default is `TRUE`.
#'
#' @details
#' Comprehensive Path Processing Features:
#' \itemize{
#'   \item Intelligent input validation
#'   \item Flexible filename transformation
#'   \item Robust handling of diverse path formats
#'   \item Configurable extraction strategies
#'   \item Minimal performance overhead
#' }
#'
#' Processing Workflow:
#' \enumerate{
#'   \item Validates input path vector
#'   \item Handles empty input scenarios
#'   \item Optionally removes directory paths using [`base::basename()`]
#'   \item Optionally strips file extensions via regex substitution
#' }
#'
#' Extension Handling Strategies:
#' \itemize{
#'   \item Supports multi-dot filenames
#'   \item Removes the last file extension
#'   \item Preserves complex filename structures
#'   \item Compatible with various file naming conventions
#' }
#'
#' @return A `character` vector of processed filenames with applied transformations.
#'
#' @note
#' Critical Behavioral Considerations:
#' \itemize{
#'   \item Requires valid `character` input paths
#'   \item Supports processing multiple file paths simultaneously
#'   \item Warns when no transformations are requested
#'   \item Handles edge cases like empty vectors gracefully
#'   \item Preserves original input order
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`base::basename()`] for basic filename extraction
#'   \item [`base::file.path()`] for path manipulation
#'   \item [`tools::file_ext()`] for extension handling
#' }
#'
#' @export
get_filename <- function(paths, rm_extension = TRUE, rm_path = TRUE) {

  # Input validation
  if (missing(paths)) {
    stop("Parameter 'paths' cannot be empty")
  }

  if (!is.character(paths)) {
    stop("'paths' must be a character vector")
  }

  # Handle empty vector
  if (length(paths) == 0) {
    return(character(0))
  }

  # Warn if both parameters are FALSE
  if (!rm_extension && !rm_path) {
    warning("Setting both rm_extension=FALSE and rm_path=FALSE returns the original paths")
  }

  # Process paths
  result <- if (rm_path) basename(paths) else paths

  # Process extensions
  if (rm_extension) {
    result <- sub("\\.[^.]*$", "", result)
  }

  return(result)
}
```
  
```{r example-get_filename}
xlsx_files <- mintyr_example(mintyr_examples("xlsx_test"))
xlsx_files
get_filename(xlsx_files) # Keep only file names
get_filename(xlsx_files, rm_extension = FALSE) # Keep extension
get_filename(xlsx_files, rm_path = FALSE) # Keep path
```


# w2l_nest
    
```{r function-w2l_nest}
#' Reshape Wide Data to Long Format and Nest by Specified Columns
#' 
#' @description
#' The `w2l_nest` function reshapes wide-format data into long-format and nests it by specified columns.
#' It handles both `data.frame` and `data.table` objects and provides options for grouping and nesting the data.
#' 
#' @param data A `data.frame` or `data.table`. The input data in wide format.
#' @param cols2l A numeric or character vector. Specifies the columns to reshape from wide to long format.
#'   Can be either numeric indices or column names.
#' @param by An optional character vector. Specifies the columns to group by. Default is `NULL`.
#' @param nest_type A character string, either `"dt"` or `"df"`. Specifies the type of object to nest in the
#'   result: `"dt"` for `data.table`, `"df"` for `data.frame`. Default is `"dt"`.
#'
#' @return A `data.table` with nested data in long format, grouped by specified columns if provided.
#' Each row contains a nested `data.table` or `data.frame` under the column `data`, depending on `nest_type`.
#' \itemize{
#'   \item If `by` is `NULL`, returns a `data.table` nested by `name`.
#'   \item If `by` is specified, returns a `data.table` nested by `name` and the grouping variables.
#' }
#' 
#' @details
#' The function performs the following key operations:
#' \enumerate{
#'   \item Melts the specified wide columns into long format
#'   \item Nests the resulting data by the `name` column
#'   \item Optionally groups by additional variables specified in `by`
#'   \item Allows flexible output format (`data.table` or `data.frame`)
#' }
#' 
#' Transformation Strategy:
#' \itemize{
#'   \item Converts input to `data.table` if necessary
#'   \item Validates input columns and grouping variables
#'   \item Reshapes data using `data.table::melt()`
#'   \item Nests data with flexible grouping options
#' }
#' 
#' @note
#' Important Considerations:
#' \itemize{
#'   \item The `cols2l` parameter should be either numeric indices or a character vector of column names present in `data`.
#'   \item Ensure all grouping variables specified in `by` are present in `data`.
#'   \item The function converts `data.frame` to `data.table` if necessary.
#'   \item The `nest_type` parameter controls whether nested data are `data.table` (`"dt"`) or `data.frame` (`"df"`) objects.
#'   \item If `nest_type` is not `"dt"` or `"df"`, the function will stop with an error.
#' }
#' 
#' @import data.table
#' @export
w2l_nest <- function(data, cols2l, by = NULL, nest_type = "dt") {
  . <- name <- NULL

  # Ensure the data is a data.table object
  if (!data.table::is.data.table(data)) {
    if (is.data.frame(data)) {
      data <- data.table::as.data.table(data)  # Convert data.frame to data.table if necessary
    } else {
      stop("Data must be either a data.frame or a data.table.")  # Stop if data is not a data.table or data.frame
    }
  }

  # Process grouping variables
  if (!is.null(by)) {
    missing_by_vars <- by[!by %in% names(data)]
    if (length(missing_by_vars) > 0) {
      stop("Grouping variables not present in data: ", paste(missing_by_vars, collapse=", "))
    }
  }

  # Check the validity of cols2l based on its type
  if (is.numeric(cols2l)) {
    if (any(cols2l < 1 | cols2l > ncol(data))) {
      stop("Numeric indices in cols2l are out of bounds.")  # Corrected the condition
    }
  } else if (is.character(cols2l)) {
    if (!all(cols2l %in% names(data))) {
      missing_cols <- cols2l[!cols2l %in% names(data)]
      stop("Some columns specified in cols2l are not present in the data: ", paste(missing_cols, collapse=", "))
    }
  } else {
    stop("cols2l should be either numeric indices or character vector of column names.")  # Ensure cols2l is either numeric or character
  }

  # Melt the data
  #id_vars <- setdiff(names(data), cols2l)  # Use all other columns as id variables
  melted_data <- data.table::melt(
    data,
    #id.vars = id_vars,
    measure.vars = cols2l,
    variable.name = "name",
    value.name = "value"
  )  # Melt the data using specified cols2l

  # Determine grouping variables for nesting
  if (!is.null(by) && length(by) > 0) {
    groupby <- c("name", by)
  } else {
    groupby <- "name"
  }

  # # Nest the data based on nest_type
  if (nest_type == "dt") {
    result <- melted_data[, .(data = list(.SD)), by = groupby]
  } else if (nest_type == "df") {
    result <- melted_data[, .(data = list(as.data.frame(.SD))), by = groupby]
  } else {
    stop("Invalid nest_type provided. It must be either 'dt' or 'df'.")
  }

  # Return the result
  return(result)
}
```
  
```{r example-w2l_nest}
w2l_nest(data = iris, cols2l = 1:4)
w2l_nest(data = iris, cols2l = c("Sepal.Length", "Sepal.Width", "Petal.Length"), by = "Species")
```
  
# w2l_split
    
```{r function-w2l_split}
#' Wide to Long Data Splitting with Advanced Transformation Capabilities
#'
#' @description
#' Transforms wide-format data to long format with flexible splitting 
#' and grouping options, supporting multiple data type conversions.
#'
#' @param data A `data.frame` or `data.table` to be transformed and split.
#' @param cols2l Columns to be transformed from wide to long format. 
#'   Can be specified as numeric indices or column names.
#' @param by Optional grouping columns for additional data stratification.
#' @param split_type Output format for split data, either `"dt"` (`data.table`) 
#'   or `"df"` (`data.frame`). Defaults to `"dt"`.
#' @param sep Separator used for generating list names when grouping. 
#'   Defaults to `"_"`.
#'
#' @details
#' The function provides comprehensive wide-to-long data transformation 
#' with the following advanced features:
#' \itemize{
#'   \item Flexible column specification (numeric indices or names)
#'   \item Automatic data type conversion
#'   \item Intelligent handling of grouping variables
#'   \item Customizable output data type
#'   \item Robust error checking and validation
#' }
#'
#' Transformation Strategy:
#' \enumerate{
#'   \item Converts input to `data.table` format
#'   \item Melts specified columns to long format
#'   \item Splits data based on optional grouping variables
#'   \item Generates list names using grouping values
#' }
#'
#' Column Specification Options:
#' \itemize{
#'   \item Numeric indices of columns to transform
#'   \item Character vector of column names
#'   \item Comprehensive validation of provided columns
#' }
#'
#' @return 
#' A list of `data.table`s or `data.frame`s, split according to specified parameters.
#'
#' @note
#' \itemize{
#'   \item Supports complex data transformation scenarios
#'   \item Handles mixed input data types
#'   \item Provides detailed error messages for invalid inputs
#'   \item Efficient data manipulation using `data.table`
#' }
#'
#' @importFrom data.table is.data.table as.data.table melt
#' @export
#' 
w2l_split <- function (data, cols2l, by = NULL, split_type = "dt", sep = "_") {
  # Check if input data is data.table, if not convert it
  if (!data.table::is.data.table(data)) {
    if (is.data.frame(data)) {
      data <- data.table::as.data.table(data)
    }
    else {
      stop("data must be a data.frame or data.table.")
    }
  }

  # Check if cols2l parameter is provided
  if (missing(cols2l))
    stop("cols2l parameter is missing.")

  # Process cols2l parameter - can be either numeric indices or column names
  if (is.numeric(cols2l)) {
    if (any(cols2l < 1 | cols2l > ncol(data))) {
      stop("Numeric indices in cols2l are out of bounds.")
    }
    cols2l_names <- names(data)[cols2l]
  }
  else if (is.character(cols2l)) {
    if (!all(cols2l %in% names(data))) {
      missing_cols <- cols2l[!cols2l %in% names(data)]
      stop("Some columns specified in cols2l are not present in the data: ",
           paste(missing_cols, collapse = ", "))
    }
    cols2l_names <- cols2l
  }
  else {
    stop("cols2l should be either numeric indices or character vector of column names.")
  }

  # Validate by parameter if provided
  if (!is.null(by)) {
    if (!all(by %in% names(data))) {
      missing_by <- by[!by %in% names(data)]
      stop("Some 'by' columns are not present in the data: ",
           paste(missing_by, collapse = ", "))
    }
  }

  # Identify ID variables (all columns except those to be transformed)
  id_vars <- setdiff(names(data), cols2l_names)
  if (!is.null(by)) {
    id_vars <- unique(c(id_vars, by))
  }

  # Melt data from wide to long format
  dt_long <- data.table::melt(data, id.vars = id_vars, measure.vars = cols2l_names,
                              variable.name = "variable", value.name = "value")

  # Define splitting variables and split the data
  split_vars <- c("variable", by)
  dt_list <- split(dt_long, by = split_vars, keep.by = F, drop = TRUE)

  # Create list names using by variables if provided
  if (!is.null(by)) {
    # Combine split variables values using specified separator
    split_values <- do.call(paste, c(lapply(split_vars, function(x) dt_long[[x]]), list(sep = sep)))
    split_values <- unique(split_values)
    names(dt_list) <- split_values
  }

  # Convert to specified output format
  if (split_type == "dt") {
    # Keep as data.table
  }
  else if (split_type == "df") {
    # Convert to data.frame
    dt_list <- lapply(dt_list, as.data.frame)
  }
  else {
    stop("Invalid split_type provided. It must be either 'dt' or 'df'.")
  }

  return(dt_list)
}
```
  
```{r example-w2l_split}
w2l_split(data = iris, cols2l = 1:3)
w2l_split(data = iris, cols2l = c("Sepal.Length", "Sepal.Width"))
```


# nest_cv
    
```{r function-nest_cv}
#' Advanced Cross-Validation for Nested Datasets
#'
#' @description
#' Provides a flexible and powerful cross-validation strategy for nested datasets,
#' supporting complex machine learning and statistical modeling workflows.
#'
#' @param nest_dt A `data.frame` or `data.table` containing at least one nested 
#' `data.frame` or `data.table` column.
#'   - Supports multi-level nested structures
#'   - Requires at least one nested data column
#' @inheritParams rsample::vfold_cv
#'
#' @details
#' Cross-Validation Processing Workflow:
#' \enumerate{
#'   \item Input data validation
#'   \item Identify nested data columns
#'   \item Perform cross-validation splits for each nested dataset
#'   \item Generate training and validation sets
#'   \item Preserve original non-nested column context
#' }
#'
#' Key Features:
#' \itemize{
#'   \item Supports complex nested data structures
#'   \item Flexible stratified sampling strategies
#'   \item High-performance data processing
#'   \item Seamless integration with `rsample`
#'   \item Preserves original data context
#' }
#'
#' @return Enhanced `data.table` containing:
#' \itemize{
#'   \item Original non-nested columns
#'   \item `splits`: Cross-validation split objects
#'   \item `train`: Training datasets for each split
#'   \item `validate`: Validation datasets for each split
#' }
#'
#' @note Usage Considerations:
#' \itemize{
#'   \item Input data must contain at least one nested `data.frame` or `data.table`
#'   \item Internally converts to `data.table` for performance optimization
#'   \item Stratification variable must exist in all nested data frames
#'   \item Supports additional parameter passing to [`rsample::vfold_cv()`] via `...`
#' }
#'
#'
#' @seealso
#' \itemize{
#'   \item [`rsample::vfold_cv()`] Underlying cross-validation function
#'   \item [`rsample::training()`] Extract training set
#'   \item [`rsample::testing()`] Extract test set
#' }
#'
#' @import data.table
#' @importFrom rsample vfold_cv training testing
#' @export
#'
nest_cv <- function(nest_dt, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...) {
  # Initialize local variables to avoid global binding warnings
  cv_split <- data  <- splits <- NULL

  # Validate input data is not empty
  if (nrow(nest_dt) == 0) {
    stop("Input 'nest_dt' cannot be empty")
  }

  # Identify nested data.frame or data.table columns
  nested_cols <- names(nest_dt)[sapply(nest_dt, function(x) {
    is.list(x) && all(sapply(x, function(y) {
      inherits(y, c("data.frame", "data.table"))
    }))
  })]

  # Ensure at least one nested column exists
  if (length(nested_cols) == 0) {
    stop("Input 'nest_dt' must contain at least one nested column of data.frames or data.tables")
  }

  # Create a copy of input data to prevent modification of original dataset
  dt <- data.table::copy(nest_dt)

  # Identify nested list columns
  is_nested_list <- sapply(dt, function(x) all(vapply(x, is.list, logical(1))))

  # Extract non-nested column names
  non_nested_cols <- names(dt)[!is_nested_list]

  # Apply cross-validation with flexible stratification
  dt[, cv_split := lapply(data, function(x) {
    if (!is.null(strata)) {
      rsample::vfold_cv(
        data = x, 
        v = v, 
        repeats = repeats,
        strata = strata,
        breaks = breaks, 
        pool = pool, 
        ...
      )
    } else {
      rsample::vfold_cv(
        data = x, 
        v = v, 
        repeats = repeats,
        breaks = breaks, 
        pool = pool, 
        ...
      )
    }
  })
  ][, cv_split[[1]], by = non_nested_cols
  ][, ':='(
     train = lapply(splits, \(x) rsample::training(x)),
     validate = lapply(splits, \(x) rsample::testing(x))
   )][]
}
```
  
```{r example-nest_cv}
dt_nest <- w2l_nest(data = iris, cols2l = 1:2, by = "Species")
nest_cv(nest_dt = dt_nest, v = 2, repeats = 2)
```
  
  
# top_perc
    
```{r function-top_perc}
#' Advanced Top Percentage Selection and Statistical Summarization
#'
#' @description
#' A sophisticated function for selecting top or bottom percentiles of data
#' and computing comprehensive statistical summaries with high flexibility.
#'
#' @param data A `data.frame` containing the source dataset for analysis
#'   - Supports various data frame-like structures
#'   - Automatically converts non-data frame inputs
#'
#' @param perc Numeric vector of percentages for data selection
#'   - Range: `-1` to `1`
#'   - Positive values: Select top percentiles
#'   - Negative values: Select bottom percentiles
#'   - Multiple percentiles supported
#'
#' @param trait Character string specifying the 'selection column'
#'   - Must be a valid column name in the input `data`
#'   - Used as the basis for top/bottom percentage selection
#'
#' @param by Optional character vector for 'grouping columns'
#'   - Default is `NULL`
#'   - Enables stratified analysis
#'   - Allows granular percentage selection within groups
#'
#' @param type Statistical summary type
#'   - Default: `"mean_sd"`
#'   - Controls the type of summary statistics computed
#'   - Supports various summary methods from `rstatix`
#'
#' @param keep_data Logical flag for data retention
#'   - Default: `FALSE`
#'   - `TRUE`: Return both summary statistics and selected data
#'   - `FALSE`: Return only summary statistics
#'
#' @details
#' Comprehensive Data Selection and Analysis Workflow:
#' \enumerate{
#'   \item Input validation and preprocessing
#'   \item Flexible percentage-based data selection
#'   \item Optional group-level analysis
#'   \item Statistical summary computation
#'   \item Configurable output generation
#' }
#'
#' Key Features:
#' \itemize{
#'   \item Multi-percentile selection support
#'   \item Stratified analysis capabilities
#'   \item Robust error handling
#'   \item Flexible statistical summarization
#'   \item Optional data retention
#' }
#'
#' @return Depending on `keep_data`:
#' \itemize{
#'   \item `FALSE`: A `data.frame` with summary statistics
#'   \item `TRUE`: A `list` with summary statistics and selected data
#' }
#'
#' @note Operational Considerations:
#' \itemize{
#'   \item Percentage selection range: `-1` to `1`
#'   \item Supports complex grouping strategies
#'   \item Leverages `rstatix` for statistical computations
#'   \item Handles multiple percentile selections
#'   \item Provides detailed error messages for invalid inputs
#' }
#'
#' @seealso
#' \itemize{
#'   \item [`rstatix::get_summary_stats()`] Statistical summary computation
#'   \item [`dplyr::top_frac()`] Percentage-based data selection
#' }
#'
#' @importFrom purrr map set_names list_rbind
#' @importFrom dplyr group_by top_frac across all_of mutate
#' @importFrom rstatix get_summary_stats
#' @importFrom rlang sym
#' @export
top_perc <- function(data, perc, trait, by = NULL, type = "mean_sd", keep_data = FALSE) {
  # Initial checks and data preparation
  missing_args <- c()
  if (missing(data)) missing_args <- c(missing_args, "data")
  if (missing(perc)) missing_args <- c(missing_args, "perc")
  if (missing(trait)) missing_args <- c(missing_args, "trait")
  
  if (length(missing_args) > 0) {
    stop("Error: Missing argument(s): ", paste(missing_args, collapse=", "))
  }
  
  if (!inherits(data, "data.frame")) {
    message("Converting 'data' to data.frame")
    data <- as.data.frame(data)
  }
  
  # Ensure 'perc' is treated as a numeric vector
  perc <- as.numeric(perc)
  if (length(perc) == 0) {
    stop("Error: 'perc' must not be empty.")
  }
  if (any(perc < -1 | perc > 1)) {
    stop("Error: Each element of 'perc' must be a numeric value between -1 and 1.")
  }
  
  # Validate 'trait' parameter
  if (!is.character(trait) || length(trait) != 1) {
    stop("Error: 'trait' must be a single character string.")
  }
  if (!trait %in% names(data)) {
    stop("Error: 'trait' must be a valid column name in 'data'.")
  }
  
  # Validate 'by' parameter if not NULL
  if (!is.null(by)) {
    if (!is.character(by) || length(by) == 0) {
      stop("Error: 'by' must be a character vector of column names in 'data'.")
    }
    if (!all(by %in% names(data))) {
      stop("Error: All elements of 'by' must be valid column names in 'data'.")
    }
  }
  
  # Processing each percentage
  results <- purrr::map(perc, function(p) {
    grouped_data <- if (!is.null(by) && length(by) > 0) {
      data |> dplyr::group_by(dplyr::across(dplyr::all_of(by)))
    } else {
      data
    }
    
    top_data <- grouped_data |>
      dplyr::top_frac(p, !!rlang::sym(trait))
    
    # Always compute stats
    stats <- top_data |>
      rstatix::get_summary_stats(!!rlang::sym(trait), type = type) |>
      dplyr::mutate(top_perc = paste0(p * 100, "%"))
    
    # Return both stats and data if keep_data is TRUE
    if (keep_data) {
      list(stat = stats, data = top_data)
    } else {
      list(stat = stats)
    }
  }) |>
    purrr::set_names(paste(trait, perc, sep = "_"))
  
  # Simplify the output structure based on what is available in each result
  if (keep_data) {
    results
  } else {
    results <- purrr::map(results, "stat") |> purrr::list_rbind()
  }
  
  return(results)
}
```
  
```{r example-top_perc}
# Example 1: Basic usage with single trait
# This example selects the top 10% of observations based on Petal.Width
# keep_data=TRUE returns both summary statistics and the filtered data
top_perc(iris, 
         perc = 0.1,                # Select top 10%
         trait = c("Petal.Width"),  # Column to analyze
         keep_data = TRUE)          # Return both stats and filtered data

# Example 2: Using grouping with 'by' parameter
# This example performs the same analysis but separately for each Species
# Returns nested list with stats and filtered data for each group
top_perc(iris, 
         perc = 0.1,                # Select top 10%
         trait = c("Petal.Width"),  # Column to analyze
         by = "Species")            # Group by Species

# Example 3: Complex example with multiple percentages and grouping variables
# Uses pipe operator and transformed data
iris |>
  # Reshape data from wide to long format for Sepal.Length and Sepal.Width
  tidyr::pivot_longer(1:2,                  # Transform first two columns
                     names_to = "names",     # New column for original column names
                     values_to = "values") |># New column for values
  # Apply top_perc function on reshaped data
  mintyr::top_perc(
    perc = c(0.1, -0.2),           # Select top 10% AND bottom 20%
    trait = "values",               # Analyze the 'values' column
    by = c("Species", "names"),     # Group by both Species and measurement type
    type = "mean_sd")               # Calculate mean and standard deviation

```




<!-- 
# Inflate your package

You're one inflate from paper to box.
Build your package from this very Rmd using `fusen::inflate()` 
-->


```{r development-inflate, eval=FALSE}
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_teaching.Rmd")
```

<!-- 
- Verify your `"DESCRIPTION"` file has been updated
- Verify your function is in `"R/"` directory
- Verify your test is in `"tests/testthat/"` directory
- Verify this Rmd appears in `"vignettes/"` directory 
-->
